{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z6q45sKwPSUb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7702ade1e584a6f907a7be03cab0251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mdtraj as md \n",
    "from ase import Atoms\n",
    "from nglview import show_ase\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import  GCNConv,BatchNorm,GATConv,Linear\n",
    "import torch_geometric.data as data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center the molecule at com           -> Done\n",
    "# train on actual positions            -> loss not decreasing beyond 9\n",
    "# loss focus more on heavy atoms       -> Done\n",
    "# ignore H\n",
    "# change latent space and check which is good dimension -> tried for 2,3,4 all losses are converging to 9..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the edge index to be learned in eoncoder\n",
    "# try EGNN models \n",
    "# input graph have equiverent properties\n",
    "# rotationally equivarient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LGVGTD4dPaQG"
   },
   "outputs": [],
   "source": [
    "# load water mol \n",
    "all_frames = md.load_xtc(\"../10_7/singlesim/it50k/eql2.xtc\",top=\"../10_7/singlesim/it50k/conf.gro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317,
     "referenced_widgets": [
      "b3e2e11d45734b7d9224fb987459470b",
      "83451c0f082c4aa888b1dd14e9c775bf",
      "174bcfbaa57647a791816ea2f5f95aba",
      "1dbdb82571c54cdd93dc2852bfff8d40",
      "8cb134fe0b18494bbefe6c95adc7d14e",
      "65d323feef3b4d44a7846a7c208946f1",
      "1ccf61fe60854532adca37efa0ce3d8c",
      "e8f4eabea82a4f928fa75a55769ed112",
      "51f160dd2cbe413ca4340f08c1c556c6",
      "f25cd88e94d7471fba0524c195300dbd",
      "f7e90ca6eca44a02aa7dbd7c721963d2",
      "d0b06dda6324492e96af92e3aeea444b",
      "c842ad6e08ac425eade8ae91843af6cf"
     ]
    },
    "id": "LfhgrqRRuEAv",
    "outputId": "82b81f8f-849f-4a0e-e6ef-549b93adb26c"
   },
   "outputs": [],
   "source": [
    "molecule = all_frames[0]\n",
    "atomic_nums = [atom.element.atomic_number for atom in molecule.top.atoms] \n",
    "water = Atoms(positions= molecule.xyz[0], numbers=atomic_nums)\n",
    "# show_ase(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate3D(features,psi,theta,phi):\n",
    "    xyz = features[:,:3]\n",
    "    rest = features[:,3:]\n",
    "    matrix = np.array([[np.cos(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.sin(psi),np.cos(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.sin(psi),np.sin(psi)*np.sin(theta)],\n",
    "                          [-np.sin(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.cos(psi),-np.sin(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.cos(psi),np.cos(psi)*np.sin(theta)],\n",
    "                            [np.sin(theta)*np.sin(phi),-np.sin(theta)*np.cos(phi),np.cos(theta)]])\n",
    "    return np.concatenate((np.dot(xyz,matrix) *10 , rest),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:01<00:00, 37302.65it/s]\n"
     ]
    }
   ],
   "source": [
    "frames = all_frames\n",
    "features = []\n",
    "for molecule in tqdm(frames):\n",
    "    atomic_nums = np.array([[atom.element.atomic_number for atom in molecule.top.atoms]]).T\n",
    "    vdwr = np.array([[atom.element.radius for atom in molecule.top.atoms]]).T\n",
    "    mass = np.array([[atom.element.mass for atom in molecule.top.atoms]]).T\n",
    "    positions = molecule.xyz[0]*10\n",
    "    \n",
    "    # positions = positions - positions[0]\n",
    "    \n",
    "    node_features = np.concatenate((positions,vdwr,atomic_nums),axis=1)\n",
    "    features.append(node_features)\n",
    "    \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfFrEF-W5vpx",
    "outputId": "4187ae4a-503a-4cef-ccc1-b5e557719f05"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # atomic Number\n",
    "# atomic_nums = np.array([[atom.element.atomic_number for atom in molecule.top.atoms]]).T\n",
    "\n",
    "# # Vander wall Radii\n",
    "# vdwr = np.array([[atom.element.radius for atom in molecule.top.atoms]]).T\n",
    "\n",
    "# # Atomic Mass \n",
    "# mass = np.array([[atom.element.mass for atom in molecule.top.atoms]]).T\n",
    "\n",
    "# atom_type = np.array([[2,1,1,0]]).T\n",
    "\n",
    "# # Relative position of atoms on one molecule\n",
    "# poitions = molecule.xyz[0]*10\n",
    "# # calculate weighted average of the positions of the atoms in the molecule\n",
    "# com = np.average(poitions, axis=0, weights=mass.T[0])\n",
    "# # relative position of atoms in the molecule\n",
    "\n",
    "# relative_pos = poitions-com\n",
    "\n",
    "\n",
    "# print(\"Absolute positions:\\n\",poitions)\n",
    "# print(\"\\nRelative positions:\\n\",relative_pos)\n",
    "# print(\"\\natomic_numbers:\\n\",atomic_nums)\n",
    "# print(\"\\nVander wall Radii:\\n\", vdwr)\n",
    "# print(\"\\nAtomic Mass:\\n\",mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wsal5pY3rTDA",
    "outputId": "c52d834d-061e-4913-c825-e9ab07d2ecfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features:\n",
      " [[13.46083832 12.57285213 13.48372459  0.152       8.        ]\n",
      " [13.04025745 13.2220211  14.04757309  0.12        1.        ]\n",
      " [12.84028053 12.43922329 12.76728725  0.12        1.        ]\n",
      " [13.34977245 12.62784863 13.46744633  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# node_features = np.concatenate((relative_pos,vdwr,atomic_nums),axis=1)\n",
    "print(\"Node Features:\\n\",features[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VQ0Tk6jn_Eug"
   },
   "outputs": [],
   "source": [
    "from_list = []\n",
    "to_list = []\n",
    "for edge in all_frames.topology.bonds:\n",
    "    from_list.append(edge.atom1.index)\n",
    "    to_list.append(edge.atom2.index)\n",
    "    from_list.append(edge.atom2.index)\n",
    "    to_list.append(edge.atom1.index)\n",
    "\n",
    "edge_list = np.array([from_list,to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adj(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max() + 1\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    return adj\n",
    "\n",
    "def convert_to_edge_index(adj):\n",
    "    edge_index = adj.nonzero().t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2e7qnLIQaisN"
   },
   "outputs": [],
   "source": [
    "graphs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 51225.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for node_feature in tqdm(features):\n",
    "    graph = data.Data(x=torch.from_numpy(node_feature),edge_index=torch.from_numpy(edge_list))\n",
    "    graphs.append(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = []\n",
    "# real_node_features = []\n",
    "\n",
    "# for i in range(n_graphs):\n",
    "#     rotated = rotate3D(node_features,np.random.uniform(0,2*np.pi),np.random.uniform(0,2*np.pi),np.random.uniform(0,2*np.pi))\n",
    "#     noisy_node_features = rotated + np.random.normal(0,0.1,rotated.shape)\n",
    "\n",
    "#     all_features.append(noisy_node_features)\n",
    "#     real_node_features.append(rotated)\n",
    "\n",
    "# all_features = np.array(all_features)    \n",
    "# real_node_features = np.array(real_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed Scaling/normalization\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(all_features.reshape(-1,1))\n",
    "# normalized_node_features = scaler.transform(all_features.reshape(-1,1)).reshape(all_features.shape)\n",
    "\n",
    "# normalized_real_node_features = scaler.transform(real_node_features.reshape(-1,1)).reshape(real_node_features.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in zip(normalized_node_features,normalized_real_node_features):\n",
    "#     graph = data.Data(x=torch.from_numpy(x),edge_index=torch.from_numpy(edge_list),y=torch.from_numpy(y))\n",
    "#     graphs.append(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 5], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis = to_networkx(graphs[0])\n",
    "nx.draw_networkx(vis, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple \n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "EPS = 1e-15\n",
    "MAX_LOGSTD = 10\n",
    "\n",
    "\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    r\"\"\"The inner product decoder from the `\"Variational Graph Auto-Encoders\"\n",
    "    <https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})\n",
    "\n",
    "    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent\n",
    "    space produced by the encoder.\"\"\"\n",
    "\n",
    "    def forward(self, z: Tensor, edge_index: Tensor,\n",
    "                sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into edge probabilities for\n",
    "        the given node-pairs :obj:`edge_index`.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z: Tensor, sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    r\"\"\"The Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper based on user-defined encoder and decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\n",
    "        GAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        reset(self.encoder)\n",
    "        reset(self.decoder)\n",
    "\n",
    "    def forward(self, *args, **kwargs) -> Tensor:  # pragma: no cover\n",
    "        r\"\"\"Alias for :meth:`encode`.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the decoder and computes edge probabilities.\"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "\n",
    "    def recon_loss(self, z: Tensor, pos_edge_index: Tensor,\n",
    "                   neg_edge_index: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to train against.\n",
    "            neg_edge_index (torch.Tensor, optional): The negative edges to\n",
    "                train against. If not given, uses negative sampling to\n",
    "                calculate negative edges. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True)[0] + EPS).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 -\n",
    "                              self.decoder(z, neg_edge_index.long(), sigmoid=True)[0] +\n",
    "                              EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def test(self, z: Tensor, pos_edge_index: Tensor,\n",
    "             neg_edge_index: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"Given latent variables :obj:`z`, positive edges\n",
    "        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,\n",
    "        computes area under the ROC curve (AUC) and average precision (AP)\n",
    "        \n",
    "        scores.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to evaluate\n",
    "                against.\n",
    "            neg_edge_index (torch.Tensor): The negative edges to evaluate\n",
    "                against.\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n",
    "\n",
    "\n",
    "class VGAE(GAE):\n",
    "    r\"\"\"The Variational Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module to compute :math:`\\mu`\n",
    "            and :math:`\\log\\sigma^2`.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__(encoder, decoder)\n",
    "\n",
    "    def reparametrize(self, mu: Tensor, logstd: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        self.__mu__, self.__logstd__, self.edge_index = self.encoder(\n",
    "            *args, **kwargs)\n",
    "        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)\n",
    "        z = self.reparametrize(self.__mu__, self.__logstd__)\n",
    "        return z, self.edge_index\n",
    "\n",
    "    def kl_loss(self, mu: Optional[Tensor] = None,\n",
    "                logstd: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logstd`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor, optional): The latent space for :math:`\\mu`. If\n",
    "                set to :obj:`None`, uses the last computation of :math:`\\mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logstd (torch.Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logstd = self.__logstd__ if logstd is None else logstd.clamp(\n",
    "            max=MAX_LOGSTD)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 133179.27it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graphs_device = []\n",
    "for graph in tqdm(graphs):\n",
    "    graphs_device.append(graph.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "K1H_72HfZhHF"
   },
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,batch_size,n_atoms):\n",
    "        \n",
    "        self.embedding_size1 = 15\n",
    "        self.embedding_size2 = 9\n",
    "        self.linear_size1 = 100\n",
    "        self.linear_size2 = 4\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.n_atoms = n_atoms\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(self.in_channels,self.embedding_size1,heads=3)\n",
    "        self.head_transform1 = Linear(self.embedding_size1*3, self.embedding_size1)\n",
    "        self.bn1 = BatchNorm(self.embedding_size1)\n",
    "        \n",
    "        self.conv2 = GCNConv(self.embedding_size1,self.embedding_size2)\n",
    "        self.bn2 = BatchNorm(self.embedding_size2)\n",
    "        \n",
    "        self.linear1 = Linear(self.embedding_size2, self.linear_size1)\n",
    "        self.linear2 = Linear(self.linear_size1,self.linear_size2)\n",
    "        \n",
    "        self.transform = Linear(self.linear_size2*self.n_atoms,self.out_channels)\n",
    "        \n",
    "        self.mu = Linear(self.out_channels, self.out_channels)\n",
    "        self.logstd = Linear(self.out_channels, self.out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        self.batch_size = x.shape[0]//self.n_atoms\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.head_transform1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = x.reshape(self.batch_size,self.n_atoms,-1)\n",
    "        x = x.reshape(self.batch_size,-1)\n",
    "        \n",
    "        x = self.transform(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        \n",
    "        x,y,z = self.mu(x), self.logstd(x), edge_index\n",
    "        return x,y,z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNDecoder(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,batch_size,n_atoms):\n",
    "        self.embedding_size1 = 9\n",
    "        self.embedding_size2 = 3\n",
    "        self.embedding_size3 = 3\n",
    "        self.linear_size1 = 512\n",
    "        self.linear_size2 = 128\n",
    "        self.batch_size = batch_size\n",
    "        self.n_atoms = n_atoms\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        super().__init__()\n",
    "        self.inv_transform = Linear(self.in_channels,self.n_atoms) \n",
    "        \n",
    "        self.conv1 = GCNConv(1, self.embedding_size1)\n",
    "        self.bn1 = BatchNorm(self.embedding_size1)\n",
    "\n",
    "        self.conv2 = GCNConv(self.embedding_size1,self.embedding_size2)\n",
    "        self.bn2 = BatchNorm(self.embedding_size2)\n",
    "\n",
    "        self.conv3 = GCNConv(self.embedding_size2,self.embedding_size3)\n",
    "\n",
    "        self.linear1 = Linear(self.embedding_size3, self.linear_size1)\n",
    "        self.linear2 = Linear(self.linear_size1, self.linear_size2)\n",
    "        self.linear3 = Linear(self.linear_size2, self.out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, sigmoid=True):\n",
    "        self.batch_size = x.shape[0]//self.n_atoms\n",
    "\n",
    "        x = self.inv_transform(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0]*x.shape[1],1)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)        \n",
    "        x = self.conv3(x,edge_index)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        \n",
    "        return x, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vu-V-Dsc1D_B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "in_channels = graph.num_features\n",
    "out_channels = 3\n",
    "n_atoms = 4\n",
    "lr = 1e-3\n",
    "n_epochs = 500\n",
    "batch_size=256\n",
    "test_train_split = 0.8\n",
    "model_name = \"IntraGVAE_l3_final.pt\"\n",
    "model_loaded = False\n",
    "force_train = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if os.path.exists(\"./models/\"+model_name) and not force_train:\n",
    "    model = torch.load(\"./models/\"+model_name)\n",
    "    model_loaded = True\n",
    "else:\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels,batch_size,n_atoms),\n",
    "                VariationalGCNDecoder(out_channels, in_channels,batch_size,n_atoms))\n",
    "    \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hqwvxYdccl4g"
   },
   "outputs": [],
   "source": [
    "split = int(test_train_split * len(graphs_device))\n",
    "train_loader = DataLoader(graphs_device[:split], batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(graphs_device[split:], batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n",
      "total_graphs: 50001\n",
      "Graphs in a batch: 256\n",
      "Train Graphs Batches: 157 (Total graphs: 40192)\n",
      "Test Graphs Batches: 40 (Total graphs: 10240)\n",
      "Model Specifics:\n",
      " VGAE(\n",
      "  (encoder): VariationalGCNEncoder(\n",
      "    (conv1): GATConv(5, 15, heads=3)\n",
      "    (head_transform1): Linear(45, 15, bias=True)\n",
      "    (bn1): BatchNorm(15)\n",
      "    (conv2): GCNConv(15, 9)\n",
      "    (bn2): BatchNorm(9)\n",
      "    (linear1): Linear(9, 100, bias=True)\n",
      "    (linear2): Linear(100, 4, bias=True)\n",
      "    (transform): Linear(16, 3, bias=True)\n",
      "    (mu): Linear(3, 3, bias=True)\n",
      "    (logstd): Linear(3, 3, bias=True)\n",
      "  )\n",
      "  (decoder): VariationalGCNDecoder(\n",
      "    (inv_transform): Linear(3, 4, bias=True)\n",
      "    (conv1): GCNConv(1, 9)\n",
      "    (bn1): BatchNorm(9)\n",
      "    (conv2): GCNConv(9, 3)\n",
      "    (bn2): BatchNorm(3)\n",
      "    (conv3): GCNConv(3, 3)\n",
      "    (linear1): Linear(3, 512, bias=True)\n",
      "    (linear2): Linear(512, 128, bias=True)\n",
      "    (linear3): Linear(128, 5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Using:\",device )\n",
    "print(\"total_graphs:\", len(graphs_device))\n",
    "print(\"Graphs in a batch:\", batch_size)\n",
    "print(\"Train Graphs Batches:\",len(train_loader),f\"(Total graphs: {len(train_loader)*batch_size})\")\n",
    "print(\"Test Graphs Batches:\",len(test_loader),f\"(Total graphs: {len(test_loader)*batch_size})\")\n",
    "print(\"Model Specifics:\\n\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PSlEaKJOczEn"
   },
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    model.double()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "     \n",
    "        \n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "\n",
    "\n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "\n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "#         positionLoss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / len(train_loader), feature_loss_all / len(train_loader), edge_loss_all / len(train_loader) ,position_loss_all / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.double()\n",
    "    \n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "        \n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "   \n",
    "        \n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        \n",
    "        \n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "\n",
    "\n",
    "    return loss_all / len(test_loader), feature_loss_all / len(test_loader), edge_loss_all / len(test_loader), position_loss_all / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9117KpSc9uP",
    "outputId": "eae0f70e-c05e-42fe-a20c-477e5cab54fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001\n",
      "\tTrain:\tTotal Loss: 10.4764, Feature Loss: 2.5297, Position Loss: 15.7743, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9539, Feature Loss: 0.0591, Position Loss: 3.2171, LR: 0.001000\n",
      "Epoch: 002\n",
      "\tTrain:\tTotal Loss: 0.5150, Feature Loss: 0.0574, Position Loss: 0.8201, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0666, Feature Loss: 0.0039, Position Loss: 0.1085, LR: 0.001000\n",
      "Epoch: 003\n",
      "\tTrain:\tTotal Loss: 0.0511, Feature Loss: 0.0025, Position Loss: 0.0835, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0127, Feature Loss: 0.0052, Position Loss: 0.0177, LR: 0.001000\n",
      "Epoch: 004\n",
      "\tTrain:\tTotal Loss: 0.0338, Feature Loss: 0.0036, Position Loss: 0.0539, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0122, Feature Loss: 0.0018, Position Loss: 0.0191, LR: 0.001000\n",
      "Epoch: 005\n",
      "\tTrain:\tTotal Loss: 0.0384, Feature Loss: 0.0043, Position Loss: 0.0612, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.1023, Feature Loss: 0.0139, Position Loss: 0.1611, LR: 0.001000\n",
      "Epoch: 006\n",
      "\tTrain:\tTotal Loss: 0.0388, Feature Loss: 0.0044, Position Loss: 0.0617, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0220, Feature Loss: 0.0003, Position Loss: 0.0365, LR: 0.001000\n",
      "Epoch: 007\n",
      "\tTrain:\tTotal Loss: 0.0404, Feature Loss: 0.0077, Position Loss: 0.0621, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0064, Feature Loss: 0.0010, Position Loss: 0.0100, LR: 0.001000\n",
      "Epoch: 008\n",
      "\tTrain:\tTotal Loss: 0.0336, Feature Loss: 0.0051, Position Loss: 0.0526, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0276, Feature Loss: 0.0281, Position Loss: 0.0272, LR: 0.001000\n",
      "Epoch: 009\n",
      "\tTrain:\tTotal Loss: 0.0280, Feature Loss: 0.0063, Position Loss: 0.0425, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0799, Feature Loss: 0.0027, Position Loss: 0.1314, LR: 0.001000\n",
      "Epoch: 010\n",
      "\tTrain:\tTotal Loss: 0.0301, Feature Loss: 0.0055, Position Loss: 0.0465, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0085, Feature Loss: 0.0080, Position Loss: 0.0088, LR: 0.001000\n",
      "Epoch: 011\n",
      "\tTrain:\tTotal Loss: 0.0388, Feature Loss: 0.0068, Position Loss: 0.0601, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.1031, Feature Loss: 0.0019, Position Loss: 0.1705, LR: 0.001000\n",
      "Epoch: 012\n",
      "\tTrain:\tTotal Loss: 0.0294, Feature Loss: 0.0043, Position Loss: 0.0461, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0007, Position Loss: 0.0022, LR: 0.001000\n",
      "Epoch: 013\n",
      "\tTrain:\tTotal Loss: 0.0298, Feature Loss: 0.0033, Position Loss: 0.0475, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0056, Feature Loss: 0.0002, Position Loss: 0.0091, LR: 0.001000\n",
      "Epoch: 014\n",
      "\tTrain:\tTotal Loss: 0.0504, Feature Loss: 0.0127, Position Loss: 0.0755, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0044, Feature Loss: 0.0008, Position Loss: 0.0068, LR: 0.001000\n",
      "Epoch: 015\n",
      "\tTrain:\tTotal Loss: 0.0468, Feature Loss: 0.0114, Position Loss: 0.0703, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0461, Feature Loss: 0.0049, Position Loss: 0.0736, LR: 0.001000\n",
      "Epoch: 016\n",
      "\tTrain:\tTotal Loss: 0.0267, Feature Loss: 0.0031, Position Loss: 0.0425, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0032, Feature Loss: 0.0031, Position Loss: 0.0033, LR: 0.001000\n",
      "Epoch: 017\n",
      "\tTrain:\tTotal Loss: 0.0343, Feature Loss: 0.0108, Position Loss: 0.0499, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0073, Feature Loss: 0.0110, Position Loss: 0.0048, LR: 0.001000\n",
      "Epoch: 018\n",
      "\tTrain:\tTotal Loss: 0.0407, Feature Loss: 0.0103, Position Loss: 0.0609, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0114, Feature Loss: 0.0136, Position Loss: 0.0100, LR: 0.001000\n",
      "Epoch: 019\n",
      "\tTrain:\tTotal Loss: 0.0367, Feature Loss: 0.0088, Position Loss: 0.0553, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0482, Feature Loss: 0.0419, Position Loss: 0.0524, LR: 0.001000\n",
      "Epoch: 020\n",
      "\tTrain:\tTotal Loss: 0.0396, Feature Loss: 0.0121, Position Loss: 0.0580, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0066, Feature Loss: 0.0045, Position Loss: 0.0080, LR: 0.001000\n",
      "Epoch: 021\n",
      "\tTrain:\tTotal Loss: 0.0275, Feature Loss: 0.0043, Position Loss: 0.0430, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0120, Feature Loss: 0.0059, Position Loss: 0.0161, LR: 0.001000\n",
      "Epoch: 022\n",
      "\tTrain:\tTotal Loss: 0.0332, Feature Loss: 0.0070, Position Loss: 0.0507, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0103, Feature Loss: 0.0052, Position Loss: 0.0137, LR: 0.001000\n",
      "Epoch: 023\n",
      "\tTrain:\tTotal Loss: 0.0425, Feature Loss: 0.0110, Position Loss: 0.0635, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0063, Feature Loss: 0.0001, Position Loss: 0.0105, LR: 0.001000\n",
      "Epoch: 024\n",
      "\tTrain:\tTotal Loss: 0.0415, Feature Loss: 0.0083, Position Loss: 0.0636, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0077, Feature Loss: 0.0010, Position Loss: 0.0121, LR: 0.001000\n",
      "Epoch: 025\n",
      "\tTrain:\tTotal Loss: 0.0362, Feature Loss: 0.0082, Position Loss: 0.0549, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0025, LR: 0.001000\n",
      "Epoch: 026\n",
      "\tTrain:\tTotal Loss: 0.0416, Feature Loss: 0.0113, Position Loss: 0.0617, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0690, Feature Loss: 0.0417, Position Loss: 0.0873, LR: 0.001000\n",
      "Epoch: 027\n",
      "\tTrain:\tTotal Loss: 0.0404, Feature Loss: 0.0115, Position Loss: 0.0597, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0865, Feature Loss: 0.0514, Position Loss: 0.1099, LR: 0.001000\n",
      "Epoch: 028\n",
      "\tTrain:\tTotal Loss: 0.0313, Feature Loss: 0.0054, Position Loss: 0.0486, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0046, Feature Loss: 0.0001, Position Loss: 0.0075, LR: 0.001000\n",
      "Epoch: 029\n",
      "\tTrain:\tTotal Loss: 0.0289, Feature Loss: 0.0056, Position Loss: 0.0444, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0043, Feature Loss: 0.0004, Position Loss: 0.0069, LR: 0.001000\n",
      "Epoch: 030\n",
      "\tTrain:\tTotal Loss: 0.0340, Feature Loss: 0.0097, Position Loss: 0.0502, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0015, Position Loss: 0.0024, LR: 0.001000\n",
      "Epoch: 031\n",
      "\tTrain:\tTotal Loss: 0.0267, Feature Loss: 0.0042, Position Loss: 0.0416, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0064, Feature Loss: 0.0039, Position Loss: 0.0081, LR: 0.001000\n",
      "Epoch: 032\n",
      "\tTrain:\tTotal Loss: 0.0397, Feature Loss: 0.0096, Position Loss: 0.0597, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0003, Position Loss: 0.0062, LR: 0.001000\n",
      "Epoch: 033\n",
      "\tTrain:\tTotal Loss: 0.0453, Feature Loss: 0.0127, Position Loss: 0.0669, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0227, Feature Loss: 0.0003, Position Loss: 0.0376, LR: 0.001000\n",
      "Epoch: 034\n",
      "\tTrain:\tTotal Loss: 0.0395, Feature Loss: 0.0097, Position Loss: 0.0593, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0028, Position Loss: 0.0033, LR: 0.001000\n",
      "Epoch: 035\n",
      "\tTrain:\tTotal Loss: 0.0320, Feature Loss: 0.0039, Position Loss: 0.0507, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0057, Feature Loss: 0.0005, Position Loss: 0.0093, LR: 0.001000\n",
      "Epoch: 036\n",
      "\tTrain:\tTotal Loss: 0.0399, Feature Loss: 0.0086, Position Loss: 0.0608, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0228, Feature Loss: 0.0169, Position Loss: 0.0268, LR: 0.001000\n",
      "Epoch: 037\n",
      "\tTrain:\tTotal Loss: 0.0359, Feature Loss: 0.0053, Position Loss: 0.0563, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0083, Feature Loss: 0.0015, Position Loss: 0.0128, LR: 0.001000\n",
      "Epoch: 038\n",
      "\tTrain:\tTotal Loss: 0.0424, Feature Loss: 0.0116, Position Loss: 0.0629, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0355, Feature Loss: 0.0132, Position Loss: 0.0503, LR: 0.001000\n",
      "Epoch: 039\n",
      "\tTrain:\tTotal Loss: 0.0394, Feature Loss: 0.0099, Position Loss: 0.0591, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0454, Feature Loss: 0.0203, Position Loss: 0.0621, LR: 0.001000\n",
      "Epoch: 040\n",
      "\tTrain:\tTotal Loss: 0.0396, Feature Loss: 0.0107, Position Loss: 0.0588, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0056, Feature Loss: 0.0070, Position Loss: 0.0046, LR: 0.001000\n",
      "Epoch: 041\n",
      "\tTrain:\tTotal Loss: 0.0405, Feature Loss: 0.0113, Position Loss: 0.0600, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0229, Feature Loss: 0.0030, Position Loss: 0.0362, LR: 0.001000\n",
      "Epoch: 042\n",
      "\tTrain:\tTotal Loss: 0.0389, Feature Loss: 0.0072, Position Loss: 0.0601, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0125, Feature Loss: 0.0025, Position Loss: 0.0192, LR: 0.001000\n",
      "Epoch: 043\n",
      "\tTrain:\tTotal Loss: 0.0342, Feature Loss: 0.0058, Position Loss: 0.0531, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0010, Position Loss: 0.0037, LR: 0.001000\n",
      "Epoch: 044\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0081, Position Loss: 0.0504, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0179, Feature Loss: 0.0090, Position Loss: 0.0238, LR: 0.001000\n",
      "Epoch: 045\n",
      "\tTrain:\tTotal Loss: 0.0342, Feature Loss: 0.0073, Position Loss: 0.0521, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0174, Feature Loss: 0.0140, Position Loss: 0.0197, LR: 0.001000\n",
      "Epoch: 046\n",
      "\tTrain:\tTotal Loss: 0.0480, Feature Loss: 0.0127, Position Loss: 0.0716, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0198, Feature Loss: 0.0006, Position Loss: 0.0326, LR: 0.001000\n",
      "Epoch: 047\n",
      "\tTrain:\tTotal Loss: 0.0370, Feature Loss: 0.0087, Position Loss: 0.0559, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0086, Feature Loss: 0.0027, Position Loss: 0.0125, LR: 0.001000\n",
      "Epoch: 048\n",
      "\tTrain:\tTotal Loss: 0.0393, Feature Loss: 0.0062, Position Loss: 0.0613, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0088, Feature Loss: 0.0158, Position Loss: 0.0040, LR: 0.001000\n",
      "Epoch: 049\n",
      "\tTrain:\tTotal Loss: 0.0352, Feature Loss: 0.0098, Position Loss: 0.0521, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0118, Feature Loss: 0.0056, Position Loss: 0.0159, LR: 0.001000\n",
      "Epoch: 050\n",
      "\tTrain:\tTotal Loss: 0.0374, Feature Loss: 0.0064, Position Loss: 0.0580, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0004, Position Loss: 0.0031, LR: 0.001000\n",
      "Epoch: 051\n",
      "\tTrain:\tTotal Loss: 0.0338, Feature Loss: 0.0049, Position Loss: 0.0531, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0302, Feature Loss: 0.0223, Position Loss: 0.0354, LR: 0.001000\n",
      "Epoch: 052\n",
      "\tTrain:\tTotal Loss: 0.0379, Feature Loss: 0.0093, Position Loss: 0.0570, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0145, Feature Loss: 0.0108, Position Loss: 0.0170, LR: 0.001000\n",
      "Epoch: 053\n",
      "\tTrain:\tTotal Loss: 0.0366, Feature Loss: 0.0061, Position Loss: 0.0569, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0224, Feature Loss: 0.0150, Position Loss: 0.0274, LR: 0.001000\n",
      "Epoch: 054\n",
      "\tTrain:\tTotal Loss: 0.0309, Feature Loss: 0.0040, Position Loss: 0.0488, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0066, Feature Loss: 0.0022, Position Loss: 0.0095, LR: 0.001000\n",
      "Epoch: 055\n",
      "\tTrain:\tTotal Loss: 0.0356, Feature Loss: 0.0059, Position Loss: 0.0553, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0413, Feature Loss: 0.0376, Position Loss: 0.0437, LR: 0.001000\n",
      "Epoch: 056\n",
      "\tTrain:\tTotal Loss: 0.0415, Feature Loss: 0.0164, Position Loss: 0.0581, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0042, Feature Loss: 0.0058, Position Loss: 0.0031, LR: 0.001000\n",
      "Epoch: 057\n",
      "\tTrain:\tTotal Loss: 0.0284, Feature Loss: 0.0074, Position Loss: 0.0424, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0486, Feature Loss: 0.0116, Position Loss: 0.0734, LR: 0.001000\n",
      "Epoch: 058\n",
      "\tTrain:\tTotal Loss: 0.0585, Feature Loss: 0.0109, Position Loss: 0.0902, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0001, Position Loss: 0.0023, LR: 0.001000\n",
      "Epoch: 059\n",
      "\tTrain:\tTotal Loss: 0.0369, Feature Loss: 0.0083, Position Loss: 0.0559, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0179, Feature Loss: 0.0149, Position Loss: 0.0200, LR: 0.001000\n",
      "Epoch: 060\n",
      "\tTrain:\tTotal Loss: 0.0235, Feature Loss: 0.0031, Position Loss: 0.0372, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0064, Feature Loss: 0.0025, Position Loss: 0.0090, LR: 0.001000\n",
      "Epoch: 061\n",
      "\tTrain:\tTotal Loss: 0.0410, Feature Loss: 0.0093, Position Loss: 0.0622, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0029, Position Loss: 0.0019, LR: 0.001000\n",
      "Epoch: 062\n",
      "\tTrain:\tTotal Loss: 0.0308, Feature Loss: 0.0058, Position Loss: 0.0475, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0016, Position Loss: 0.0031, LR: 0.001000\n",
      "Epoch: 063\n",
      "\tTrain:\tTotal Loss: 0.0294, Feature Loss: 0.0063, Position Loss: 0.0448, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0033, Feature Loss: 0.0005, Position Loss: 0.0051, LR: 0.001000\n",
      "Epoch: 064\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0051, Position Loss: 0.0523, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0413, Feature Loss: 0.0155, Position Loss: 0.0584, LR: 0.001000\n",
      "Epoch: 065\n",
      "\tTrain:\tTotal Loss: 0.0327, Feature Loss: 0.0056, Position Loss: 0.0508, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0042, Feature Loss: 0.0007, Position Loss: 0.0066, LR: 0.001000\n",
      "Epoch: 066\n",
      "\tTrain:\tTotal Loss: 0.0302, Feature Loss: 0.0077, Position Loss: 0.0451, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0033, Feature Loss: 0.0031, Position Loss: 0.0034, LR: 0.001000\n",
      "Epoch: 067\n",
      "\tTrain:\tTotal Loss: 0.0348, Feature Loss: 0.0058, Position Loss: 0.0541, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0021, Position Loss: 0.0049, LR: 0.001000\n",
      "Epoch: 068\n",
      "\tTrain:\tTotal Loss: 0.0318, Feature Loss: 0.0063, Position Loss: 0.0489, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0337, Feature Loss: 0.0104, Position Loss: 0.0493, LR: 0.001000\n",
      "Epoch: 069\n",
      "\tTrain:\tTotal Loss: 0.0355, Feature Loss: 0.0147, Position Loss: 0.0494, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0062, Feature Loss: 0.0044, Position Loss: 0.0074, LR: 0.001000\n",
      "Epoch: 070\n",
      "\tTrain:\tTotal Loss: 0.0398, Feature Loss: 0.0062, Position Loss: 0.0622, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0115, Feature Loss: 0.0003, Position Loss: 0.0190, LR: 0.001000\n",
      "Epoch: 071\n",
      "\tTrain:\tTotal Loss: 0.0378, Feature Loss: 0.0073, Position Loss: 0.0581, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0008, Position Loss: 0.0026, LR: 0.001000\n",
      "Epoch: 072\n",
      "\tTrain:\tTotal Loss: 0.0318, Feature Loss: 0.0046, Position Loss: 0.0500, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0158, Feature Loss: 0.0079, Position Loss: 0.0210, LR: 0.001000\n",
      "Epoch: 073\n",
      "\tTrain:\tTotal Loss: 0.0284, Feature Loss: 0.0043, Position Loss: 0.0445, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0087, Feature Loss: 0.0098, Position Loss: 0.0080, LR: 0.001000\n",
      "Epoch: 074\n",
      "\tTrain:\tTotal Loss: 0.0357, Feature Loss: 0.0073, Position Loss: 0.0547, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0243, Feature Loss: 0.0007, Position Loss: 0.0401, LR: 0.001000\n",
      "Epoch: 075\n",
      "\tTrain:\tTotal Loss: 0.0349, Feature Loss: 0.0065, Position Loss: 0.0539, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0035, Feature Loss: 0.0034, Position Loss: 0.0035, LR: 0.001000\n",
      "Epoch: 076\n",
      "\tTrain:\tTotal Loss: 0.0438, Feature Loss: 0.0095, Position Loss: 0.0667, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0097, Feature Loss: 0.0022, Position Loss: 0.0148, LR: 0.001000\n",
      "Epoch: 077\n",
      "\tTrain:\tTotal Loss: 0.0243, Feature Loss: 0.0039, Position Loss: 0.0379, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0066, Feature Loss: 0.0037, Position Loss: 0.0084, LR: 0.001000\n",
      "Epoch: 078\n",
      "\tTrain:\tTotal Loss: 0.0356, Feature Loss: 0.0076, Position Loss: 0.0543, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0107, Feature Loss: 0.0031, Position Loss: 0.0158, LR: 0.001000\n",
      "Epoch: 079\n",
      "\tTrain:\tTotal Loss: 0.0315, Feature Loss: 0.0057, Position Loss: 0.0487, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0044, Feature Loss: 0.0011, Position Loss: 0.0067, LR: 0.001000\n",
      "Epoch: 080\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0070, Position Loss: 0.0511, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0172, Feature Loss: 0.0099, Position Loss: 0.0220, LR: 0.001000\n",
      "Epoch: 081\n",
      "\tTrain:\tTotal Loss: 0.0342, Feature Loss: 0.0077, Position Loss: 0.0518, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0058, Feature Loss: 0.0008, Position Loss: 0.0091, LR: 0.001000\n",
      "Epoch: 082\n",
      "\tTrain:\tTotal Loss: 0.0332, Feature Loss: 0.0074, Position Loss: 0.0505, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0191, Feature Loss: 0.0008, Position Loss: 0.0312, LR: 0.001000\n",
      "Epoch: 083\n",
      "\tTrain:\tTotal Loss: 0.0362, Feature Loss: 0.0090, Position Loss: 0.0543, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0171, Feature Loss: 0.0005, Position Loss: 0.0281, LR: 0.001000\n",
      "Epoch: 084\n",
      "\tTrain:\tTotal Loss: 0.0310, Feature Loss: 0.0055, Position Loss: 0.0479, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0043, Feature Loss: 0.0044, Position Loss: 0.0042, LR: 0.001000\n",
      "Epoch: 085\n",
      "\tTrain:\tTotal Loss: 0.0331, Feature Loss: 0.0068, Position Loss: 0.0506, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0007, Position Loss: 0.0037, LR: 0.001000\n",
      "Epoch: 086\n",
      "\tTrain:\tTotal Loss: 0.0393, Feature Loss: 0.0075, Position Loss: 0.0605, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0166, Feature Loss: 0.0041, Position Loss: 0.0250, LR: 0.001000\n",
      "Epoch: 087\n",
      "\tTrain:\tTotal Loss: 0.0461, Feature Loss: 0.0086, Position Loss: 0.0710, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0319, Feature Loss: 0.0014, Position Loss: 0.0522, LR: 0.001000\n",
      "Epoch: 088\n",
      "\tTrain:\tTotal Loss: 0.0420, Feature Loss: 0.0091, Position Loss: 0.0639, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0135, Feature Loss: 0.0177, Position Loss: 0.0106, LR: 0.001000\n",
      "Epoch: 089\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0064, Position Loss: 0.0516, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0045, Feature Loss: 0.0010, Position Loss: 0.0069, LR: 0.001000\n",
      "Epoch: 090\n",
      "\tTrain:\tTotal Loss: 0.0353, Feature Loss: 0.0054, Position Loss: 0.0553, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0056, Feature Loss: 0.0014, Position Loss: 0.0084, LR: 0.001000\n",
      "Epoch: 091\n",
      "\tTrain:\tTotal Loss: 0.0295, Feature Loss: 0.0052, Position Loss: 0.0456, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0251, Feature Loss: 0.0213, Position Loss: 0.0277, LR: 0.001000\n",
      "Epoch: 092\n",
      "\tTrain:\tTotal Loss: 0.0431, Feature Loss: 0.0126, Position Loss: 0.0634, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0072, Feature Loss: 0.0002, Position Loss: 0.0119, LR: 0.001000\n",
      "Epoch: 093\n",
      "\tTrain:\tTotal Loss: 0.0355, Feature Loss: 0.0080, Position Loss: 0.0539, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0077, Feature Loss: 0.0004, Position Loss: 0.0126, LR: 0.001000\n",
      "Epoch: 094\n",
      "\tTrain:\tTotal Loss: 0.0374, Feature Loss: 0.0073, Position Loss: 0.0575, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0471, Feature Loss: 0.0025, Position Loss: 0.0768, LR: 0.001000\n",
      "Epoch: 095\n",
      "\tTrain:\tTotal Loss: 0.0419, Feature Loss: 0.0091, Position Loss: 0.0637, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0438, Feature Loss: 0.0137, Position Loss: 0.0639, LR: 0.001000\n",
      "Epoch: 096\n",
      "\tTrain:\tTotal Loss: 0.0319, Feature Loss: 0.0042, Position Loss: 0.0504, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0056, Feature Loss: 0.0003, Position Loss: 0.0092, LR: 0.001000\n",
      "Epoch: 097\n",
      "\tTrain:\tTotal Loss: 0.0304, Feature Loss: 0.0063, Position Loss: 0.0464, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0014, Position Loss: 0.0041, LR: 0.001000\n",
      "Epoch: 098\n",
      "\tTrain:\tTotal Loss: 0.0332, Feature Loss: 0.0051, Position Loss: 0.0519, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0202, Feature Loss: 0.0003, Position Loss: 0.0336, LR: 0.001000\n",
      "Epoch: 099\n",
      "\tTrain:\tTotal Loss: 0.0368, Feature Loss: 0.0056, Position Loss: 0.0576, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0041, Feature Loss: 0.0018, Position Loss: 0.0055, LR: 0.001000\n",
      "Epoch: 100\n",
      "\tTrain:\tTotal Loss: 0.0242, Feature Loss: 0.0020, Position Loss: 0.0390, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0108, Feature Loss: 0.0092, Position Loss: 0.0120, LR: 0.001000\n",
      "Epoch: 101\n",
      "\tTrain:\tTotal Loss: 0.0340, Feature Loss: 0.0062, Position Loss: 0.0525, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.1152, Feature Loss: 0.0242, Position Loss: 0.1758, LR: 0.001000\n",
      "Epoch: 102\n",
      "\tTrain:\tTotal Loss: 0.0394, Feature Loss: 0.0075, Position Loss: 0.0606, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0110, Feature Loss: 0.0007, Position Loss: 0.0179, LR: 0.001000\n",
      "Epoch: 103\n",
      "\tTrain:\tTotal Loss: 0.0281, Feature Loss: 0.0069, Position Loss: 0.0423, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0040, Feature Loss: 0.0002, Position Loss: 0.0065, LR: 0.001000\n",
      "Epoch: 104\n",
      "\tTrain:\tTotal Loss: 0.0317, Feature Loss: 0.0055, Position Loss: 0.0491, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0005, Position Loss: 0.0061, LR: 0.001000\n",
      "Epoch: 105\n",
      "\tTrain:\tTotal Loss: 0.0357, Feature Loss: 0.0057, Position Loss: 0.0557, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0003, Position Loss: 0.0037, LR: 0.001000\n",
      "Epoch: 106\n",
      "\tTrain:\tTotal Loss: 0.0278, Feature Loss: 0.0085, Position Loss: 0.0406, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0049, Feature Loss: 0.0030, Position Loss: 0.0062, LR: 0.001000\n",
      "Epoch: 107\n",
      "\tTrain:\tTotal Loss: 0.0303, Feature Loss: 0.0039, Position Loss: 0.0479, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0688, Feature Loss: 0.0259, Position Loss: 0.0975, LR: 0.001000\n",
      "Epoch: 108\n",
      "\tTrain:\tTotal Loss: 0.0324, Feature Loss: 0.0043, Position Loss: 0.0511, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0254, Feature Loss: 0.0027, Position Loss: 0.0404, LR: 0.001000\n",
      "Epoch: 109\n",
      "\tTrain:\tTotal Loss: 0.0299, Feature Loss: 0.0037, Position Loss: 0.0475, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0479, Feature Loss: 0.0046, Position Loss: 0.0768, LR: 0.001000\n",
      "Epoch: 110\n",
      "\tTrain:\tTotal Loss: 0.0329, Feature Loss: 0.0086, Position Loss: 0.0491, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0204, Feature Loss: 0.0053, Position Loss: 0.0306, LR: 0.001000\n",
      "Epoch: 111\n",
      "\tTrain:\tTotal Loss: 0.0474, Feature Loss: 0.0086, Position Loss: 0.0732, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0186, Feature Loss: 0.0045, Position Loss: 0.0280, LR: 0.001000\n",
      "Epoch: 112\n",
      "\tTrain:\tTotal Loss: 0.0312, Feature Loss: 0.0040, Position Loss: 0.0494, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0197, Feature Loss: 0.0003, Position Loss: 0.0326, LR: 0.001000\n",
      "Epoch: 113\n",
      "\tTrain:\tTotal Loss: 0.0207, Feature Loss: 0.0019, Position Loss: 0.0332, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0094, Feature Loss: 0.0059, Position Loss: 0.0117, LR: 0.001000\n",
      "Epoch: 114\n",
      "\tTrain:\tTotal Loss: 0.0265, Feature Loss: 0.0051, Position Loss: 0.0408, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0058, Feature Loss: 0.0045, Position Loss: 0.0067, LR: 0.001000\n",
      "Epoch: 115\n",
      "\tTrain:\tTotal Loss: 0.0312, Feature Loss: 0.0050, Position Loss: 0.0488, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0081, Feature Loss: 0.0029, Position Loss: 0.0115, LR: 0.001000\n",
      "Epoch: 116\n",
      "\tTrain:\tTotal Loss: 0.0336, Feature Loss: 0.0072, Position Loss: 0.0512, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0050, Feature Loss: 0.0065, Position Loss: 0.0040, LR: 0.001000\n",
      "Epoch: 117\n",
      "\tTrain:\tTotal Loss: 0.0368, Feature Loss: 0.0100, Position Loss: 0.0547, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0120, Feature Loss: 0.0009, Position Loss: 0.0194, LR: 0.001000\n",
      "Epoch: 118\n",
      "\tTrain:\tTotal Loss: 0.0303, Feature Loss: 0.0070, Position Loss: 0.0458, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0195, Feature Loss: 0.0008, Position Loss: 0.0321, LR: 0.001000\n",
      "Epoch: 119\n",
      "\tTrain:\tTotal Loss: 0.0271, Feature Loss: 0.0033, Position Loss: 0.0430, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0065, Feature Loss: 0.0044, Position Loss: 0.0079, LR: 0.001000\n",
      "Epoch: 120\n",
      "\tTrain:\tTotal Loss: 0.0430, Feature Loss: 0.0096, Position Loss: 0.0652, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0102, Feature Loss: 0.0023, Position Loss: 0.0155, LR: 0.001000\n",
      "Epoch: 121\n",
      "\tTrain:\tTotal Loss: 0.0358, Feature Loss: 0.0046, Position Loss: 0.0566, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0321, Feature Loss: 0.0006, Position Loss: 0.0530, LR: 0.001000\n",
      "Epoch: 122\n",
      "\tTrain:\tTotal Loss: 0.0309, Feature Loss: 0.0076, Position Loss: 0.0464, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0007, Position Loss: 0.0033, LR: 0.001000\n",
      "Epoch: 123\n",
      "\tTrain:\tTotal Loss: 0.0264, Feature Loss: 0.0065, Position Loss: 0.0396, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0268, Feature Loss: 0.0088, Position Loss: 0.0388, LR: 0.001000\n",
      "Epoch: 124\n",
      "\tTrain:\tTotal Loss: 0.0310, Feature Loss: 0.0062, Position Loss: 0.0475, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0059, Feature Loss: 0.0001, Position Loss: 0.0099, LR: 0.001000\n",
      "Epoch: 125\n",
      "\tTrain:\tTotal Loss: 0.0334, Feature Loss: 0.0082, Position Loss: 0.0503, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0011, Position Loss: 0.0029, LR: 0.001000\n",
      "Epoch: 126\n",
      "\tTrain:\tTotal Loss: 0.0338, Feature Loss: 0.0055, Position Loss: 0.0526, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0001, Position Loss: 0.0030, LR: 0.001000\n",
      "Epoch: 127\n",
      "\tTrain:\tTotal Loss: 0.0264, Feature Loss: 0.0045, Position Loss: 0.0410, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0392, Feature Loss: 0.0122, Position Loss: 0.0573, LR: 0.001000\n",
      "Epoch: 128\n",
      "\tTrain:\tTotal Loss: 0.0368, Feature Loss: 0.0068, Position Loss: 0.0568, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0010, Position Loss: 0.0045, LR: 0.001000\n",
      "Epoch: 129\n",
      "\tTrain:\tTotal Loss: 0.0277, Feature Loss: 0.0029, Position Loss: 0.0441, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0074, Feature Loss: 0.0001, Position Loss: 0.0122, LR: 0.001000\n",
      "Epoch: 130\n",
      "\tTrain:\tTotal Loss: 0.0409, Feature Loss: 0.0093, Position Loss: 0.0619, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0256, Feature Loss: 0.0092, Position Loss: 0.0365, LR: 0.001000\n",
      "Epoch: 131\n",
      "\tTrain:\tTotal Loss: 0.0300, Feature Loss: 0.0050, Position Loss: 0.0466, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0090, Feature Loss: 0.0016, Position Loss: 0.0140, LR: 0.001000\n",
      "Epoch: 132\n",
      "\tTrain:\tTotal Loss: 0.0300, Feature Loss: 0.0036, Position Loss: 0.0476, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0136, Feature Loss: 0.0070, Position Loss: 0.0180, LR: 0.001000\n",
      "Epoch: 133\n",
      "\tTrain:\tTotal Loss: 0.0284, Feature Loss: 0.0043, Position Loss: 0.0444, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0059, Feature Loss: 0.0001, Position Loss: 0.0097, LR: 0.001000\n",
      "Epoch: 134\n",
      "\tTrain:\tTotal Loss: 0.0314, Feature Loss: 0.0038, Position Loss: 0.0499, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0042, Feature Loss: 0.0012, Position Loss: 0.0062, LR: 0.001000\n",
      "Epoch: 135\n",
      "\tTrain:\tTotal Loss: 0.0298, Feature Loss: 0.0031, Position Loss: 0.0476, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0041, Feature Loss: 0.0000, Position Loss: 0.0068, LR: 0.001000\n",
      "Epoch: 136\n",
      "\tTrain:\tTotal Loss: 0.0323, Feature Loss: 0.0058, Position Loss: 0.0500, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0020, Position Loss: 0.0049, LR: 0.001000\n",
      "Epoch: 137\n",
      "\tTrain:\tTotal Loss: 0.0307, Feature Loss: 0.0034, Position Loss: 0.0490, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0151, Feature Loss: 0.0047, Position Loss: 0.0220, LR: 0.001000\n",
      "Epoch: 138\n",
      "\tTrain:\tTotal Loss: 0.0313, Feature Loss: 0.0062, Position Loss: 0.0480, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0327, Feature Loss: 0.0066, Position Loss: 0.0502, LR: 0.001000\n",
      "Epoch: 139\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0057, Position Loss: 0.0520, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0523, Feature Loss: 0.0154, Position Loss: 0.0768, LR: 0.001000\n",
      "Epoch: 140\n",
      "\tTrain:\tTotal Loss: 0.0369, Feature Loss: 0.0078, Position Loss: 0.0564, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0149, Feature Loss: 0.0049, Position Loss: 0.0216, LR: 0.001000\n",
      "Epoch: 141\n",
      "\tTrain:\tTotal Loss: 0.0206, Feature Loss: 0.0035, Position Loss: 0.0321, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0076, Feature Loss: 0.0001, Position Loss: 0.0126, LR: 0.001000\n",
      "Epoch: 142\n",
      "\tTrain:\tTotal Loss: 0.0291, Feature Loss: 0.0031, Position Loss: 0.0464, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0907, Feature Loss: 0.0257, Position Loss: 0.1339, LR: 0.001000\n",
      "Epoch: 143\n",
      "\tTrain:\tTotal Loss: 0.0299, Feature Loss: 0.0052, Position Loss: 0.0464, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0060, Feature Loss: 0.0046, Position Loss: 0.0070, LR: 0.001000\n",
      "Epoch: 144\n",
      "\tTrain:\tTotal Loss: 0.0271, Feature Loss: 0.0049, Position Loss: 0.0419, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0010, Position Loss: 0.0027, LR: 0.001000\n",
      "Epoch: 145\n",
      "\tTrain:\tTotal Loss: 0.0270, Feature Loss: 0.0064, Position Loss: 0.0406, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0020, Position Loss: 0.0028, LR: 0.001000\n",
      "Epoch: 146\n",
      "\tTrain:\tTotal Loss: 0.0341, Feature Loss: 0.0062, Position Loss: 0.0527, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0082, Feature Loss: 0.0020, Position Loss: 0.0123, LR: 0.001000\n",
      "Epoch: 147\n",
      "\tTrain:\tTotal Loss: 0.0286, Feature Loss: 0.0032, Position Loss: 0.0456, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0686, Feature Loss: 0.0012, Position Loss: 0.1135, LR: 0.001000\n",
      "Epoch: 148\n",
      "\tTrain:\tTotal Loss: 0.0280, Feature Loss: 0.0046, Position Loss: 0.0436, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0003, Position Loss: 0.0041, LR: 0.001000\n",
      "Epoch: 149\n",
      "\tTrain:\tTotal Loss: 0.0330, Feature Loss: 0.0060, Position Loss: 0.0511, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0034, Position Loss: 0.0065, LR: 0.001000\n",
      "Epoch: 150\n",
      "\tTrain:\tTotal Loss: 0.0261, Feature Loss: 0.0067, Position Loss: 0.0390, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0061, Feature Loss: 0.0054, Position Loss: 0.0065, LR: 0.001000\n",
      "Epoch: 151\n",
      "\tTrain:\tTotal Loss: 0.0313, Feature Loss: 0.0036, Position Loss: 0.0498, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0087, Feature Loss: 0.0136, Position Loss: 0.0054, LR: 0.001000\n",
      "Epoch: 152\n",
      "\tTrain:\tTotal Loss: 0.0276, Feature Loss: 0.0059, Position Loss: 0.0421, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0054, Feature Loss: 0.0101, Position Loss: 0.0023, LR: 0.001000\n",
      "Epoch: 153\n",
      "\tTrain:\tTotal Loss: 0.0384, Feature Loss: 0.0063, Position Loss: 0.0597, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0433, Feature Loss: 0.0026, Position Loss: 0.0705, LR: 0.001000\n",
      "Epoch: 154\n",
      "\tTrain:\tTotal Loss: 0.0369, Feature Loss: 0.0048, Position Loss: 0.0582, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0818, Feature Loss: 0.0005, Position Loss: 0.1361, LR: 0.001000\n",
      "Epoch: 155\n",
      "\tTrain:\tTotal Loss: 0.0349, Feature Loss: 0.0067, Position Loss: 0.0537, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0199, Feature Loss: 0.0121, Position Loss: 0.0251, LR: 0.001000\n",
      "Epoch: 156\n",
      "\tTrain:\tTotal Loss: 0.0265, Feature Loss: 0.0039, Position Loss: 0.0416, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0089, Feature Loss: 0.0090, Position Loss: 0.0088, LR: 0.001000\n",
      "Epoch: 157\n",
      "\tTrain:\tTotal Loss: 0.0261, Feature Loss: 0.0036, Position Loss: 0.0411, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0093, Feature Loss: 0.0018, Position Loss: 0.0143, LR: 0.001000\n",
      "Epoch: 158\n",
      "\tTrain:\tTotal Loss: 0.0216, Feature Loss: 0.0020, Position Loss: 0.0347, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0339, Feature Loss: 0.0133, Position Loss: 0.0476, LR: 0.001000\n",
      "Epoch: 159\n",
      "\tTrain:\tTotal Loss: 0.0252, Feature Loss: 0.0035, Position Loss: 0.0397, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0008, Position Loss: 0.0058, LR: 0.001000\n",
      "Epoch: 160\n",
      "\tTrain:\tTotal Loss: 0.0346, Feature Loss: 0.0071, Position Loss: 0.0529, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0011, Position Loss: 0.0027, LR: 0.001000\n",
      "Epoch: 161\n",
      "\tTrain:\tTotal Loss: 0.0334, Feature Loss: 0.0070, Position Loss: 0.0509, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0092, Feature Loss: 0.0002, Position Loss: 0.0152, LR: 0.001000\n",
      "Epoch: 162\n",
      "\tTrain:\tTotal Loss: 0.0321, Feature Loss: 0.0072, Position Loss: 0.0486, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0068, Feature Loss: 0.0007, Position Loss: 0.0110, LR: 0.001000\n",
      "Epoch: 163\n",
      "\tTrain:\tTotal Loss: 0.0315, Feature Loss: 0.0049, Position Loss: 0.0493, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0163, Feature Loss: 0.0001, Position Loss: 0.0271, LR: 0.001000\n",
      "Epoch: 164\n",
      "\tTrain:\tTotal Loss: 0.0437, Feature Loss: 0.0093, Position Loss: 0.0666, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0187, Feature Loss: 0.0200, Position Loss: 0.0178, LR: 0.001000\n",
      "Epoch: 165\n",
      "\tTrain:\tTotal Loss: 0.0241, Feature Loss: 0.0036, Position Loss: 0.0377, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0018, Position Loss: 0.0029, LR: 0.001000\n",
      "Epoch: 166\n",
      "\tTrain:\tTotal Loss: 0.0219, Feature Loss: 0.0032, Position Loss: 0.0343, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0004, Position Loss: 0.0086, LR: 0.001000\n",
      "Epoch: 167\n",
      "\tTrain:\tTotal Loss: 0.0291, Feature Loss: 0.0065, Position Loss: 0.0442, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0044, Feature Loss: 0.0006, Position Loss: 0.0069, LR: 0.001000\n",
      "Epoch: 168\n",
      "\tTrain:\tTotal Loss: 0.0288, Feature Loss: 0.0040, Position Loss: 0.0452, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0161, Feature Loss: 0.0078, Position Loss: 0.0216, LR: 0.001000\n",
      "Epoch: 169\n",
      "\tTrain:\tTotal Loss: 0.0343, Feature Loss: 0.0035, Position Loss: 0.0548, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0409, Feature Loss: 0.0029, Position Loss: 0.0662, LR: 0.001000\n",
      "Epoch: 170\n",
      "\tTrain:\tTotal Loss: 0.0413, Feature Loss: 0.0077, Position Loss: 0.0637, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0047, Feature Loss: 0.0059, Position Loss: 0.0039, LR: 0.001000\n",
      "Epoch: 171\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0063, Position Loss: 0.0516, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0209, Feature Loss: 0.0041, Position Loss: 0.0321, LR: 0.001000\n",
      "Epoch: 172\n",
      "\tTrain:\tTotal Loss: 0.0408, Feature Loss: 0.0072, Position Loss: 0.0631, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0117, Feature Loss: 0.0049, Position Loss: 0.0162, LR: 0.001000\n",
      "Epoch: 173\n",
      "\tTrain:\tTotal Loss: 0.0325, Feature Loss: 0.0050, Position Loss: 0.0508, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0729, Feature Loss: 0.0012, Position Loss: 0.1207, LR: 0.001000\n",
      "Epoch: 174\n",
      "\tTrain:\tTotal Loss: 0.0314, Feature Loss: 0.0066, Position Loss: 0.0480, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0006, Position Loss: 0.0041, LR: 0.001000\n",
      "Epoch: 175\n",
      "\tTrain:\tTotal Loss: 0.0287, Feature Loss: 0.0039, Position Loss: 0.0453, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0001, Position Loss: 0.0045, LR: 0.001000\n",
      "Epoch: 176\n",
      "\tTrain:\tTotal Loss: 0.0230, Feature Loss: 0.0019, Position Loss: 0.0371, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0002, Position Loss: 0.0023, LR: 0.001000\n",
      "Epoch: 177\n",
      "\tTrain:\tTotal Loss: 0.0316, Feature Loss: 0.0065, Position Loss: 0.0484, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0051, Feature Loss: 0.0001, Position Loss: 0.0084, LR: 0.001000\n",
      "Epoch: 178\n",
      "\tTrain:\tTotal Loss: 0.0229, Feature Loss: 0.0028, Position Loss: 0.0363, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0235, Feature Loss: 0.0194, Position Loss: 0.0263, LR: 0.001000\n",
      "Epoch: 179\n",
      "\tTrain:\tTotal Loss: 0.0386, Feature Loss: 0.0082, Position Loss: 0.0590, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0125, Feature Loss: 0.0002, Position Loss: 0.0207, LR: 0.001000\n",
      "Epoch: 180\n",
      "\tTrain:\tTotal Loss: 0.0362, Feature Loss: 0.0048, Position Loss: 0.0572, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0081, Feature Loss: 0.0075, Position Loss: 0.0085, LR: 0.001000\n",
      "Epoch: 181\n",
      "\tTrain:\tTotal Loss: 0.0320, Feature Loss: 0.0045, Position Loss: 0.0504, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0743, Feature Loss: 0.0123, Position Loss: 0.1157, LR: 0.001000\n",
      "Epoch: 182\n",
      "\tTrain:\tTotal Loss: 0.0335, Feature Loss: 0.0050, Position Loss: 0.0525, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0073, Feature Loss: 0.0006, Position Loss: 0.0117, LR: 0.001000\n",
      "Epoch: 183\n",
      "\tTrain:\tTotal Loss: 0.0298, Feature Loss: 0.0062, Position Loss: 0.0455, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0057, Feature Loss: 0.0011, Position Loss: 0.0087, LR: 0.001000\n",
      "Epoch: 184\n",
      "\tTrain:\tTotal Loss: 0.0266, Feature Loss: 0.0035, Position Loss: 0.0421, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0051, Feature Loss: 0.0060, Position Loss: 0.0046, LR: 0.001000\n",
      "Epoch: 185\n",
      "\tTrain:\tTotal Loss: 0.0309, Feature Loss: 0.0045, Position Loss: 0.0484, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0063, Feature Loss: 0.0026, Position Loss: 0.0087, LR: 0.001000\n",
      "Epoch: 186\n",
      "\tTrain:\tTotal Loss: 0.0255, Feature Loss: 0.0034, Position Loss: 0.0402, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0001, Position Loss: 0.0023, LR: 0.001000\n",
      "Epoch: 187\n",
      "\tTrain:\tTotal Loss: 0.0313, Feature Loss: 0.0070, Position Loss: 0.0474, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0166, Feature Loss: 0.0093, Position Loss: 0.0215, LR: 0.001000\n",
      "Epoch: 188\n",
      "\tTrain:\tTotal Loss: 0.0367, Feature Loss: 0.0066, Position Loss: 0.0567, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0618, Feature Loss: 0.0029, Position Loss: 0.1011, LR: 0.001000\n",
      "Epoch: 189\n",
      "\tTrain:\tTotal Loss: 0.0293, Feature Loss: 0.0046, Position Loss: 0.0458, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0006, Position Loss: 0.0059, LR: 0.001000\n",
      "Epoch: 190\n",
      "\tTrain:\tTotal Loss: 0.0410, Feature Loss: 0.0062, Position Loss: 0.0641, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0312, Feature Loss: 0.0368, Position Loss: 0.0275, LR: 0.001000\n",
      "Epoch: 191\n",
      "\tTrain:\tTotal Loss: 0.0309, Feature Loss: 0.0061, Position Loss: 0.0474, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0093, Feature Loss: 0.0004, Position Loss: 0.0152, LR: 0.001000\n",
      "Epoch: 192\n",
      "\tTrain:\tTotal Loss: 0.0363, Feature Loss: 0.0040, Position Loss: 0.0579, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0638, Feature Loss: 0.0073, Position Loss: 0.1015, LR: 0.001000\n",
      "Epoch: 193\n",
      "\tTrain:\tTotal Loss: 0.0295, Feature Loss: 0.0043, Position Loss: 0.0462, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0006, Position Loss: 0.0035, LR: 0.001000\n",
      "Epoch: 194\n",
      "\tTrain:\tTotal Loss: 0.0218, Feature Loss: 0.0025, Position Loss: 0.0347, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0029, Feature Loss: 0.0022, Position Loss: 0.0033, LR: 0.001000\n",
      "Epoch: 195\n",
      "\tTrain:\tTotal Loss: 0.0241, Feature Loss: 0.0026, Position Loss: 0.0385, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0021, Position Loss: 0.0029, LR: 0.001000\n",
      "Epoch: 196\n",
      "\tTrain:\tTotal Loss: 0.0203, Feature Loss: 0.0016, Position Loss: 0.0328, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0013, Position Loss: 0.0037, LR: 0.001000\n",
      "Epoch: 197\n",
      "\tTrain:\tTotal Loss: 0.0250, Feature Loss: 0.0023, Position Loss: 0.0400, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0119, Feature Loss: 0.0041, Position Loss: 0.0171, LR: 0.001000\n",
      "Epoch: 198\n",
      "\tTrain:\tTotal Loss: 0.0233, Feature Loss: 0.0021, Position Loss: 0.0374, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0313, Feature Loss: 0.0076, Position Loss: 0.0471, LR: 0.001000\n",
      "Epoch: 199\n",
      "\tTrain:\tTotal Loss: 0.0238, Feature Loss: 0.0030, Position Loss: 0.0376, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0046, Feature Loss: 0.0001, Position Loss: 0.0076, LR: 0.001000\n",
      "Epoch: 200\n",
      "\tTrain:\tTotal Loss: 0.0213, Feature Loss: 0.0021, Position Loss: 0.0342, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0012, Position Loss: 0.0072, LR: 0.001000\n",
      "Epoch: 201\n",
      "\tTrain:\tTotal Loss: 0.0175, Feature Loss: 0.0008, Position Loss: 0.0286, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0001, Position Loss: 0.0023, LR: 0.000500\n",
      "Epoch: 202\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0016, Position Loss: 0.0311, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0013, Position Loss: 0.0028, LR: 0.000500\n",
      "Epoch: 203\n",
      "\tTrain:\tTotal Loss: 0.0236, Feature Loss: 0.0021, Position Loss: 0.0379, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0032, Position Loss: 0.0031, LR: 0.000500\n",
      "Epoch: 204\n",
      "\tTrain:\tTotal Loss: 0.0204, Feature Loss: 0.0011, Position Loss: 0.0333, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0037, Feature Loss: 0.0003, Position Loss: 0.0059, LR: 0.000500\n",
      "Epoch: 205\n",
      "\tTrain:\tTotal Loss: 0.0200, Feature Loss: 0.0011, Position Loss: 0.0327, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0130, Feature Loss: 0.0013, Position Loss: 0.0207, LR: 0.000500\n",
      "Epoch: 206\n",
      "\tTrain:\tTotal Loss: 0.0181, Feature Loss: 0.0012, Position Loss: 0.0294, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0130, Feature Loss: 0.0012, Position Loss: 0.0209, LR: 0.000500\n",
      "Epoch: 207\n",
      "\tTrain:\tTotal Loss: 0.0237, Feature Loss: 0.0027, Position Loss: 0.0377, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0008, Position Loss: 0.0033, LR: 0.000500\n",
      "Epoch: 208\n",
      "\tTrain:\tTotal Loss: 0.0256, Feature Loss: 0.0025, Position Loss: 0.0410, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0060, Feature Loss: 0.0070, Position Loss: 0.0053, LR: 0.000500\n",
      "Epoch: 209\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0014, Position Loss: 0.0308, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0054, Feature Loss: 0.0002, Position Loss: 0.0089, LR: 0.000500\n",
      "Epoch: 210\n",
      "\tTrain:\tTotal Loss: 0.0275, Feature Loss: 0.0026, Position Loss: 0.0441, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0276, Feature Loss: 0.0004, Position Loss: 0.0457, LR: 0.000500\n",
      "Epoch: 211\n",
      "\tTrain:\tTotal Loss: 0.0326, Feature Loss: 0.0038, Position Loss: 0.0517, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0011, Position Loss: 0.0028, LR: 0.000500\n",
      "Epoch: 212\n",
      "\tTrain:\tTotal Loss: 0.0168, Feature Loss: 0.0014, Position Loss: 0.0271, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0101, Feature Loss: 0.0022, Position Loss: 0.0154, LR: 0.000500\n",
      "Epoch: 213\n",
      "\tTrain:\tTotal Loss: 0.0243, Feature Loss: 0.0015, Position Loss: 0.0394, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0012, Position Loss: 0.0022, LR: 0.000500\n",
      "Epoch: 214\n",
      "\tTrain:\tTotal Loss: 0.0188, Feature Loss: 0.0013, Position Loss: 0.0304, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0060, Feature Loss: 0.0044, Position Loss: 0.0070, LR: 0.000500\n",
      "Epoch: 215\n",
      "\tTrain:\tTotal Loss: 0.0184, Feature Loss: 0.0012, Position Loss: 0.0299, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0029, Feature Loss: 0.0026, Position Loss: 0.0031, LR: 0.000500\n",
      "Epoch: 216\n",
      "\tTrain:\tTotal Loss: 0.0211, Feature Loss: 0.0014, Position Loss: 0.0343, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0043, Feature Loss: 0.0054, Position Loss: 0.0036, LR: 0.000500\n",
      "Epoch: 217\n",
      "\tTrain:\tTotal Loss: 0.0191, Feature Loss: 0.0018, Position Loss: 0.0307, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0002, Position Loss: 0.0026, LR: 0.000500\n",
      "Epoch: 218\n",
      "\tTrain:\tTotal Loss: 0.0292, Feature Loss: 0.0034, Position Loss: 0.0464, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0142, Feature Loss: 0.0056, Position Loss: 0.0200, LR: 0.000500\n",
      "Epoch: 219\n",
      "\tTrain:\tTotal Loss: 0.0261, Feature Loss: 0.0043, Position Loss: 0.0406, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0251, Feature Loss: 0.0034, Position Loss: 0.0396, LR: 0.000500\n",
      "Epoch: 220\n",
      "\tTrain:\tTotal Loss: 0.0216, Feature Loss: 0.0031, Position Loss: 0.0339, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0035, Feature Loss: 0.0039, Position Loss: 0.0033, LR: 0.000500\n",
      "Epoch: 221\n",
      "\tTrain:\tTotal Loss: 0.0228, Feature Loss: 0.0042, Position Loss: 0.0353, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0019, Position Loss: 0.0031, LR: 0.000500\n",
      "Epoch: 222\n",
      "\tTrain:\tTotal Loss: 0.0234, Feature Loss: 0.0021, Position Loss: 0.0377, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0001, Position Loss: 0.0080, LR: 0.000500\n",
      "Epoch: 223\n",
      "\tTrain:\tTotal Loss: 0.0237, Feature Loss: 0.0019, Position Loss: 0.0382, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0135, Feature Loss: 0.0021, Position Loss: 0.0211, LR: 0.000500\n",
      "Epoch: 224\n",
      "\tTrain:\tTotal Loss: 0.0211, Feature Loss: 0.0020, Position Loss: 0.0338, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0100, Feature Loss: 0.0051, Position Loss: 0.0132, LR: 0.000500\n",
      "Epoch: 225\n",
      "\tTrain:\tTotal Loss: 0.0158, Feature Loss: 0.0011, Position Loss: 0.0255, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0033, Feature Loss: 0.0029, Position Loss: 0.0035, LR: 0.000500\n",
      "Epoch: 226\n",
      "\tTrain:\tTotal Loss: 0.0241, Feature Loss: 0.0025, Position Loss: 0.0385, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0133, Feature Loss: 0.0000, Position Loss: 0.0221, LR: 0.000500\n",
      "Epoch: 227\n",
      "\tTrain:\tTotal Loss: 0.0252, Feature Loss: 0.0017, Position Loss: 0.0409, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0205, Feature Loss: 0.0016, Position Loss: 0.0331, LR: 0.000500\n",
      "Epoch: 228\n",
      "\tTrain:\tTotal Loss: 0.0160, Feature Loss: 0.0017, Position Loss: 0.0255, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0001, Position Loss: 0.0043, LR: 0.000500\n",
      "Epoch: 229\n",
      "\tTrain:\tTotal Loss: 0.0238, Feature Loss: 0.0019, Position Loss: 0.0383, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0001, Position Loss: 0.0019, LR: 0.000500\n",
      "Epoch: 230\n",
      "\tTrain:\tTotal Loss: 0.0212, Feature Loss: 0.0013, Position Loss: 0.0344, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0006, Position Loss: 0.0030, LR: 0.000500\n",
      "Epoch: 231\n",
      "\tTrain:\tTotal Loss: 0.0194, Feature Loss: 0.0013, Position Loss: 0.0315, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0183, Feature Loss: 0.0001, Position Loss: 0.0305, LR: 0.000500\n",
      "Epoch: 232\n",
      "\tTrain:\tTotal Loss: 0.0235, Feature Loss: 0.0032, Position Loss: 0.0370, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0197, Feature Loss: 0.0077, Position Loss: 0.0278, LR: 0.000500\n",
      "Epoch: 233\n",
      "\tTrain:\tTotal Loss: 0.0282, Feature Loss: 0.0019, Position Loss: 0.0457, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0050, Feature Loss: 0.0020, Position Loss: 0.0070, LR: 0.000500\n",
      "Epoch: 234\n",
      "\tTrain:\tTotal Loss: 0.0229, Feature Loss: 0.0018, Position Loss: 0.0370, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0080, Feature Loss: 0.0001, Position Loss: 0.0132, LR: 0.000500\n",
      "Epoch: 235\n",
      "\tTrain:\tTotal Loss: 0.0224, Feature Loss: 0.0014, Position Loss: 0.0363, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0001, Position Loss: 0.0050, LR: 0.000500\n",
      "Epoch: 236\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0009, Position Loss: 0.0294, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0002, Position Loss: 0.0088, LR: 0.000500\n",
      "Epoch: 237\n",
      "\tTrain:\tTotal Loss: 0.0316, Feature Loss: 0.0036, Position Loss: 0.0502, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0004, Position Loss: 0.0031, LR: 0.000500\n",
      "Epoch: 238\n",
      "\tTrain:\tTotal Loss: 0.0241, Feature Loss: 0.0031, Position Loss: 0.0381, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0029, Position Loss: 0.0032, LR: 0.000500\n",
      "Epoch: 239\n",
      "\tTrain:\tTotal Loss: 0.0234, Feature Loss: 0.0020, Position Loss: 0.0376, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0034, Position Loss: 0.0041, LR: 0.000500\n",
      "Epoch: 240\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0013, Position Loss: 0.0308, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 241\n",
      "\tTrain:\tTotal Loss: 0.0229, Feature Loss: 0.0014, Position Loss: 0.0373, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0070, Feature Loss: 0.0011, Position Loss: 0.0109, LR: 0.000500\n",
      "Epoch: 242\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0020, Position Loss: 0.0304, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0103, Feature Loss: 0.0015, Position Loss: 0.0161, LR: 0.000500\n",
      "Epoch: 243\n",
      "\tTrain:\tTotal Loss: 0.0223, Feature Loss: 0.0026, Position Loss: 0.0354, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0164, Feature Loss: 0.0001, Position Loss: 0.0273, LR: 0.000500\n",
      "Epoch: 244\n",
      "\tTrain:\tTotal Loss: 0.0210, Feature Loss: 0.0019, Position Loss: 0.0338, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0079, Feature Loss: 0.0020, Position Loss: 0.0119, LR: 0.000500\n",
      "Epoch: 245\n",
      "\tTrain:\tTotal Loss: 0.0208, Feature Loss: 0.0016, Position Loss: 0.0336, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0099, Feature Loss: 0.0016, Position Loss: 0.0155, LR: 0.000500\n",
      "Epoch: 246\n",
      "\tTrain:\tTotal Loss: 0.0207, Feature Loss: 0.0015, Position Loss: 0.0334, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0059, Feature Loss: 0.0031, Position Loss: 0.0078, LR: 0.000500\n",
      "Epoch: 247\n",
      "\tTrain:\tTotal Loss: 0.0225, Feature Loss: 0.0024, Position Loss: 0.0359, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0044, Feature Loss: 0.0010, Position Loss: 0.0067, LR: 0.000500\n",
      "Epoch: 248\n",
      "\tTrain:\tTotal Loss: 0.0201, Feature Loss: 0.0020, Position Loss: 0.0322, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0080, Feature Loss: 0.0024, Position Loss: 0.0118, LR: 0.000500\n",
      "Epoch: 249\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0012, Position Loss: 0.0310, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0003, Position Loss: 0.0028, LR: 0.000500\n",
      "Epoch: 250\n",
      "\tTrain:\tTotal Loss: 0.0210, Feature Loss: 0.0024, Position Loss: 0.0334, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0033, Feature Loss: 0.0001, Position Loss: 0.0054, LR: 0.000500\n",
      "Epoch: 251\n",
      "\tTrain:\tTotal Loss: 0.0271, Feature Loss: 0.0029, Position Loss: 0.0432, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0056, Feature Loss: 0.0009, Position Loss: 0.0088, LR: 0.000500\n",
      "Epoch: 252\n",
      "\tTrain:\tTotal Loss: 0.0211, Feature Loss: 0.0024, Position Loss: 0.0336, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0001, Position Loss: 0.0065, LR: 0.000500\n",
      "Epoch: 253\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0017, Position Loss: 0.0298, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0071, Feature Loss: 0.0013, Position Loss: 0.0110, LR: 0.000500\n",
      "Epoch: 254\n",
      "\tTrain:\tTotal Loss: 0.0246, Feature Loss: 0.0022, Position Loss: 0.0395, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0103, Feature Loss: 0.0047, Position Loss: 0.0140, LR: 0.000500\n",
      "Epoch: 255\n",
      "\tTrain:\tTotal Loss: 0.0253, Feature Loss: 0.0024, Position Loss: 0.0406, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0029, Feature Loss: 0.0001, Position Loss: 0.0047, LR: 0.000500\n",
      "Epoch: 256\n",
      "\tTrain:\tTotal Loss: 0.0234, Feature Loss: 0.0025, Position Loss: 0.0373, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0052, Feature Loss: 0.0075, Position Loss: 0.0036, LR: 0.000500\n",
      "Epoch: 257\n",
      "\tTrain:\tTotal Loss: 0.0206, Feature Loss: 0.0021, Position Loss: 0.0330, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0075, Feature Loss: 0.0001, Position Loss: 0.0125, LR: 0.000500\n",
      "Epoch: 258\n",
      "\tTrain:\tTotal Loss: 0.0232, Feature Loss: 0.0015, Position Loss: 0.0377, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0011, Position Loss: 0.0057, LR: 0.000500\n",
      "Epoch: 259\n",
      "\tTrain:\tTotal Loss: 0.0187, Feature Loss: 0.0016, Position Loss: 0.0301, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0001, Position Loss: 0.0080, LR: 0.000500\n",
      "Epoch: 260\n",
      "\tTrain:\tTotal Loss: 0.0188, Feature Loss: 0.0007, Position Loss: 0.0308, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0054, Feature Loss: 0.0023, Position Loss: 0.0075, LR: 0.000500\n",
      "Epoch: 261\n",
      "\tTrain:\tTotal Loss: 0.0204, Feature Loss: 0.0020, Position Loss: 0.0327, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0031, Position Loss: 0.0023, LR: 0.000500\n",
      "Epoch: 262\n",
      "\tTrain:\tTotal Loss: 0.0191, Feature Loss: 0.0013, Position Loss: 0.0310, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0089, Feature Loss: 0.0024, Position Loss: 0.0133, LR: 0.000500\n",
      "Epoch: 263\n",
      "\tTrain:\tTotal Loss: 0.0188, Feature Loss: 0.0010, Position Loss: 0.0306, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0085, Feature Loss: 0.0001, Position Loss: 0.0142, LR: 0.000500\n",
      "Epoch: 264\n",
      "\tTrain:\tTotal Loss: 0.0181, Feature Loss: 0.0015, Position Loss: 0.0292, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0002, Position Loss: 0.0043, LR: 0.000500\n",
      "Epoch: 265\n",
      "\tTrain:\tTotal Loss: 0.0197, Feature Loss: 0.0016, Position Loss: 0.0317, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0163, Feature Loss: 0.0033, Position Loss: 0.0250, LR: 0.000500\n",
      "Epoch: 266\n",
      "\tTrain:\tTotal Loss: 0.0214, Feature Loss: 0.0027, Position Loss: 0.0338, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0002, Position Loss: 0.0025, LR: 0.000500\n",
      "Epoch: 267\n",
      "\tTrain:\tTotal Loss: 0.0176, Feature Loss: 0.0010, Position Loss: 0.0288, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0238, Feature Loss: 0.0004, Position Loss: 0.0394, LR: 0.000500\n",
      "Epoch: 268\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0013, Position Loss: 0.0301, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0058, Feature Loss: 0.0019, Position Loss: 0.0084, LR: 0.000500\n",
      "Epoch: 269\n",
      "\tTrain:\tTotal Loss: 0.0208, Feature Loss: 0.0015, Position Loss: 0.0337, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0001, Position Loss: 0.0089, LR: 0.000500\n",
      "Epoch: 270\n",
      "\tTrain:\tTotal Loss: 0.0238, Feature Loss: 0.0023, Position Loss: 0.0382, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0003, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 271\n",
      "\tTrain:\tTotal Loss: 0.0168, Feature Loss: 0.0005, Position Loss: 0.0276, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0032, Feature Loss: 0.0016, Position Loss: 0.0043, LR: 0.000500\n",
      "Epoch: 272\n",
      "\tTrain:\tTotal Loss: 0.0221, Feature Loss: 0.0012, Position Loss: 0.0360, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0052, Feature Loss: 0.0001, Position Loss: 0.0086, LR: 0.000500\n",
      "Epoch: 273\n",
      "\tTrain:\tTotal Loss: 0.0275, Feature Loss: 0.0036, Position Loss: 0.0434, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0040, Feature Loss: 0.0016, Position Loss: 0.0056, LR: 0.000500\n",
      "Epoch: 274\n",
      "\tTrain:\tTotal Loss: 0.0244, Feature Loss: 0.0026, Position Loss: 0.0389, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0073, Feature Loss: 0.0001, Position Loss: 0.0120, LR: 0.000500\n",
      "Epoch: 275\n",
      "\tTrain:\tTotal Loss: 0.0233, Feature Loss: 0.0027, Position Loss: 0.0370, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0008, Position Loss: 0.0045, LR: 0.000500\n",
      "Epoch: 276\n",
      "\tTrain:\tTotal Loss: 0.0197, Feature Loss: 0.0016, Position Loss: 0.0318, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0090, Feature Loss: 0.0089, Position Loss: 0.0090, LR: 0.000500\n",
      "Epoch: 277\n",
      "\tTrain:\tTotal Loss: 0.0222, Feature Loss: 0.0033, Position Loss: 0.0348, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0018, Position Loss: 0.0033, LR: 0.000500\n",
      "Epoch: 278\n",
      "\tTrain:\tTotal Loss: 0.0202, Feature Loss: 0.0013, Position Loss: 0.0328, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0006, Position Loss: 0.0020, LR: 0.000500\n",
      "Epoch: 279\n",
      "\tTrain:\tTotal Loss: 0.0244, Feature Loss: 0.0020, Position Loss: 0.0394, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0095, Feature Loss: 0.0002, Position Loss: 0.0157, LR: 0.000500\n",
      "Epoch: 280\n",
      "\tTrain:\tTotal Loss: 0.0156, Feature Loss: 0.0014, Position Loss: 0.0250, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0019, Position Loss: 0.0025, LR: 0.000500\n",
      "Epoch: 281\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0018, Position Loss: 0.0288, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0015, Position Loss: 0.0026, LR: 0.000500\n",
      "Epoch: 282\n",
      "\tTrain:\tTotal Loss: 0.0206, Feature Loss: 0.0013, Position Loss: 0.0334, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0274, Feature Loss: 0.0017, Position Loss: 0.0445, LR: 0.000500\n",
      "Epoch: 283\n",
      "\tTrain:\tTotal Loss: 0.0211, Feature Loss: 0.0019, Position Loss: 0.0339, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0103, Feature Loss: 0.0003, Position Loss: 0.0169, LR: 0.000500\n",
      "Epoch: 284\n",
      "\tTrain:\tTotal Loss: 0.0216, Feature Loss: 0.0009, Position Loss: 0.0353, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0006, Position Loss: 0.0020, LR: 0.000500\n",
      "Epoch: 285\n",
      "\tTrain:\tTotal Loss: 0.0211, Feature Loss: 0.0015, Position Loss: 0.0342, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0137, Feature Loss: 0.0003, Position Loss: 0.0227, LR: 0.000500\n",
      "Epoch: 286\n",
      "\tTrain:\tTotal Loss: 0.0220, Feature Loss: 0.0026, Position Loss: 0.0349, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0165, Feature Loss: 0.0014, Position Loss: 0.0266, LR: 0.000500\n",
      "Epoch: 287\n",
      "\tTrain:\tTotal Loss: 0.0195, Feature Loss: 0.0012, Position Loss: 0.0317, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0001, Position Loss: 0.0040, LR: 0.000500\n",
      "Epoch: 288\n",
      "\tTrain:\tTotal Loss: 0.0254, Feature Loss: 0.0032, Position Loss: 0.0402, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0137, Feature Loss: 0.0005, Position Loss: 0.0225, LR: 0.000500\n",
      "Epoch: 289\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0013, Position Loss: 0.0309, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0001, Position Loss: 0.0029, LR: 0.000500\n",
      "Epoch: 290\n",
      "\tTrain:\tTotal Loss: 0.0172, Feature Loss: 0.0008, Position Loss: 0.0281, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0110, Feature Loss: 0.0001, Position Loss: 0.0183, LR: 0.000500\n",
      "Epoch: 291\n",
      "\tTrain:\tTotal Loss: 0.0236, Feature Loss: 0.0028, Position Loss: 0.0374, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0001, Position Loss: 0.0029, LR: 0.000500\n",
      "Epoch: 292\n",
      "\tTrain:\tTotal Loss: 0.0215, Feature Loss: 0.0022, Position Loss: 0.0343, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0102, Feature Loss: 0.0025, Position Loss: 0.0153, LR: 0.000500\n",
      "Epoch: 293\n",
      "\tTrain:\tTotal Loss: 0.0217, Feature Loss: 0.0021, Position Loss: 0.0348, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0092, Feature Loss: 0.0104, Position Loss: 0.0084, LR: 0.000500\n",
      "Epoch: 294\n",
      "\tTrain:\tTotal Loss: 0.0194, Feature Loss: 0.0021, Position Loss: 0.0309, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0011, Position Loss: 0.0025, LR: 0.000500\n",
      "Epoch: 295\n",
      "\tTrain:\tTotal Loss: 0.0208, Feature Loss: 0.0016, Position Loss: 0.0336, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0057, Feature Loss: 0.0014, Position Loss: 0.0085, LR: 0.000500\n",
      "Epoch: 296\n",
      "\tTrain:\tTotal Loss: 0.0225, Feature Loss: 0.0022, Position Loss: 0.0360, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0127, Feature Loss: 0.0126, Position Loss: 0.0127, LR: 0.000500\n",
      "Epoch: 297\n",
      "\tTrain:\tTotal Loss: 0.0200, Feature Loss: 0.0029, Position Loss: 0.0314, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0100, Feature Loss: 0.0009, Position Loss: 0.0161, LR: 0.000500\n",
      "Epoch: 298\n",
      "\tTrain:\tTotal Loss: 0.0203, Feature Loss: 0.0016, Position Loss: 0.0327, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0018, Position Loss: 0.0032, LR: 0.000500\n",
      "Epoch: 299\n",
      "\tTrain:\tTotal Loss: 0.0202, Feature Loss: 0.0015, Position Loss: 0.0327, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0066, Position Loss: 0.0021, LR: 0.000500\n",
      "Epoch: 300\n",
      "\tTrain:\tTotal Loss: 0.0229, Feature Loss: 0.0020, Position Loss: 0.0367, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0012, Position Loss: 0.0045, LR: 0.000500\n",
      "Epoch: 301\n",
      "\tTrain:\tTotal Loss: 0.0229, Feature Loss: 0.0024, Position Loss: 0.0366, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0097, Feature Loss: 0.0070, Position Loss: 0.0115, LR: 0.000500\n",
      "Epoch: 302\n",
      "\tTrain:\tTotal Loss: 0.0177, Feature Loss: 0.0014, Position Loss: 0.0285, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0186, Feature Loss: 0.0001, Position Loss: 0.0310, LR: 0.000500\n",
      "Epoch: 303\n",
      "\tTrain:\tTotal Loss: 0.0274, Feature Loss: 0.0049, Position Loss: 0.0424, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0007, Position Loss: 0.0032, LR: 0.000500\n",
      "Epoch: 304\n",
      "\tTrain:\tTotal Loss: 0.0166, Feature Loss: 0.0016, Position Loss: 0.0266, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0073, Feature Loss: 0.0015, Position Loss: 0.0112, LR: 0.000500\n",
      "Epoch: 305\n",
      "\tTrain:\tTotal Loss: 0.0284, Feature Loss: 0.0029, Position Loss: 0.0454, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0125, Feature Loss: 0.0022, Position Loss: 0.0194, LR: 0.000500\n",
      "Epoch: 306\n",
      "\tTrain:\tTotal Loss: 0.0200, Feature Loss: 0.0014, Position Loss: 0.0325, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0131, Feature Loss: 0.0036, Position Loss: 0.0194, LR: 0.000500\n",
      "Epoch: 307\n",
      "\tTrain:\tTotal Loss: 0.0234, Feature Loss: 0.0023, Position Loss: 0.0375, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0034, Feature Loss: 0.0019, Position Loss: 0.0045, LR: 0.000500\n",
      "Epoch: 308\n",
      "\tTrain:\tTotal Loss: 0.0260, Feature Loss: 0.0030, Position Loss: 0.0413, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0031, Position Loss: 0.0068, LR: 0.000500\n",
      "Epoch: 309\n",
      "\tTrain:\tTotal Loss: 0.0238, Feature Loss: 0.0024, Position Loss: 0.0381, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0037, Position Loss: 0.0026, LR: 0.000500\n",
      "Epoch: 310\n",
      "\tTrain:\tTotal Loss: 0.0175, Feature Loss: 0.0008, Position Loss: 0.0287, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0001, Position Loss: 0.0045, LR: 0.000500\n",
      "Epoch: 311\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0014, Position Loss: 0.0291, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0012, Position Loss: 0.0033, LR: 0.000500\n",
      "Epoch: 312\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0014, Position Loss: 0.0308, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0018, Position Loss: 0.0053, LR: 0.000500\n",
      "Epoch: 313\n",
      "\tTrain:\tTotal Loss: 0.0258, Feature Loss: 0.0045, Position Loss: 0.0400, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0224, Feature Loss: 0.0038, Position Loss: 0.0347, LR: 0.000500\n",
      "Epoch: 314\n",
      "\tTrain:\tTotal Loss: 0.0239, Feature Loss: 0.0021, Position Loss: 0.0385, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0062, Feature Loss: 0.0025, Position Loss: 0.0087, LR: 0.000500\n",
      "Epoch: 315\n",
      "\tTrain:\tTotal Loss: 0.0205, Feature Loss: 0.0016, Position Loss: 0.0331, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0071, Feature Loss: 0.0023, Position Loss: 0.0103, LR: 0.000500\n",
      "Epoch: 316\n",
      "\tTrain:\tTotal Loss: 0.0217, Feature Loss: 0.0026, Position Loss: 0.0345, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0103, Feature Loss: 0.0050, Position Loss: 0.0138, LR: 0.000500\n",
      "Epoch: 317\n",
      "\tTrain:\tTotal Loss: 0.0273, Feature Loss: 0.0053, Position Loss: 0.0419, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0013, Position Loss: 0.0022, LR: 0.000500\n",
      "Epoch: 318\n",
      "\tTrain:\tTotal Loss: 0.0169, Feature Loss: 0.0016, Position Loss: 0.0270, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0001, Position Loss: 0.0022, LR: 0.000500\n",
      "Epoch: 319\n",
      "\tTrain:\tTotal Loss: 0.0163, Feature Loss: 0.0010, Position Loss: 0.0266, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0028, Feature Loss: 0.0028, Position Loss: 0.0028, LR: 0.000500\n",
      "Epoch: 320\n",
      "\tTrain:\tTotal Loss: 0.0205, Feature Loss: 0.0010, Position Loss: 0.0334, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0075, Feature Loss: 0.0005, Position Loss: 0.0121, LR: 0.000500\n",
      "Epoch: 321\n",
      "\tTrain:\tTotal Loss: 0.0169, Feature Loss: 0.0009, Position Loss: 0.0275, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0003, Position Loss: 0.0061, LR: 0.000500\n",
      "Epoch: 322\n",
      "\tTrain:\tTotal Loss: 0.0256, Feature Loss: 0.0023, Position Loss: 0.0411, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0078, Feature Loss: 0.0093, Position Loss: 0.0068, LR: 0.000500\n",
      "Epoch: 323\n",
      "\tTrain:\tTotal Loss: 0.0167, Feature Loss: 0.0020, Position Loss: 0.0265, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0093, Feature Loss: 0.0001, Position Loss: 0.0155, LR: 0.000500\n",
      "Epoch: 324\n",
      "\tTrain:\tTotal Loss: 0.0178, Feature Loss: 0.0008, Position Loss: 0.0291, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0064, Feature Loss: 0.0007, Position Loss: 0.0102, LR: 0.000500\n",
      "Epoch: 325\n",
      "\tTrain:\tTotal Loss: 0.0205, Feature Loss: 0.0021, Position Loss: 0.0328, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0061, Feature Loss: 0.0027, Position Loss: 0.0084, LR: 0.000500\n",
      "Epoch: 326\n",
      "\tTrain:\tTotal Loss: 0.0197, Feature Loss: 0.0013, Position Loss: 0.0320, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0229, Feature Loss: 0.0060, Position Loss: 0.0342, LR: 0.000500\n",
      "Epoch: 327\n",
      "\tTrain:\tTotal Loss: 0.0183, Feature Loss: 0.0012, Position Loss: 0.0297, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0032, Feature Loss: 0.0000, Position Loss: 0.0053, LR: 0.000500\n",
      "Epoch: 328\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0008, Position Loss: 0.0316, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0038, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 329\n",
      "\tTrain:\tTotal Loss: 0.0238, Feature Loss: 0.0020, Position Loss: 0.0383, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0134, Feature Loss: 0.0040, Position Loss: 0.0197, LR: 0.000500\n",
      "Epoch: 330\n",
      "\tTrain:\tTotal Loss: 0.0286, Feature Loss: 0.0033, Position Loss: 0.0455, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0001, Position Loss: 0.0063, LR: 0.000500\n",
      "Epoch: 331\n",
      "\tTrain:\tTotal Loss: 0.0241, Feature Loss: 0.0022, Position Loss: 0.0388, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0082, Feature Loss: 0.0031, Position Loss: 0.0117, LR: 0.000500\n",
      "Epoch: 332\n",
      "\tTrain:\tTotal Loss: 0.0192, Feature Loss: 0.0020, Position Loss: 0.0307, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0081, Feature Loss: 0.0008, Position Loss: 0.0130, LR: 0.000500\n",
      "Epoch: 333\n",
      "\tTrain:\tTotal Loss: 0.0226, Feature Loss: 0.0033, Position Loss: 0.0354, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0000, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 334\n",
      "\tTrain:\tTotal Loss: 0.0224, Feature Loss: 0.0014, Position Loss: 0.0364, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0065, Feature Loss: 0.0038, Position Loss: 0.0083, LR: 0.000500\n",
      "Epoch: 335\n",
      "\tTrain:\tTotal Loss: 0.0227, Feature Loss: 0.0014, Position Loss: 0.0370, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0087, Feature Loss: 0.0002, Position Loss: 0.0144, LR: 0.000500\n",
      "Epoch: 336\n",
      "\tTrain:\tTotal Loss: 0.0155, Feature Loss: 0.0012, Position Loss: 0.0249, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0083, Feature Loss: 0.0028, Position Loss: 0.0120, LR: 0.000500\n",
      "Epoch: 337\n",
      "\tTrain:\tTotal Loss: 0.0250, Feature Loss: 0.0025, Position Loss: 0.0400, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 338\n",
      "\tTrain:\tTotal Loss: 0.0192, Feature Loss: 0.0011, Position Loss: 0.0312, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0002, Position Loss: 0.0021, LR: 0.000500\n",
      "Epoch: 339\n",
      "\tTrain:\tTotal Loss: 0.0162, Feature Loss: 0.0005, Position Loss: 0.0267, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0016, Position Loss: 0.0078, LR: 0.000500\n",
      "Epoch: 340\n",
      "\tTrain:\tTotal Loss: 0.0230, Feature Loss: 0.0017, Position Loss: 0.0372, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0126, Feature Loss: 0.0002, Position Loss: 0.0208, LR: 0.000500\n",
      "Epoch: 341\n",
      "\tTrain:\tTotal Loss: 0.0204, Feature Loss: 0.0024, Position Loss: 0.0324, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0061, Feature Loss: 0.0002, Position Loss: 0.0100, LR: 0.000500\n",
      "Epoch: 342\n",
      "\tTrain:\tTotal Loss: 0.0244, Feature Loss: 0.0016, Position Loss: 0.0396, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0076, Feature Loss: 0.0020, Position Loss: 0.0114, LR: 0.000500\n",
      "Epoch: 343\n",
      "\tTrain:\tTotal Loss: 0.0243, Feature Loss: 0.0010, Position Loss: 0.0399, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 344\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0011, Position Loss: 0.0304, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0049, Feature Loss: 0.0000, Position Loss: 0.0081, LR: 0.000500\n",
      "Epoch: 345\n",
      "\tTrain:\tTotal Loss: 0.0218, Feature Loss: 0.0021, Position Loss: 0.0349, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0005, Position Loss: 0.0046, LR: 0.000500\n",
      "Epoch: 346\n",
      "\tTrain:\tTotal Loss: 0.0158, Feature Loss: 0.0011, Position Loss: 0.0256, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0115, Feature Loss: 0.0052, Position Loss: 0.0157, LR: 0.000500\n",
      "Epoch: 347\n",
      "\tTrain:\tTotal Loss: 0.0255, Feature Loss: 0.0024, Position Loss: 0.0409, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0050, Feature Loss: 0.0078, Position Loss: 0.0031, LR: 0.000500\n",
      "Epoch: 348\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0022, Position Loss: 0.0285, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0063, Feature Loss: 0.0001, Position Loss: 0.0105, LR: 0.000500\n",
      "Epoch: 349\n",
      "\tTrain:\tTotal Loss: 0.0206, Feature Loss: 0.0016, Position Loss: 0.0332, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0052, Feature Loss: 0.0006, Position Loss: 0.0082, LR: 0.000500\n",
      "Epoch: 350\n",
      "\tTrain:\tTotal Loss: 0.0209, Feature Loss: 0.0022, Position Loss: 0.0334, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0073, Feature Loss: 0.0003, Position Loss: 0.0119, LR: 0.000500\n",
      "Epoch: 351\n",
      "\tTrain:\tTotal Loss: 0.0199, Feature Loss: 0.0012, Position Loss: 0.0324, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0001, Position Loss: 0.0051, LR: 0.000500\n",
      "Epoch: 352\n",
      "\tTrain:\tTotal Loss: 0.0198, Feature Loss: 0.0010, Position Loss: 0.0323, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0050, Feature Loss: 0.0001, Position Loss: 0.0082, LR: 0.000500\n",
      "Epoch: 353\n",
      "\tTrain:\tTotal Loss: 0.0192, Feature Loss: 0.0012, Position Loss: 0.0313, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0131, Feature Loss: 0.0014, Position Loss: 0.0208, LR: 0.000500\n",
      "Epoch: 354\n",
      "\tTrain:\tTotal Loss: 0.0168, Feature Loss: 0.0013, Position Loss: 0.0271, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0043, Feature Loss: 0.0002, Position Loss: 0.0070, LR: 0.000500\n",
      "Epoch: 355\n",
      "\tTrain:\tTotal Loss: 0.0275, Feature Loss: 0.0021, Position Loss: 0.0445, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0084, Feature Loss: 0.0104, Position Loss: 0.0071, LR: 0.000500\n",
      "Epoch: 356\n",
      "\tTrain:\tTotal Loss: 0.0214, Feature Loss: 0.0034, Position Loss: 0.0334, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.000500\n",
      "Epoch: 357\n",
      "\tTrain:\tTotal Loss: 0.0218, Feature Loss: 0.0022, Position Loss: 0.0348, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0166, Feature Loss: 0.0054, Position Loss: 0.0241, LR: 0.000500\n",
      "Epoch: 358\n",
      "\tTrain:\tTotal Loss: 0.0139, Feature Loss: 0.0011, Position Loss: 0.0224, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0004, Position Loss: 0.0033, LR: 0.000500\n",
      "Epoch: 359\n",
      "\tTrain:\tTotal Loss: 0.0183, Feature Loss: 0.0014, Position Loss: 0.0296, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0072, Feature Loss: 0.0026, Position Loss: 0.0102, LR: 0.000500\n",
      "Epoch: 360\n",
      "\tTrain:\tTotal Loss: 0.0196, Feature Loss: 0.0012, Position Loss: 0.0319, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0103, Feature Loss: 0.0004, Position Loss: 0.0169, LR: 0.000500\n",
      "Epoch: 361\n",
      "\tTrain:\tTotal Loss: 0.0221, Feature Loss: 0.0033, Position Loss: 0.0347, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0075, Feature Loss: 0.0064, Position Loss: 0.0082, LR: 0.000500\n",
      "Epoch: 362\n",
      "\tTrain:\tTotal Loss: 0.0173, Feature Loss: 0.0009, Position Loss: 0.0282, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0000, Position Loss: 0.0064, LR: 0.000500\n",
      "Epoch: 363\n",
      "\tTrain:\tTotal Loss: 0.0197, Feature Loss: 0.0022, Position Loss: 0.0314, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0280, Feature Loss: 0.0104, Position Loss: 0.0397, LR: 0.000500\n",
      "Epoch: 364\n",
      "\tTrain:\tTotal Loss: 0.0200, Feature Loss: 0.0019, Position Loss: 0.0320, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0042, Position Loss: 0.0023, LR: 0.000500\n",
      "Epoch: 365\n",
      "\tTrain:\tTotal Loss: 0.0232, Feature Loss: 0.0027, Position Loss: 0.0368, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0001, Position Loss: 0.0039, LR: 0.000500\n",
      "Epoch: 366\n",
      "\tTrain:\tTotal Loss: 0.0198, Feature Loss: 0.0012, Position Loss: 0.0323, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0220, Feature Loss: 0.0019, Position Loss: 0.0354, LR: 0.000500\n",
      "Epoch: 367\n",
      "\tTrain:\tTotal Loss: 0.0221, Feature Loss: 0.0028, Position Loss: 0.0350, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0003, Position Loss: 0.0039, LR: 0.000500\n",
      "Epoch: 368\n",
      "\tTrain:\tTotal Loss: 0.0169, Feature Loss: 0.0012, Position Loss: 0.0274, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0079, Feature Loss: 0.0032, Position Loss: 0.0111, LR: 0.000500\n",
      "Epoch: 369\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0018, Position Loss: 0.0310, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0040, Feature Loss: 0.0044, Position Loss: 0.0038, LR: 0.000500\n",
      "Epoch: 370\n",
      "\tTrain:\tTotal Loss: 0.0242, Feature Loss: 0.0025, Position Loss: 0.0386, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0089, Feature Loss: 0.0000, Position Loss: 0.0148, LR: 0.000500\n",
      "Epoch: 371\n",
      "\tTrain:\tTotal Loss: 0.0236, Feature Loss: 0.0023, Position Loss: 0.0377, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0041, Feature Loss: 0.0046, Position Loss: 0.0038, LR: 0.000500\n",
      "Epoch: 372\n",
      "\tTrain:\tTotal Loss: 0.0177, Feature Loss: 0.0017, Position Loss: 0.0284, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0058, Feature Loss: 0.0006, Position Loss: 0.0093, LR: 0.000500\n",
      "Epoch: 373\n",
      "\tTrain:\tTotal Loss: 0.0196, Feature Loss: 0.0019, Position Loss: 0.0314, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0026, Position Loss: 0.0023, LR: 0.000500\n",
      "Epoch: 374\n",
      "\tTrain:\tTotal Loss: 0.0159, Feature Loss: 0.0008, Position Loss: 0.0259, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0002, Position Loss: 0.0030, LR: 0.000500\n",
      "Epoch: 375\n",
      "\tTrain:\tTotal Loss: 0.0206, Feature Loss: 0.0016, Position Loss: 0.0333, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0002, Position Loss: 0.0019, LR: 0.000500\n",
      "Epoch: 376\n",
      "\tTrain:\tTotal Loss: 0.0284, Feature Loss: 0.0028, Position Loss: 0.0455, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0031, Feature Loss: 0.0004, Position Loss: 0.0048, LR: 0.000500\n",
      "Epoch: 377\n",
      "\tTrain:\tTotal Loss: 0.0183, Feature Loss: 0.0008, Position Loss: 0.0299, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0041, Position Loss: 0.0052, LR: 0.000500\n",
      "Epoch: 378\n",
      "\tTrain:\tTotal Loss: 0.0197, Feature Loss: 0.0011, Position Loss: 0.0322, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0024, Position Loss: 0.0048, LR: 0.000500\n",
      "Epoch: 379\n",
      "\tTrain:\tTotal Loss: 0.0221, Feature Loss: 0.0020, Position Loss: 0.0356, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0056, Feature Loss: 0.0038, Position Loss: 0.0068, LR: 0.000500\n",
      "Epoch: 380\n",
      "\tTrain:\tTotal Loss: 0.0157, Feature Loss: 0.0010, Position Loss: 0.0254, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0087, Feature Loss: 0.0002, Position Loss: 0.0144, LR: 0.000500\n",
      "Epoch: 381\n",
      "\tTrain:\tTotal Loss: 0.0198, Feature Loss: 0.0018, Position Loss: 0.0318, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0043, Feature Loss: 0.0010, Position Loss: 0.0064, LR: 0.000500\n",
      "Epoch: 382\n",
      "\tTrain:\tTotal Loss: 0.0189, Feature Loss: 0.0016, Position Loss: 0.0304, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0082, Feature Loss: 0.0055, Position Loss: 0.0100, LR: 0.000500\n",
      "Epoch: 383\n",
      "\tTrain:\tTotal Loss: 0.0198, Feature Loss: 0.0018, Position Loss: 0.0318, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0097, Feature Loss: 0.0004, Position Loss: 0.0158, LR: 0.000500\n",
      "Epoch: 384\n",
      "\tTrain:\tTotal Loss: 0.0216, Feature Loss: 0.0016, Position Loss: 0.0350, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0040, Feature Loss: 0.0003, Position Loss: 0.0066, LR: 0.000500\n",
      "Epoch: 385\n",
      "\tTrain:\tTotal Loss: 0.0243, Feature Loss: 0.0025, Position Loss: 0.0387, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0001, Position Loss: 0.0035, LR: 0.000500\n",
      "Epoch: 386\n",
      "\tTrain:\tTotal Loss: 0.0227, Feature Loss: 0.0021, Position Loss: 0.0365, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0000, Position Loss: 0.0031, LR: 0.000500\n",
      "Epoch: 387\n",
      "\tTrain:\tTotal Loss: 0.0204, Feature Loss: 0.0016, Position Loss: 0.0329, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0131, Feature Loss: 0.0015, Position Loss: 0.0209, LR: 0.000500\n",
      "Epoch: 388\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0014, Position Loss: 0.0312, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0059, Feature Loss: 0.0014, Position Loss: 0.0088, LR: 0.000500\n",
      "Epoch: 389\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0006, Position Loss: 0.0318, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0059, Feature Loss: 0.0006, Position Loss: 0.0093, LR: 0.000500\n",
      "Epoch: 390\n",
      "\tTrain:\tTotal Loss: 0.0182, Feature Loss: 0.0009, Position Loss: 0.0298, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0001, Position Loss: 0.0038, LR: 0.000500\n",
      "Epoch: 391\n",
      "\tTrain:\tTotal Loss: 0.0179, Feature Loss: 0.0011, Position Loss: 0.0291, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0042, Feature Loss: 0.0003, Position Loss: 0.0067, LR: 0.000500\n",
      "Epoch: 392\n",
      "\tTrain:\tTotal Loss: 0.0160, Feature Loss: 0.0012, Position Loss: 0.0258, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0034, Feature Loss: 0.0005, Position Loss: 0.0053, LR: 0.000500\n",
      "Epoch: 393\n",
      "\tTrain:\tTotal Loss: 0.0233, Feature Loss: 0.0015, Position Loss: 0.0379, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0165, Feature Loss: 0.0038, Position Loss: 0.0251, LR: 0.000500\n",
      "Epoch: 394\n",
      "\tTrain:\tTotal Loss: 0.0210, Feature Loss: 0.0023, Position Loss: 0.0335, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0162, Feature Loss: 0.0017, Position Loss: 0.0259, LR: 0.000500\n",
      "Epoch: 395\n",
      "\tTrain:\tTotal Loss: 0.0210, Feature Loss: 0.0016, Position Loss: 0.0340, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0002, Position Loss: 0.0042, LR: 0.000500\n",
      "Epoch: 396\n",
      "\tTrain:\tTotal Loss: 0.0201, Feature Loss: 0.0019, Position Loss: 0.0322, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0100, Feature Loss: 0.0001, Position Loss: 0.0165, LR: 0.000500\n",
      "Epoch: 397\n",
      "\tTrain:\tTotal Loss: 0.0203, Feature Loss: 0.0015, Position Loss: 0.0329, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0122, Feature Loss: 0.0000, Position Loss: 0.0203, LR: 0.000500\n",
      "Epoch: 398\n",
      "\tTrain:\tTotal Loss: 0.0161, Feature Loss: 0.0011, Position Loss: 0.0260, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0009, Position Loss: 0.0019, LR: 0.000500\n",
      "Epoch: 399\n",
      "\tTrain:\tTotal Loss: 0.0191, Feature Loss: 0.0022, Position Loss: 0.0303, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0097, Feature Loss: 0.0012, Position Loss: 0.0153, LR: 0.000500\n",
      "Epoch: 400\n",
      "\tTrain:\tTotal Loss: 0.0232, Feature Loss: 0.0018, Position Loss: 0.0374, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0082, Feature Loss: 0.0009, Position Loss: 0.0131, LR: 0.000500\n",
      "Epoch: 401\n",
      "\tTrain:\tTotal Loss: 0.0182, Feature Loss: 0.0006, Position Loss: 0.0299, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0000, Position Loss: 0.0023, LR: 0.000250\n",
      "Epoch: 402\n",
      "\tTrain:\tTotal Loss: 0.0158, Feature Loss: 0.0005, Position Loss: 0.0261, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0002, Position Loss: 0.0042, LR: 0.000250\n",
      "Epoch: 403\n",
      "\tTrain:\tTotal Loss: 0.0185, Feature Loss: 0.0005, Position Loss: 0.0305, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0010, Position Loss: 0.0026, LR: 0.000250\n",
      "Epoch: 404\n",
      "\tTrain:\tTotal Loss: 0.0148, Feature Loss: 0.0004, Position Loss: 0.0244, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0025, LR: 0.000250\n",
      "Epoch: 405\n",
      "\tTrain:\tTotal Loss: 0.0120, Feature Loss: 0.0003, Position Loss: 0.0198, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0000, Position Loss: 0.0040, LR: 0.000250\n",
      "Epoch: 406\n",
      "\tTrain:\tTotal Loss: 0.0184, Feature Loss: 0.0006, Position Loss: 0.0303, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0001, Position Loss: 0.0025, LR: 0.000250\n",
      "Epoch: 407\n",
      "\tTrain:\tTotal Loss: 0.0160, Feature Loss: 0.0003, Position Loss: 0.0264, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0168, Feature Loss: 0.0007, Position Loss: 0.0275, LR: 0.000250\n",
      "Epoch: 408\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0006, Position Loss: 0.0307, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0002, Position Loss: 0.0025, LR: 0.000250\n",
      "Epoch: 409\n",
      "\tTrain:\tTotal Loss: 0.0117, Feature Loss: 0.0002, Position Loss: 0.0194, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0001, Position Loss: 0.0019, LR: 0.000250\n",
      "Epoch: 410\n",
      "\tTrain:\tTotal Loss: 0.0107, Feature Loss: 0.0002, Position Loss: 0.0177, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0001, Position Loss: 0.0024, LR: 0.000250\n",
      "Epoch: 411\n",
      "\tTrain:\tTotal Loss: 0.0146, Feature Loss: 0.0005, Position Loss: 0.0239, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0000, Position Loss: 0.0022, LR: 0.000250\n",
      "Epoch: 412\n",
      "\tTrain:\tTotal Loss: 0.0160, Feature Loss: 0.0009, Position Loss: 0.0260, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0032, Feature Loss: 0.0002, Position Loss: 0.0052, LR: 0.000250\n",
      "Epoch: 413\n",
      "\tTrain:\tTotal Loss: 0.0175, Feature Loss: 0.0006, Position Loss: 0.0288, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0000, Position Loss: 0.0043, LR: 0.000250\n",
      "Epoch: 414\n",
      "\tTrain:\tTotal Loss: 0.0192, Feature Loss: 0.0005, Position Loss: 0.0317, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0001, Position Loss: 0.0038, LR: 0.000250\n",
      "Epoch: 415\n",
      "\tTrain:\tTotal Loss: 0.0163, Feature Loss: 0.0005, Position Loss: 0.0268, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0002, Position Loss: 0.0044, LR: 0.000250\n",
      "Epoch: 416\n",
      "\tTrain:\tTotal Loss: 0.0154, Feature Loss: 0.0007, Position Loss: 0.0253, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0083, Feature Loss: 0.0000, Position Loss: 0.0138, LR: 0.000250\n",
      "Epoch: 417\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0004, Position Loss: 0.0296, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0042, Feature Loss: 0.0014, Position Loss: 0.0060, LR: 0.000250\n",
      "Epoch: 418\n",
      "\tTrain:\tTotal Loss: 0.0196, Feature Loss: 0.0011, Position Loss: 0.0320, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0004, Position Loss: 0.0029, LR: 0.000250\n",
      "Epoch: 419\n",
      "\tTrain:\tTotal Loss: 0.0191, Feature Loss: 0.0005, Position Loss: 0.0315, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0011, Feature Loss: 0.0002, Position Loss: 0.0018, LR: 0.000250\n",
      "Epoch: 420\n",
      "\tTrain:\tTotal Loss: 0.0158, Feature Loss: 0.0004, Position Loss: 0.0260, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0043, Feature Loss: 0.0004, Position Loss: 0.0068, LR: 0.000250\n",
      "Epoch: 421\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0005, Position Loss: 0.0307, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0017, Position Loss: 0.0029, LR: 0.000250\n",
      "Epoch: 422\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0005, Position Loss: 0.0306, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0013, Position Loss: 0.0024, LR: 0.000250\n",
      "Epoch: 423\n",
      "\tTrain:\tTotal Loss: 0.0159, Feature Loss: 0.0006, Position Loss: 0.0260, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0001, Position Loss: 0.0023, LR: 0.000250\n",
      "Epoch: 424\n",
      "\tTrain:\tTotal Loss: 0.0168, Feature Loss: 0.0004, Position Loss: 0.0278, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0005, Position Loss: 0.0022, LR: 0.000250\n",
      "Epoch: 425\n",
      "\tTrain:\tTotal Loss: 0.0141, Feature Loss: 0.0005, Position Loss: 0.0232, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0035, Feature Loss: 0.0005, Position Loss: 0.0055, LR: 0.000250\n",
      "Epoch: 426\n",
      "\tTrain:\tTotal Loss: 0.0145, Feature Loss: 0.0007, Position Loss: 0.0238, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0000, Position Loss: 0.0021, LR: 0.000250\n",
      "Epoch: 427\n",
      "\tTrain:\tTotal Loss: 0.0181, Feature Loss: 0.0008, Position Loss: 0.0297, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0088, Feature Loss: 0.0010, Position Loss: 0.0141, LR: 0.000250\n",
      "Epoch: 428\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0012, Position Loss: 0.0293, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0002, Position Loss: 0.0043, LR: 0.000250\n",
      "Epoch: 429\n",
      "\tTrain:\tTotal Loss: 0.0205, Feature Loss: 0.0010, Position Loss: 0.0335, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0061, Feature Loss: 0.0025, Position Loss: 0.0085, LR: 0.000250\n",
      "Epoch: 430\n",
      "\tTrain:\tTotal Loss: 0.0164, Feature Loss: 0.0010, Position Loss: 0.0267, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0004, Position Loss: 0.0036, LR: 0.000250\n",
      "Epoch: 431\n",
      "\tTrain:\tTotal Loss: 0.0152, Feature Loss: 0.0002, Position Loss: 0.0252, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0006, Position Loss: 0.0021, LR: 0.000250\n",
      "Epoch: 432\n",
      "\tTrain:\tTotal Loss: 0.0170, Feature Loss: 0.0004, Position Loss: 0.0281, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0055, Feature Loss: 0.0007, Position Loss: 0.0087, LR: 0.000250\n",
      "Epoch: 433\n",
      "\tTrain:\tTotal Loss: 0.0171, Feature Loss: 0.0006, Position Loss: 0.0281, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0070, Feature Loss: 0.0003, Position Loss: 0.0116, LR: 0.000250\n",
      "Epoch: 434\n",
      "\tTrain:\tTotal Loss: 0.0216, Feature Loss: 0.0009, Position Loss: 0.0354, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0079, Feature Loss: 0.0006, Position Loss: 0.0127, LR: 0.000250\n",
      "Epoch: 435\n",
      "\tTrain:\tTotal Loss: 0.0158, Feature Loss: 0.0008, Position Loss: 0.0257, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0012, Position Loss: 0.0025, LR: 0.000250\n",
      "Epoch: 436\n",
      "\tTrain:\tTotal Loss: 0.0157, Feature Loss: 0.0005, Position Loss: 0.0258, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0006, Position Loss: 0.0038, LR: 0.000250\n",
      "Epoch: 437\n",
      "\tTrain:\tTotal Loss: 0.0174, Feature Loss: 0.0006, Position Loss: 0.0285, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0014, Position Loss: 0.0053, LR: 0.000250\n",
      "Epoch: 438\n",
      "\tTrain:\tTotal Loss: 0.0152, Feature Loss: 0.0005, Position Loss: 0.0250, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0077, Feature Loss: 0.0000, Position Loss: 0.0128, LR: 0.000250\n",
      "Epoch: 439\n",
      "\tTrain:\tTotal Loss: 0.0154, Feature Loss: 0.0003, Position Loss: 0.0254, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0005, Position Loss: 0.0047, LR: 0.000250\n",
      "Epoch: 440\n",
      "\tTrain:\tTotal Loss: 0.0175, Feature Loss: 0.0003, Position Loss: 0.0291, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0001, Position Loss: 0.0080, LR: 0.000250\n",
      "Epoch: 441\n",
      "\tTrain:\tTotal Loss: 0.0154, Feature Loss: 0.0006, Position Loss: 0.0253, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0007, Position Loss: 0.0045, LR: 0.000250\n",
      "Epoch: 442\n",
      "\tTrain:\tTotal Loss: 0.0161, Feature Loss: 0.0007, Position Loss: 0.0264, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0053, Feature Loss: 0.0001, Position Loss: 0.0087, LR: 0.000250\n",
      "Epoch: 443\n",
      "\tTrain:\tTotal Loss: 0.0201, Feature Loss: 0.0005, Position Loss: 0.0331, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0037, Feature Loss: 0.0001, Position Loss: 0.0061, LR: 0.000250\n",
      "Epoch: 444\n",
      "\tTrain:\tTotal Loss: 0.0175, Feature Loss: 0.0006, Position Loss: 0.0288, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0068, Feature Loss: 0.0022, Position Loss: 0.0099, LR: 0.000250\n",
      "Epoch: 445\n",
      "\tTrain:\tTotal Loss: 0.0162, Feature Loss: 0.0003, Position Loss: 0.0267, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0001, Position Loss: 0.0024, LR: 0.000250\n",
      "Epoch: 446\n",
      "\tTrain:\tTotal Loss: 0.0163, Feature Loss: 0.0003, Position Loss: 0.0270, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0055, Feature Loss: 0.0003, Position Loss: 0.0090, LR: 0.000250\n",
      "Epoch: 447\n",
      "\tTrain:\tTotal Loss: 0.0178, Feature Loss: 0.0008, Position Loss: 0.0292, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0000, Position Loss: 0.0029, LR: 0.000250\n",
      "Epoch: 448\n",
      "\tTrain:\tTotal Loss: 0.0167, Feature Loss: 0.0003, Position Loss: 0.0277, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0000, Position Loss: 0.0023, LR: 0.000250\n",
      "Epoch: 449\n",
      "\tTrain:\tTotal Loss: 0.0171, Feature Loss: 0.0004, Position Loss: 0.0283, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0005, Position Loss: 0.0030, LR: 0.000250\n",
      "Epoch: 450\n",
      "\tTrain:\tTotal Loss: 0.0167, Feature Loss: 0.0004, Position Loss: 0.0275, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0001, Position Loss: 0.0064, LR: 0.000250\n",
      "Epoch: 451\n",
      "\tTrain:\tTotal Loss: 0.0184, Feature Loss: 0.0006, Position Loss: 0.0303, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0003, Position Loss: 0.0035, LR: 0.000250\n",
      "Epoch: 452\n",
      "\tTrain:\tTotal Loss: 0.0189, Feature Loss: 0.0006, Position Loss: 0.0310, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0147, Feature Loss: 0.0005, Position Loss: 0.0242, LR: 0.000250\n",
      "Epoch: 453\n",
      "\tTrain:\tTotal Loss: 0.0174, Feature Loss: 0.0004, Position Loss: 0.0287, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0002, Position Loss: 0.0036, LR: 0.000250\n",
      "Epoch: 454\n",
      "\tTrain:\tTotal Loss: 0.0183, Feature Loss: 0.0008, Position Loss: 0.0300, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0001, Position Loss: 0.0040, LR: 0.000250\n",
      "Epoch: 455\n",
      "\tTrain:\tTotal Loss: 0.0144, Feature Loss: 0.0003, Position Loss: 0.0238, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0049, Feature Loss: 0.0004, Position Loss: 0.0079, LR: 0.000250\n",
      "Epoch: 456\n",
      "\tTrain:\tTotal Loss: 0.0194, Feature Loss: 0.0004, Position Loss: 0.0321, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0000, Position Loss: 0.0020, LR: 0.000250\n",
      "Epoch: 457\n",
      "\tTrain:\tTotal Loss: 0.0163, Feature Loss: 0.0007, Position Loss: 0.0267, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0034, Feature Loss: 0.0002, Position Loss: 0.0056, LR: 0.000250\n",
      "Epoch: 458\n",
      "\tTrain:\tTotal Loss: 0.0116, Feature Loss: 0.0004, Position Loss: 0.0191, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0003, Position Loss: 0.0024, LR: 0.000250\n",
      "Epoch: 459\n",
      "\tTrain:\tTotal Loss: 0.0191, Feature Loss: 0.0006, Position Loss: 0.0315, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0019, Position Loss: 0.0030, LR: 0.000250\n",
      "Epoch: 460\n",
      "\tTrain:\tTotal Loss: 0.0186, Feature Loss: 0.0004, Position Loss: 0.0307, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0000, Position Loss: 0.0035, LR: 0.000250\n",
      "Epoch: 461\n",
      "\tTrain:\tTotal Loss: 0.0125, Feature Loss: 0.0003, Position Loss: 0.0206, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0095, Feature Loss: 0.0000, Position Loss: 0.0158, LR: 0.000250\n",
      "Epoch: 462\n",
      "\tTrain:\tTotal Loss: 0.0131, Feature Loss: 0.0006, Position Loss: 0.0214, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0011, Feature Loss: 0.0000, Position Loss: 0.0018, LR: 0.000250\n",
      "Epoch: 463\n",
      "\tTrain:\tTotal Loss: 0.0179, Feature Loss: 0.0006, Position Loss: 0.0294, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0194, Feature Loss: 0.0006, Position Loss: 0.0319, LR: 0.000250\n",
      "Epoch: 464\n",
      "\tTrain:\tTotal Loss: 0.0148, Feature Loss: 0.0004, Position Loss: 0.0245, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0006, Position Loss: 0.0032, LR: 0.000250\n",
      "Epoch: 465\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0005, Position Loss: 0.0319, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0000, Position Loss: 0.0023, LR: 0.000250\n",
      "Epoch: 466\n",
      "\tTrain:\tTotal Loss: 0.0170, Feature Loss: 0.0010, Position Loss: 0.0276, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0027, Feature Loss: 0.0004, Position Loss: 0.0043, LR: 0.000250\n",
      "Epoch: 467\n",
      "\tTrain:\tTotal Loss: 0.0177, Feature Loss: 0.0009, Position Loss: 0.0289, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0007, Position Loss: 0.0059, LR: 0.000250\n",
      "Epoch: 468\n",
      "\tTrain:\tTotal Loss: 0.0173, Feature Loss: 0.0009, Position Loss: 0.0282, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0044, Feature Loss: 0.0002, Position Loss: 0.0072, LR: 0.000250\n",
      "Epoch: 469\n",
      "\tTrain:\tTotal Loss: 0.0181, Feature Loss: 0.0009, Position Loss: 0.0296, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0001, Position Loss: 0.0028, LR: 0.000250\n",
      "Epoch: 470\n",
      "\tTrain:\tTotal Loss: 0.0126, Feature Loss: 0.0002, Position Loss: 0.0208, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0000, Position Loss: 0.0040, LR: 0.000250\n",
      "Epoch: 471\n",
      "\tTrain:\tTotal Loss: 0.0187, Feature Loss: 0.0004, Position Loss: 0.0310, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0089, Feature Loss: 0.0004, Position Loss: 0.0146, LR: 0.000250\n",
      "Epoch: 472\n",
      "\tTrain:\tTotal Loss: 0.0162, Feature Loss: 0.0006, Position Loss: 0.0265, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0004, Position Loss: 0.0019, LR: 0.000250\n",
      "Epoch: 473\n",
      "\tTrain:\tTotal Loss: 0.0151, Feature Loss: 0.0004, Position Loss: 0.0250, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0005, Position Loss: 0.0018, LR: 0.000250\n",
      "Epoch: 474\n",
      "\tTrain:\tTotal Loss: 0.0152, Feature Loss: 0.0002, Position Loss: 0.0252, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0019, Feature Loss: 0.0002, Position Loss: 0.0030, LR: 0.000250\n",
      "Epoch: 475\n",
      "\tTrain:\tTotal Loss: 0.0149, Feature Loss: 0.0006, Position Loss: 0.0244, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0005, Position Loss: 0.0040, LR: 0.000250\n",
      "Epoch: 476\n",
      "\tTrain:\tTotal Loss: 0.0168, Feature Loss: 0.0005, Position Loss: 0.0276, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0034, Feature Loss: 0.0004, Position Loss: 0.0055, LR: 0.000250\n",
      "Epoch: 477\n",
      "\tTrain:\tTotal Loss: 0.0164, Feature Loss: 0.0005, Position Loss: 0.0271, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0000, Position Loss: 0.0025, LR: 0.000250\n",
      "Epoch: 478\n",
      "\tTrain:\tTotal Loss: 0.0145, Feature Loss: 0.0004, Position Loss: 0.0239, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0004, Position Loss: 0.0021, LR: 0.000250\n",
      "Epoch: 479\n",
      "\tTrain:\tTotal Loss: 0.0165, Feature Loss: 0.0005, Position Loss: 0.0272, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0051, Feature Loss: 0.0001, Position Loss: 0.0084, LR: 0.000250\n",
      "Epoch: 480\n",
      "\tTrain:\tTotal Loss: 0.0132, Feature Loss: 0.0004, Position Loss: 0.0218, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0003, Position Loss: 0.0018, LR: 0.000250\n",
      "Epoch: 481\n",
      "\tTrain:\tTotal Loss: 0.0172, Feature Loss: 0.0005, Position Loss: 0.0283, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0005, Position Loss: 0.0025, LR: 0.000250\n",
      "Epoch: 482\n",
      "\tTrain:\tTotal Loss: 0.0182, Feature Loss: 0.0008, Position Loss: 0.0298, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0035, Feature Loss: 0.0010, Position Loss: 0.0051, LR: 0.000250\n",
      "Epoch: 483\n",
      "\tTrain:\tTotal Loss: 0.0162, Feature Loss: 0.0005, Position Loss: 0.0266, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0028, Feature Loss: 0.0002, Position Loss: 0.0046, LR: 0.000250\n",
      "Epoch: 484\n",
      "\tTrain:\tTotal Loss: 0.0174, Feature Loss: 0.0007, Position Loss: 0.0286, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0008, Position Loss: 0.0033, LR: 0.000250\n",
      "Epoch: 485\n",
      "\tTrain:\tTotal Loss: 0.0136, Feature Loss: 0.0002, Position Loss: 0.0225, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0001, Position Loss: 0.0039, LR: 0.000250\n",
      "Epoch: 486\n",
      "\tTrain:\tTotal Loss: 0.0193, Feature Loss: 0.0005, Position Loss: 0.0318, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0029, Feature Loss: 0.0004, Position Loss: 0.0045, LR: 0.000250\n",
      "Epoch: 487\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0006, Position Loss: 0.0296, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0000, Position Loss: 0.0080, LR: 0.000250\n",
      "Epoch: 488\n",
      "\tTrain:\tTotal Loss: 0.0180, Feature Loss: 0.0008, Position Loss: 0.0296, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0000, Position Loss: 0.0019, LR: 0.000250\n",
      "Epoch: 489\n",
      "\tTrain:\tTotal Loss: 0.0135, Feature Loss: 0.0002, Position Loss: 0.0223, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.000250\n",
      "Epoch: 490\n",
      "\tTrain:\tTotal Loss: 0.0168, Feature Loss: 0.0006, Position Loss: 0.0276, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0004, Position Loss: 0.0031, LR: 0.000250\n",
      "Epoch: 491\n",
      "\tTrain:\tTotal Loss: 0.0116, Feature Loss: 0.0002, Position Loss: 0.0192, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0000, Position Loss: 0.0022, LR: 0.000250\n",
      "Epoch: 492\n",
      "\tTrain:\tTotal Loss: 0.0169, Feature Loss: 0.0006, Position Loss: 0.0277, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0006, Position Loss: 0.0021, LR: 0.000250\n",
      "Epoch: 493\n",
      "\tTrain:\tTotal Loss: 0.0176, Feature Loss: 0.0008, Position Loss: 0.0289, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0148, Feature Loss: 0.0004, Position Loss: 0.0243, LR: 0.000250\n",
      "Epoch: 494\n",
      "\tTrain:\tTotal Loss: 0.0167, Feature Loss: 0.0010, Position Loss: 0.0272, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0004, Position Loss: 0.0036, LR: 0.000250\n",
      "Epoch: 495\n",
      "\tTrain:\tTotal Loss: 0.0159, Feature Loss: 0.0005, Position Loss: 0.0262, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0002, Position Loss: 0.0026, LR: 0.000250\n",
      "Epoch: 496\n",
      "\tTrain:\tTotal Loss: 0.0176, Feature Loss: 0.0006, Position Loss: 0.0289, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0033, Feature Loss: 0.0001, Position Loss: 0.0054, LR: 0.000250\n",
      "Epoch: 497\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0008, Position Loss: 0.0311, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0067, Feature Loss: 0.0001, Position Loss: 0.0112, LR: 0.000250\n",
      "Epoch: 498\n",
      "\tTrain:\tTotal Loss: 0.0176, Feature Loss: 0.0007, Position Loss: 0.0288, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0028, Feature Loss: 0.0007, Position Loss: 0.0042, LR: 0.000250\n",
      "Epoch: 499\n",
      "\tTrain:\tTotal Loss: 0.0187, Feature Loss: 0.0008, Position Loss: 0.0307, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0015, Position Loss: 0.0019, LR: 0.000250\n",
      "Epoch: 500\n",
      "\tTrain:\tTotal Loss: 0.0190, Feature Loss: 0.0007, Position Loss: 0.0311, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0041, Feature Loss: 0.0000, Position Loss: 0.0068, LR: 0.000250\n"
     ]
    }
   ],
   "source": [
    "train_total_losses = []\n",
    "train_feature_losses = []\n",
    "train_edge_losses = []\n",
    "train_position_losses = []\n",
    "\n",
    "test_total_losses = []\n",
    "test_feature_losses = []\n",
    "test_edge_losses = []\n",
    "test_position_losses = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "\n",
    "\n",
    "if model_loaded:        \n",
    "    print(\"Pretrained Model Loaded, no training required\")\n",
    "else:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_total_loss, train_feature_loss, train_edge_loss,train_position_loss = train()\n",
    "        test_total_loss, test_feature_loss, test_edge_loss,test_position_loss = test()\n",
    "        \n",
    "        print(f\"Epoch: {epoch:03d}\")\n",
    "        print(f'\\tTrain:\\tTotal Loss: {train_total_loss:.4f}, Feature Loss: {train_feature_loss:.4f}, Position Loss: {train_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        print(f'\\tTest: \\tTotal Loss: {test_total_loss:.4f}, Feature Loss: {test_feature_loss:.4f}, Position Loss: {test_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        \n",
    "        if(early_stopper.early_stop(test_total_loss)):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "\n",
    "        train_total_losses.append(train_total_loss)\n",
    "        train_feature_losses.append(train_feature_loss)\n",
    "        train_edge_losses.append(train_edge_loss)\n",
    "        train_position_losses.append(train_position_loss)\n",
    "\n",
    "        test_total_losses.append(test_total_loss)\n",
    "        test_feature_losses.append(test_feature_loss)\n",
    "        test_edge_losses.append(test_edge_loss)\n",
    "        test_position_losses.append(test_position_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model,\"./models/\"+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "Vp6sgGOOUuhs",
    "outputId": "8e483db8-e50c-4165-c93e-52a09d610557"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACRbElEQVR4nO2deXwU9f3/X5s7AZIAgYQbFBQQ5FIgoPWKBI8qWhHRCiLFelC1tKj4VdBaf1QtFBUU0apoRSke1HpQMQIqBJBb5BAQCEcOrtzHJruf3x+bmZ2ZnWs3u9lkeT0fjzyyO/uZmc/M7M7nNe/r4xBCCBBCCCGENGGiwt0BQgghhBArKFgIIYQQ0uShYCGEEEJIk4eChRBCCCFNHgoWQgghhDR5KFgIIYQQ0uShYCGEEEJIk4eChRBCCCFNHgoWQgghhDR5KFgIIYQQ0uShYCGkieBwOGz9rV69usH7qqysxFNPPWV7W6tXrzbsz2233dbg/uixa9cuPPXUUzh06FBItt8QpPPx4YcfhrsrhJw1xIS7A4QQD++++67q/TvvvIOVK1f6LO/Tp0+D91VZWYmnn34aAHD55ZfbXu/BBx/ExRdfrFrWvXv3BvdHj127duHpp5/G5ZdfHrJ9EEKaDxQshDQRfvvb36rer1+/HitXrvRZHk4uvfRS3HLLLeHuRoOoqKhAixYtwt0NQoif0CVESDPC7XZj3rx5uOCCC5CQkID09HT8/ve/x5kzZ1TtNm3ahOzsbKSlpSExMRE9evTA3XffDQA4dOgQ2rVrBwB4+umnZdfOU0891eD+bdiwAaNHj0ZKSgqSkpJw2WWXYe3atao2hw8fxv3334/zzz8fiYmJaNu2LcaOHaty/bz99tsYO3YsAOCKK67wcYcZ9bd79+646667VNtxOBxYs2YN7r//frRv3x6dO3eWP//yyy9x6aWXokWLFmjVqhWuu+46/PTTTw0+DxK//PILxo4dizZt2iApKQnDhw/H559/7tPu5ZdfxgUXXICkpCS0bt0aF110EZYsWSJ/XlZWhocffhjdu3dHfHw82rdvj6uvvhpbtmwJWl8JaerQwkJIM+L3v/893n77bUyaNAkPPvggDh48iPnz52Pr1q1Yu3YtYmNjUVRUhFGjRqFdu3Z47LHHkJqaikOHDuHjjz8GALRr1w6vvvoq7rvvPtx00024+eabAQAXXnih5f7Lyspw8uRJ1bI2bdogKioK33zzDa655hoMGTIEs2bNQlRUFN566y1ceeWV+O677zB06FAAwA8//IB169bhtttuQ+fOnXHo0CG8+uqruPzyy7Fr1y4kJSXhV7/6FR588EG89NJLePzxx2U3WKDusPvvvx/t2rXDzJkzUVFRAcDjgps4cSKys7Px3HPPobKyEq+++iouueQSbN26tcFuqMLCQowYMQKVlZV48MEH0bZtWyxevBg33HADPvzwQ9x0000AgNdffx0PPvggbrnlFjz00EOorq7Gjh07sGHDBtx+++0AgHvvvRcffvghpk6dir59++LUqVP4/vvvsXv3bgwePLhB/SSk2SAIIU2SBx54QCh/ot99950AIN577z1VuxUrVqiWf/LJJwKA+OGHHwy3feLECQFAzJo1y1ZfVq1aJQDo/h08eFC43W7Rq1cvkZ2dLdxut7xeZWWl6NGjh7j66qtVy7Tk5uYKAOKdd96Rly1btkwAEKtWrfJpb9T3bt26iYkTJ8rv33rrLQFAXHLJJaKurk5eXlZWJlJTU8WUKVNU6xcUFIiUlBSf5UbnY9myZYZtHn74YQFAfPfdd6r99ujRQ3Tv3l24XC4hhBA33nijuOCCC0z3l5KSIh544AHTNoREOnQJEdJMWLZsGVJSUnD11Vfj5MmT8t+QIUPQsmVLrFq1CgCQmpoKAPjss89QW1sb1D7MnDkTK1euVP1lZGRg27Zt2LdvH26//XacOnVK7ltFRQWuuuoqfPvtt3C73QCAxMREeXu1tbU4deoUevbsidTU1JC5OKZMmYLo6Gj5/cqVK1FcXIzx48erzmV0dDSGDRsmn8uG8MUXX2Do0KG45JJL5GUtW7bEPffcg0OHDmHXrl0APNfr6NGj+OGHHwy3lZqaig0bNuD48eMN7hchzRW6hAhpJuzbtw8lJSVo37697udFRUUAgMsuuwy/+c1v8PTTT+Mf//gHLr/8cowZMwa333474uPjG9SH/v37IysrS7dvADBx4kTDdUtKStC6dWtUVVVh9uzZeOutt3Ds2DEIIVRtQkGPHj10+3vllVfqtk9OTm7wPg8fPoxhw4b5LJfcWocPH0a/fv3w6KOP4uuvv8bQoUPRs2dPjBo1CrfffjtGjhwpr/P8889j4sSJ6NKlC4YMGYJrr70WEyZMwDnnnNPgfhLSXKBgIaSZ4Ha70b59e7z33nu6n0uBtFJ9kPXr1+O///0v/ve//+Huu+/GnDlzsH79erRs2TIkfQOAF154AQMHDtRtI+33D3/4A9566y08/PDDyMzMREpKilzPRdpOoLhcLt3lSquOsr/vvvsuMjIyfNrHxDTerbFPnz7Yu3cvPvvsM6xYsQIfffQRXnnlFcycOVNOPb/11ltx6aWX4pNPPsFXX32FF154Ac899xw+/vhjXHPNNY3WV0LCCQULIc2Ec889F19//TVGjhzpMwDrMXz4cAwfPhzPPvsslixZgjvuuAMffPABfve738HhcAS9b4DHMqFngVHy4YcfYuLEiZgzZ468rLq6GsXFxap2Zn1s3bq1T3un04n8/Hy/+tu+fXvL/gZKt27dsHfvXp/le/bskT+XaNGiBcaNG4dx48bB6XTi5ptvxrPPPosZM2YgISEBANChQwfcf//9uP/++1FUVITBgwfj2WefpWAhZw2MYSGkmXDrrbfC5XLhmWee8fmsrq5OHsDPnDmjcrMAkK0eNTU1AICkpCQA8Bn0A2XIkCE499xz8fe//x3l5eU+n584cUJ+HR0d7dO/l19+2cc6ItVK0evjueeei2+//Va1bNGiRYYWFi3Z2dlITk7G//t//083zkfZ30C59tprsXHjRuTm5srLKioqsGjRInTv3h19+/YFAJw6dUq1XlxcHPr27QshBGpra+FyuXxcZe3bt0fHjh3l60nI2QAtLIQ0Ey677DL8/ve/x+zZs7Ft2zaMGjUKsbGx2LdvH5YtW4YXX3wRt9xyCxYvXoxXXnkFN910E84991yUlZXh9ddfR3JyMq699loAHhdJ3759sXTpUpx33nlo06YN+vXrh379+gXUt6ioKLzxxhu45pprcMEFF2DSpEno1KkTjh07hlWrViE5ORn//e9/AQDXX3893n33XaSkpKBv377Izc3F119/jbZt26q2OXDgQERHR+O5555DSUkJ4uPjceWVV6J9+/b43e9+h3vvvRe/+c1vcPXVV2P79u343//+h7S0NFv9TU5Oxquvvoo777wTgwcPxm233YZ27dohLy8Pn3/+OUaOHIn58+dbbuejjz6SLSZKJk6ciMceewzvv/8+rrnmGjz44INo06YNFi9ejIMHD+Kjjz5CVJTneXHUqFHIyMjAyJEjkZ6ejt27d2P+/Pm47rrr0KpVKxQXF6Nz58645ZZbMGDAALRs2RJff/01fvjhB5WVipCIJ7xJSoQQI7RpzRKLFi0SQ4YMEYmJiaJVq1aif//+4pFHHhHHjx8XQgixZcsWMX78eNG1a1cRHx8v2rdvL66//nqxadMm1XbWrVsnhgwZIuLi4ixTnO2k8QohxNatW8XNN98s2rZtK+Lj40W3bt3ErbfeKnJycuQ2Z86cEZMmTRJpaWmiZcuWIjs7W+zZs8cnJVkIIV5//XVxzjnniOjoaFWKs8vlEo8++qhIS0sTSUlJIjs7W+zfv98wrdkoxXvVqlUiOztbpKSkiISEBHHuueeKu+66y+dcGZ0Poz8plfnAgQPilltuEampqSIhIUEMHTpUfPbZZ6ptvfbaa+JXv/qVfM7OPfdcMX36dFFSUiKEEKKmpkZMnz5dDBgwQLRq1Uq0aNFCDBgwQLzyyiumfSQk0nAIobHNEkIIIYQ0MRjDQgghhJAmDwULIYQQQpo8FCyEEEIIafJQsBBCCCGkyUPBQgghhJAmDwULIYQQQpo8EVE4zu124/jx42jVqlXQS44TQgghJDQIIVBWVoaOHTvKxRSNiAjBcvz4cXTp0iXc3SCEEEJIABw5cgSdO3c2bRMRgqVVq1YAPAccjGnhCSGEEBJ6SktL0aVLF3kcNyMiBIvkBkpOTqZgIYQQQpoZdsI5GHRLCCGEkCYPBQshhBBCmjwULIQQQghp8kREDAshhJDwIoRAXV0dXC5XuLtCmhjR0dGIiYlpcNkRChZCCCENwul0Ij8/H5WVleHuCmmiJCUloUOHDoiLiwt4GwEJlgULFuCFF15AQUEBBgwYgJdffhlDhw41bL9s2TI8+eSTOHToEHr16oXnnnsO1157rarN7t278eijj2LNmjWoq6tD37598dFHH6Fr166BdJEQQkgj4Ha7cfDgQURHR6Njx46Ii4tjAU8iI4SA0+nEiRMncPDgQfTq1cuyQJwRfguWpUuXYtq0aVi4cCGGDRuGefPmITs7G3v37kX79u192q9btw7jx4/H7Nmzcf3112PJkiUYM2YMtmzZgn79+gEADhw4gEsuuQSTJ0/G008/jeTkZPz0009ISEgI6KAIIYQ0Dk6nE263G126dEFSUlK4u0OaIImJiYiNjcXhw4fhdDoDHtsdQgjhzwrDhg3DxRdfjPnz5wOA/EX9wx/+gMcee8yn/bhx41BRUYHPPvtMXjZ8+HAMHDgQCxcuBADcdtttiI2NxbvvvmurDzU1NaipqZHfS4VnSkpKWIeFEEIakerqahw8eBA9evTgQyYxxOh7UlpaipSUFFvjt192GafTic2bNyMrK8u7gagoZGVlITc3V3ed3NxcVXsAyM7Oltu73W58/vnnOO+885CdnY327dtj2LBhWL58uWE/Zs+ejZSUFPmPZfkJIYSQyMYvwXLy5Em4XC6kp6erlqenp6OgoEB3nYKCAtP2RUVFKC8vx9/+9jeMHj0aX331FW666SbcfPPNWLNmje42Z8yYgZKSEvnvyJEj/hwGIYQQQpoZYc8ScrvdAIAbb7wRf/zjHwEAAwcOxLp167Bw4UJcdtllPuvEx8cjPj6+UftJCCGEkPDhl4UlLS0N0dHRKCwsVC0vLCxERkaG7joZGRmm7dPS0hATE4O+ffuq2vTp0wd5eXn+dI8QQgixzV133QWHw+Hzt3///qBs/+2330ZqampQthUod911F8aMGRPWPgQLvwRLXFwchgwZgpycHHmZ2+1GTk4OMjMzddfJzMxUtQeAlStXyu3j4uJw8cUXY+/evao2P//8M7p16+ZP94JOncuNpz79CU99+hOqa1kMiRBCIo3Ro0cjPz9f9dejR49wd8uH2tracHch7PidDD1t2jS8/vrrWLx4MXbv3o377rsPFRUVmDRpEgBgwoQJmDFjhtz+oYcewooVKzBnzhzs2bMHTz31FDZt2oSpU6fKbaZPn46lS5fi9ddfx/79+zF//nz897//xf333x+EQwwclxB4e90hvL3uEJwud1j7QgghzQUhBCqddWH58zPxFfHx8cjIyFD9RUdHAwD+85//YPDgwUhISMA555yDp59+GnV1dfK6c+fORf/+/dGiRQt06dIF999/P8rLywEAq1evxqRJk1BSUiJbbp566ikAnpmJtYklqampePvttwEAhw4dgsPhwNKlS3HZZZchISEB7733HgDgjTfeQJ8+fZCQkIDevXvjlVdeCeAKeVmzZg2GDh2K+Ph4dOjQAY899pjqGD/88EP0798fiYmJaNu2LbKyslBRUSEf49ChQ9GiRQukpqZi5MiROHz4cIP6Y4bfMSzjxo3DiRMnMHPmTBQUFGDgwIFYsWKFHFibl5enKgozYsQILFmyBE888QQef/xx9OrVC8uXL5drsADATTfdhIULF2L27Nl48MEHcf755+Ojjz7CJZdcEoRDDBwHWPyIEEL8parWhb4z/xeWfe/6SzaS4hoenvndd99hwoQJeOmll3DppZfiwIEDuOeeewAAs2bNAuDJkn3ppZfQo0cP/PLLL7j//vvxyCOP4JVXXsGIESMwb948zJw5U/YgtGzZ0q8+PPbYY5gzZw4GDRoki5aZM2di/vz5GDRoELZu3YopU6agRYsWmDhxot/HeOzYMVx77bW466678M4772DPnj2YMmUKEhIS8NRTTyE/Px/jx4/H888/j5tuugllZWX47rvv5GkYxowZgylTpuD999+H0+nExo0bQ1o0MKCrOnXqVJWFRMnq1at9lo0dOxZjx4413ebdd9+Nu+++O5DuNAp+inZCCCHNgM8++0wlJK655hosW7YMTz/9NB577DFZCJxzzjl45pln8Mgjj8iC5eGHH5bX6969O/7617/i3nvvxSuvvIK4uDikpKTA4XAYxnha8fDDD+Pmm2+W38+aNQtz5syRl/Xo0QO7du3Ca6+9FpBgeeWVV9ClSxfMnz8fDocDvXv3xvHjx/Hoo49i5syZyM/PR11dHW6++WY5RKN///4AgNOnT6OkpATXX389zj33XACe2NNQEvYsoaaMSihSsBBCiC0SY6Ox6y/ZYdu3P1xxxRV49dVX5fctWrQAAGzfvh1r167Fs88+K3/mcrlQXV2NyspKJCUl4euvv8bs2bOxZ88elJaWoq6uTvV5Q7nooovk1xUVFThw4AAmT56MKVOmyMvr6uqQkpIS0PZ3796NzMxMlVVk5MiRKC8vx9GjRzFgwABcddVV6N+/P7KzszFq1CjccsstaN26Ndq0aYO77roL2dnZuPrqq5GVlYVbb70VHTp0CPyALaBgMUGtV6hYCCHEDg6HIyhumcagRYsW6Nmzp8/y8vJyPP300yoLh0RCQgIOHTqE66+/Hvfddx+effZZtGnTBt9//z0mT54Mp9NpKlgcDodPrI1eUK0knqT+AMDrr7+OYcOGqdpJMTfBJjo6GitXrsS6devw1Vdf4eWXX8b//d//YcOGDejRowfeeustPPjgg1ixYgWWLl2KJ554AitXrsTw4cND0p/m8Y0KE5zAixBCzk4GDx6MvXv36ooZANi8eTPcbjfmzJkjx23++9//VrWJi4uDy+WbYdquXTvk5+fL7/ft22c503V6ejo6duyIX375BXfccYe/h6NLnz598NFHH0EIIY93a9euRatWrdC5c2cAnnFw5MiRGDlyJGbOnIlu3brhk08+wbRp0wAAgwYNwqBBgzBjxgxkZmZiyZIlFCzhhjEshBBy9jBz5kxcf/316Nq1K2655RZERUVh+/bt2LlzJ/7617+iZ8+eqK2txcsvv4xf//rXWLt2rTw/nkT37t1RXl6OnJwcDBgwAElJSUhKSsKVV16J+fPnIzMzEy6XC48++ihiY2Mt+/T000/jwQcfREpKCkaPHo2amhps2rQJZ86ckQWEHiUlJdi2bZtqWdu2bXH//fdj3rx5+MMf/oCpU6di7969mDVrFqZNm4aoqChs2LABOTk5GDVqFNq3b48NGzbgxIkT6NOnDw4ePIhFixbhhhtuQMeOHbF3717s27cPEyZMCOh820JEACUlJQKAKCkpCep2XS636PboZ6Lbo5+JU+U1Qd02IYREAlVVVWLXrl2iqqoq3F3xm4kTJ4obb7zR8PMVK1aIESNGiMTERJGcnCyGDh0qFi1aJH8+d+5c0aFDB5GYmCiys7PFO++8IwCIM2fOyG3uvfde0bZtWwFAzJo1SwghxLFjx8SoUaNEixYtRK9evcQXX3whUlJSxFtvvSWEEOLgwYMCgNi6datPn9577z0xcOBAERcXJ1q3bi1+9atfiY8//tj0GOGJwlT9TZ48WQghxOrVq8XFF18s4uLiREZGhnj00UdFbW2tEEKIXbt2iezsbNGuXTsRHx8vzjvvPPHyyy8LIYQoKCgQY8aMER06dBBxcXGiW7duYubMmcLlcun2w+h74s/47fdszU0Rf2Z79AchBHrM+AIAsPmJLLRtyekACCFECWdrJnZo9NmazzYYw0IIIYQ0DShYbNLszVCEEEJIM4aCxSbN33FGCCGENF8oWCyQvEKsw0IIIYSEDwoWQgghDSYC8jdICAnG94OCxQI57Ja/RUII8UGqH2JV+Iyc3UjfDzv1Zoxg4TgLHA4HIOgQIoQQPaKjo5GamoqioiIAQFJSEjMsiYwQApWVlSgqKkJqamqDphGgYLGAPztCCDFHmo1YEi2EaElNTQ141moJChab0D1LCCH6OBwOdOjQAe3bt9edxI+c3cTGxgZlgkYKFguYJUQIIfaIjo4O2czBhDDo1gJHvVOIFhZCCCEkfFCwWMEgFkIIISTsULDYhAYWQgghJHxQsFggGVhYFIkQQggJHxQsFshBt9QrhBBCSNigYLHAwSAWQgghJOxQsBBCCCGkyUPBYgFdQoQQQkj4oWCxQA66ZZ4QIYQQEjYoWCzgJF6EEEJI+KFgsQldQoQQQkj4oGCxwOsSIoQQQki4oGCxQg66pWQhhBBCwgUFCyGEEEKaPBQsFtAlRAghhIQfChYLpCwheoQIIYSQ8EHBYoE3q5mKhRBCCAkXFCyEEEIIafJQsFggx7DQwEIIIYSEDQoWC+QYljD3gxBCCDmboWCxgIX5CSGEkPBDwWITuoQIIYSQ8EHBYoGUJcTZmgkhhJDwQcFiCeuwEEIIIeGGgsUCRwiDWM5UOPH22oM4VV4Tup0QQgghEQAFi01CYWF5YMkWPPXfXbj3X5uDv3FCCCEkgqBgscA7l1DwFcu6A6cAAD8cOhP0bRNCCCGRBAWLBXLQLWNYCCGEkLBBwWKBg5VYCCGEkLATkGBZsGABunfvjoSEBAwbNgwbN240bb9s2TL07t0bCQkJ6N+/P7744gvV53fddRccDofqb/To0YF0jRBCCCERiN+CZenSpZg2bRpmzZqFLVu2YMCAAcjOzkZRUZFu+3Xr1mH8+PGYPHkytm7dijFjxmDMmDHYuXOnqt3o0aORn58v/73//vuBHVGQoUuIEEIICT9+C5a5c+diypQpmDRpEvr27YuFCxciKSkJb775pm77F198EaNHj8b06dPRp08fPPPMMxg8eDDmz5+vahcfH4+MjAz5r3Xr1oEdUZAJZdAtIYQQQuzhl2BxOp3YvHkzsrKyvBuIikJWVhZyc3N118nNzVW1B4Ds7Gyf9qtXr0b79u1x/vnn47777sOpU6cM+1FTU4PS0lLVHyGEEEIiF78Ey8mTJ+FyuZCenq5anp6ejoKCAt11CgoKLNuPHj0a77zzDnJycvDcc89hzZo1uOaaa+ByuXS3OXv2bKSkpMh/Xbp08ecw/EKerZkGFkIIISRsxIS7AwBw2223ya/79++PCy+8EOeeey5Wr16Nq666yqf9jBkzMG3aNPl9aWlpSEULgJA6hKKYiEQIIYSY4peFJS0tDdHR0SgsLFQtLywsREZGhu46GRkZfrUHgHPOOQdpaWnYv3+/7ufx8fFITk5W/YUKb9Bt6CRLTBSzywkhhBAz/Bop4+LiMGTIEOTk5MjL3G43cnJykJmZqbtOZmamqj0ArFy50rA9ABw9ehSnTp1Chw4d/Oles4V6hRBCCDHH76Fy2rRpeP3117F48WLs3r0b9913HyoqKjBp0iQAwIQJEzBjxgy5/UMPPYQVK1Zgzpw52LNnD5566ils2rQJU6dOBQCUl5dj+vTpWL9+PQ4dOoScnBzceOON6NmzJ7Kzs4N0mIEjW1hCuA9aWAghhBBz/I5hGTduHE6cOIGZM2eioKAAAwcOxIoVK+TA2ry8PEQpBuARI0ZgyZIleOKJJ/D444+jV69eWL58Ofr16wcAiI6Oxo4dO7B48WIUFxejY8eOGDVqFJ555hnEx8cH6TADR6p0G8qgW8awEEIIIeY4RCiDMxqJ0tJSpKSkoKSkJOjxLJe9sAqHT1Xio/syMaRbm6Buu/tjnwMAWifFYuvMUUHdNiGEENLU8Wf8pi+iCRBNlxAhhBBiCkdKC+RKtyG0Q0XzKhBCCCGmcKi0QC4cF8J9MOiWEEIIMYcjpQWNYWGhXiGEEELM4VDZBIh2ME2IEEIIMYOCxYpGqHQbzbxmQgghxBQKFgtkl1AI90HBQgghhJhDwWKBoxHcNUxrJoQQQszhSGkTpjUTQggh4YNDpQVel1AIY1gYdEsIIYSYQsFigaMRglgYw0IIIYSYQ8HSBKBgIYQQQsyhYLFAnq05hPugYCGEEELMoWCxwCHXYQndPihYCCGEEHMoWGwS7KBbt9u7PaY1E0IIIeZwpAwTdUrBQgMLIYQQYgoFiwXybM1Bdgm5aGEhhBBCbMOR0oJQZTXXut3yaxaOI4QQQszhUGmBI0STH7pcSgsLfUKEEEKIGRQsYUIZw9IY8xURQgghzRkKFgtkC0uQt6uMYQlpkRdCCCEkAqBgsUAqHBdsUVGniGEhhBBCiDkULBZ4LSzBVSx1ihiWUE6sSAghhEQCFCxhQhnDEsoquoQQQkgkQMFigZzWHMI6LBQshBBCiDkULFaEqHCcMoaFLiFCCCHEHAoWC0JVOE6VJUQIIYQQUyhYwkStiy4hQgghxC4ULBaErNKtMoYlqFsmhBBCIg8KFgtC5RJSxbBQsRBCCCGmULCECXUMCxULIYQQYgYFiwWOkGUJUaQQQgghdqFgscA7LWEIK91SuxBCCCGmULBY4A26De52Xao6LIQQQggxg4IlTKhL81OyEEIIIWZQsFggzdYcysJxlCuEEEKIORQsVoTIJaSMYSGEEEKIORQsFnjrsISwcBy1CyGEEGIKBUuI+XxHPn63+AeUVNaqltcy6JYQQgixDQWLBQ3NEnpgyRZ8vbsI83J+Vi13MeiWEEIIsQ0FiwXBCro9U+FUvWcMCyGEEGIfChYLgjX5oXZtN60qhBBCiG0oWJoA1C6EEEKIORQsFjgc1m1sbUfzXilSgp2BRAghhEQaFCwWyDEsQdYUSpFCCwshhBBiDgWLTRpqBXFoTDUUKYQQQoh9AhIsCxYsQPfu3ZGQkIBhw4Zh48aNpu2XLVuG3r17IyEhAf3798cXX3xh2Pbee++Fw+HAvHnzAula0AmWS0iLUq9QvBBCCCHm+C1Yli5dimnTpmHWrFnYsmULBgwYgOzsbBQVFem2X7duHcaPH4/Jkydj69atGDNmDMaMGYOdO3f6tP3kk0+wfv16dOzY0f8jCTENFRWMYSGEEEICx2/BMnfuXEyZMgWTJk1C3759sXDhQiQlJeHNN9/Ubf/iiy9i9OjRmD59Ovr06YNnnnkGgwcPxvz581Xtjh07hj/84Q947733EBsbG9jRhADJlcMYFkIIISR8+CVYnE4nNm/ejKysLO8GoqKQlZWF3Nxc3XVyc3NV7QEgOztb1d7tduPOO+/E9OnTccEFF1j2o6amBqWlpaq/UNNgTaExsagtLIQQQggxwy/BcvLkSbhcLqSnp6uWp6eno6CgQHedgoICy/bPPfccYmJi8OCDD9rqx+zZs5GSkiL/denSxZ/D8IsQhbAQQgghxA/CniW0efNmvPjii3j77bd9MmmMmDFjBkpKSuS/I0eOhKx/wap0q0XQxEIIIYTYxi/BkpaWhujoaBQWFqqWFxYWIiMjQ3edjIwM0/bfffcdioqK0LVrV8TExCAmJgaHDx/Gn/70J3Tv3l13m/Hx8UhOTlb9hQpJQjVUUzhgnNbMoFtCCCHEHL8ES1xcHIYMGYKcnBx5mdvtRk5ODjIzM3XXyczMVLUHgJUrV8rt77zzTuzYsQPbtm2T/zp27Ijp06fjf//7n7/H02xgWjMhhBBinxh/V5g2bRomTpyIiy66CEOHDsW8efNQUVGBSZMmAQAmTJiATp06Yfbs2QCAhx56CJdddhnmzJmD6667Dh988AE2bdqERYsWAQDatm2Ltm3bqvYRGxuLjIwMnH/++Q09vgYju6mCnSVEjxAhhBBiG78Fy7hx43DixAnMnDkTBQUFGDhwIFasWCEH1ubl5SEqymu4GTFiBJYsWYInnngCjz/+OHr16oXly5ejX79+wTuKEOJ1CQU5hoUyhRBCCLGN34IFAKZOnYqpU6fqfrZ69WqfZWPHjsXYsWNtb//QoUOBdCskeINug7MdCZWFhT4hQgghxJSwZwkRuoQIIYQQKyhYLKmvdBvkrTLolhBCCLEPBYsFQXMJaRcoNki9QgghhJhDwWJB6IJuCSGEEGIXCpZGwizolj4hQgghxBwKFguC5RLSopqtObib9qHK6WImEiGEkGYNBYsFjiAF3ZqW5g+hligoqUafmSsw4c2NodsJIYQQEmIoWOzSQFWhjYERJp8Fk/9sOwYA+G7fyZDtgxBCCAk1FCwW2JxA2m/ooSGEEELsQ8FiQbCmEvJxCSljWCheCCGEEFMoWCyQY1hCWDmOgoU0FCEEPtl6FHsKSsPdFUIICQkBzSV0NtLQLBuftGaD18EmVC4t0rRYvfcE/rh0OwDg0N+uC3NvCCEk+NDCYkXIYlgax6xC683ZwU/HS8LdBUIICSkULBZ4K902cDucrZkQQggJGAoWCxyO0MSwNJZEoUuIEEJIJEDBYpOgx9wy6JYEEX6HCCGRDgWLBcEzUJikNXMqREIIIcQUChYLvHMJBXm2ZmoUEkTo+iOERDoULBYEaxwwG1BCKV60BesIIYSQ5ggFS5hQWmxCaWyhu4kQQkgkQMFiQWNkCTGtmRBCCDGHgsUCbx2W0MWwUK4QQggh5lCwWCEH3QZlMzKN5aphDAshhJBIgIIlTIjGmkyInBXQq0gIiXQoWCyQZ2sO8napVwghhBD7ULBY4GiAS0gZTMu5hEgoYR0WQkikQ8Fik0BiTtymqzROWjMhhBASCVCwWNCQB1eVhUVbmp8qhRBCCLENBYsFDXIJmX3GyQ8JIYQQ21CwWNCQtGC3WQxLI01+yNgGQgghkQAFi00CCYw1s6LQwkIIIYTYh4LFgoZYKMyEiLo0f+D7IATgd4gQEvlQsFjQsBgWe2nNhBBCCDGHgsWSwAvHmaU1cxZlQgghxD4ULDZpcOE4nw/12xESCAyuJoREOhQsFjRkIDC3sOi/JoQQQogvFCwWSHolIBeOYhWHQ1s4TpHW3EiKhZYcQgghzRUKFguCFXTr+1njQ71CCCGkuULBYpOgB90qY1gaSb5QrxBCCGmuULBY0JBKt2YumHDUYXHTxBKx8NISQiIdChYL5NCTAEYEcwtL48/WzEGNEEJIc4WCxQJv0K3/qOYL0qiFsMSw0ClECCGkmULBEkLUcSraD/XbhRJaWCIX1mEhhEQ6FCwWSOnIgRWO877Wxo+IRqrEokynpmAhhBDSXKFgsUkg7hS3Sa2VcMzWTJcQIYSQ5goFi00Cq8Oi/9qsXbAJR4E6QgghJNgEJFgWLFiA7t27IyEhAcOGDcPGjRtN2y9btgy9e/dGQkIC+vfvjy+++EL1+VNPPYXevXujRYsWaN26NbKysrBhw4ZAuhZ0GhIbYCYWwiEeqFcIIYQ0V/wWLEuXLsW0adMwa9YsbNmyBQMGDEB2djaKiop0269btw7jx4/H5MmTsXXrVowZMwZjxozBzp075TbnnXce5s+fjx9//BHff/89unfvjlGjRuHEiROBH1mQcDRgtma1KDGOYQllyXxlDAvrsEQuvLSEkEjHb8Eyd+5cTJkyBZMmTULfvn2xcOFCJCUl4c0339Rt/+KLL2L06NGYPn06+vTpg2eeeQaDBw/G/Pnz5Ta33347srKycM455+CCCy7A3LlzUVpaih07dgR+ZEGiQaX5TeJUTDOIQgQHtbMDzhlFCIlE/BIsTqcTmzdvRlZWlncDUVHIyspCbm6u7jq5ubmq9gCQnZ1t2N7pdGLRokVISUnBgAEDdNvU1NSgtLRU9Rdqgh50q3zdaIqlkfZDwopZwUJCCGmu+CVYTp48CZfLhfT0dNXy9PR0FBQU6K5TUFBgq/1nn32Gli1bIiEhAf/4xz+wcuVKpKWl6W5z9uzZSElJkf+6dOniz2H4RUPKW6iDbjUuIZX1JYQuIcVruoQiF2WsFS0shJBIpMlkCV1xxRXYtm0b1q1bh9GjR+PWW281jIuZMWMGSkpK5L8jR46ErF+OBpS6NbOwNJa5o3GqvZCmBK8zISQS8UuwpKWlITo6GoWFharlhYWFyMjI0F0nIyPDVvsWLVqgZ8+eGD58OP75z38iJiYG//znP3W3GR8fj+TkZNVfqJALxwWwrlmcSnhiWDiUnQ3wMhNCIhG/BEtcXByGDBmCnJwceZnb7UZOTg4yMzN118nMzFS1B4CVK1catldut6amxp/uhZTABnt7MSyhVCzhmGSRhBcWCCSERCIx/q4wbdo0TJw4ERdddBGGDh2KefPmoaKiApMmTQIATJgwAZ06dcLs2bMBAA899BAuu+wyzJkzB9dddx0++OADbNq0CYsWLQIAVFRU4Nlnn8UNN9yADh064OTJk1iwYAGOHTuGsWPHBvFQA6MhMSxukziVcAgJxrCcHfAyE0IiEb8Fy7hx43DixAnMnDkTBQUFGDhwIFasWCEH1ubl5SEqymu4GTFiBJYsWYInnngCjz/+OHr16oXly5ejX79+AIDo6Gjs2bMHixcvxsmTJ9G2bVtcfPHF+O6773DBBRcE6TAbQLDSmrWfqdqFboQRDGI5K6BIIYREOn4LFgCYOnUqpk6dqvvZ6tWrfZaNHTvW0FqSkJCAjz/+OJBuNAoNKRynDro1zhIKJaoCdY2zSxJmKF4IIZFIk8kSauqE1MISSIcC6ANdQmcHvM6EkEiEgsWChswlZD5bc+NMShiWAnUkrPAyE0IiEQoWC7xlWHyHAX9iT8xnaw7dEONmltBZAQvHEUIiHQoWC4zmEnp3/WEMn52D/UVlhuvajWEJqYWlkSrqkqYDrzIhJBKhYAmQJ5fvRGFpDZ5YvtOwjXkMS+MPK9QrZwe8zoSQSISCxQKHRSWWOpfx6GBWHK6xKt02VqwMaULwOhNCIhAKFgu8LqEGztZsMvlhaCvdKnfDkSxS4XUmhEQ6FCw2afBcQj6l+Y3FTDBhltDZB68zISQSoWCxQM4SCqgOi1las/7rYKO08rA+x9kBrzMhJBKhYLGiAYVYlMOGdhBpvBmaG3+fJLzwOhNCIhEKFgvM6rBY4XYr3T4aGivoVvmaI1nEwutMCIl0KFhsEpBLyGR9VQxLIxViYR2WyIVBt4SQSIeCxYJglebX2lEaLa3ZsAckkhCNZbIjhJAwQcFigdVszaZjg2mWUOPQWMG9JLwwVokQEulQsFhgVJrfDmbWjcab/LBx0qdJeGEMCyEk0qFgsU0DC8eFKUtIEfcLt7uRdhokhBD4YGMedh4rCXdXmj4mRQoJISQSoGCxoAEhLOZzCfnUZQnNINOcgzG/3l2Exz7+Ede//H1Y9r/jaDH+8P5WHD1TGZb9+4NKmDavy0wIIbaICXcHmjoNcQm5Tdw+egKmIQG+RqizkYK//VCyt6A0rPu/Yf5aAMCR05VY/sDIsPbFikbLOiOEkDBBC4sFjnoVEewYlkZTDwy6bTAHTpSHuwuWMLiaEBLpULDYJBB3ivAjhiVUY4xaNHEki1R4ZQkhkQ4FSwgxnfyw0WJYmq9LqMn0t6n0wwRaWAghkQ4FiwUNi2HxvtZaN3zfhwZ1H0ikwvR1QkikQ8Fik0CGALuzNeu9DxbK7Ta3WXxDEYQcsdDCQgiJcChYLJAr3RoMAmauHNO5hBot5rb5uoSIfTgFAyEk0qFgsaAhT/kqC4uFCyhUZny1SGm6Q5kQAmcqnJplYepMM0Q5M3hzs6QRQogdKFgskPRKYFlC+q89740nQwwVTXkce+rTnzDomZX46qeCcHfFhyZ82mRYmp8QEulQsNilwUG34UEpjJpyBdTFuYcBAM//b6+8jDEs9mkuljRCCAkUChYL5CyhANZVWWXCFXSr2kfTH8iaokZpDueNsUqEkEiHgsUCRwOGUH/SmkOFanqARtlj8ODAax+zeasIISQSoGCxwFuHpaGVbrWfad43QtBtcwjGpBuo4TSDy0wIIX5DwWKTho4BVqX4G8Ml1BwevRti0QoVzeC0mWakEUJIJEDBYhPDOiwm66hna9ZmBTVOpdvm5ipQWlhobbEPs4QIIZEOBYsFjgaMmmp3jOYzn7ahn/6wuQ1kTaW/TaUfZrhV2WDNoMOEEOInFCwWeOuw+E/TSGv2vm4OA1lDBOLZDCc/JIREOhQsNmlo0K1OlK3Z26DR3LKEKFcCozlcW0IIaQgULBY0rDS/4rX2M5O2DeVkeQ22Hyn27UMzePRuijEszSGIlRYWQkikExPuDjR1GuISMivm5SMegjjIXPzs1xAC+Pj+Ec0uGFMpUppDf5sOzBIihEQ2tLBY4GhAqVvzwnGhQxrov993UmPlafoDWZNMa276p40WFkJIxEPBYpPgT37Y8O3b2X9zK9neVNxAzY3mlr5OCCH+QsFiQYNiWMxcQlqLSwhGGbdHsYR0H8HG6HQ3h/ibcKL+rvFcEUIiDwoWC+QYliDP1hzCEBbVNpXbbQ5pzUqFyHgW+yi/a015Vm5CCAkUChabGFa6NRscTCvdapuGwiUkmkRa85kKJ77ZUwiXjZFUaWFpbjVkwon69PBcEUIiDwoWK+of8wOJMQn3k65biCYRjHnjgrW4++1NeHvdIcu2Ri64cJ7K5jD8N7dYJUII8RcKFgsaEgOqtJpoLQSNMZeQW2i3G56RLO90JQDgix/zLdsanW9aWCxg0C0hJMKhYLFAzmpuaAyL5VxC/m/fCiG0oin4+2gswqpXmsF5a271dgghxF8oWGwSWOE44/UbJ61ZNLuBLMrAJ0QLiznCJF6KEEIigYAEy4IFC9C9e3ckJCRg2LBh2Lhxo2n7ZcuWoXfv3khISED//v3xxRdfyJ/V1tbi0UcfRf/+/dGiRQt07NgREyZMwPHjxwPpWtCRCpkFMgaYDSI+AqUx0pqbganAMIal6Xc9rJiJY0IIiQT8FixLly7FtGnTMGvWLGzZsgUDBgxAdnY2ioqKdNuvW7cO48ePx+TJk7F161aMGTMGY8aMwc6dOwEAlZWV2LJlC5588kls2bIFH3/8Mfbu3YsbbrihYUcWJEI2l5Cfo8rWvDP4v09+RHGl06/9u5uZS8io0m04LSzNQeg1heBqQggJJX4Llrlz52LKlCmYNGkS+vbti4ULFyIpKQlvvvmmbvsXX3wRo0ePxvTp09GnTx8888wzGDx4MObPnw8ASElJwcqVK3Hrrbfi/PPPx/DhwzF//nxs3rwZeXl5DTu6IOAdPgOodGsSCekjYCy2ddMr6/Dehjz85bNdtvfvFs1v8kMjmoPYsqLW5caR+gDkYOOmS4gQEuH4JVicTic2b96MrKws7waiopCVlYXc3FzddXJzc1XtASA7O9uwPQCUlJTA4XAgNTVV9/OamhqUlpaq/kKNYR0Wk3X8Khxnc4w5cKLCXkPUpzU3IeuAHWOVsUsojBaWIO16wj834tLnV2HVHn1rZEOgS4gQEun4JVhOnjwJl8uF9PR01fL09HQUFBTorlNQUOBX++rqajz66KMYP348kpOTddvMnj0bKSkp8l+XLl38OQy/aMDchxbWDYuYFgOi/XBRiSZSh8UfIjmGJfeXUwCAf60/HPyNN7PrTAgh/tKksoRqa2tx6623QgiBV1991bDdjBkzUFJSIv8dOXIkZH1qyOzBZlVmA7WwREfZ70+zLM2voDn3vbFRFY6jjYUQEoHE+NM4LS0N0dHRKCwsVC0vLCxERkaG7joZGRm22kti5fDhw/jmm28MrSsAEB8fj/j4eH+6HjhyHZaGDQLBmjvIKO1Xj6ZS6dYflMenLs0fhs6ECLuHIoTA5MWb0DopDnNuHWDRVv81IYRECn5ZWOLi4jBkyBDk5OTIy9xuN3JycpCZmam7TmZmpqo9AKxcuVLVXhIr+/btw9dff422bdv6061GIZAxwO02fuoNtNKtP4LFs4vwzyUkYafryjZneyDpgRMV+GZPET7actTy+M0y0gghJBLwy8ICANOmTcPEiRNx0UUXYejQoZg3bx4qKiowadIkAMCECRPQqVMnzJ49GwDw0EMP4bLLLsOcOXNw3XXX4YMPPsCmTZuwaNEiAB6xcsstt2DLli347LPP4HK55PiWNm3aIC4uLljHGhANma3ZrGibr4vIZgyLHy4ht9DO4tu8hrKmEkgarn1rU9LN4pfUcwk1r+tMCCF28FuwjBs3DidOnMDMmTNRUFCAgQMHYsWKFXJgbV5eHqKivIabESNGYMmSJXjiiSfw+OOPo1evXli+fDn69esHADh27Bg+/fRTAMDAgQNV+1q1ahUuv/zyAA8tODh0zAJ2BwS1hUC7DfP3RkT5E8MihLqvzWAcU8YMmc3FdLbhFgLRJvFUzewyE0KI3/gtWABg6tSpmDp1qu5nq1ev9lk2duxYjB07Vrd99+7dm/QToWxhUSyzG09hliUU6DH7kyXk1pbmbwZDmZFLKJwxLMH+fgayPSvB5m4q5ihCCAkRTSpLqCkTyFwtZmNIoGOKX1lCPoXjAtxpiFGeT6VFS+XOiqSo2wCwvna0RhFCIhsKFgv0AkXtW1iMXUI+lW9tblPPRWW0T7cIzDLU2BgW5Wui/Q0HViKkOQhTQghpCBQsFujpA3XJfePRQR1XYJ4VZL9wnLlgUVXX1cSwNFWXkEtpYVEsbyoxLE3hrFmJTXqECCGRDgWLTQJ5gjUPutXGtNjbppVLSFusrjk8ebsUo3FTjGEJNgGlyFtaWJglRAiJbChYLJCyVtRpo/bW9SeGxXYdFj8Ei3YuocYcxlxugXX7T6KsutayrdvAwtJUUrKbwvgv3BafG7wmhJBIIaAsobMJ/RiW4Kc1m6G0QFhlCWktKuGarfmttQfx189348LOKZZtlcJEHXTrv0iMVFyWFhb914QQEinQwmKTgOpcCMM3lpVvldS6vI/XVpVuhcYqEa6BbNmmowCAHUdLLNuqXEKK5eESW6HGbp6X9lqatjV5RwghkQAFi038GTzkdQzW131vsh2VYPEnhkU0jwqoboMYFm3G09mG8tr5F8MSsi4RQkjYoGCxQHJRBBLDop5LSI3Pe5Nt1rq8H1qVYfGJYVEJLfN1w4V6MDaowxJBo7DdI1FanqwOvzlcZ0IIaQgULBbo6YOACscFMF1zda0L764/jIMnKxTbMV9HndbctEq2OwycIer4DH2rQgTpFdv45xJq+unrhBDSEBh0a4HkojCKBTEbGszScn0HFd8tzft6HxauOaBaZh18aZIl1Iijvj+DpluRAeM2sBREkoXFLv6kdTPolhAS6dDCYhPlGGA7hsUkaNRO1tD3+0/4LLMqUe/WiKnmMHi5hJGoOrstLP5MTdCULGmEEBIKKFgskN0YAQwI6iqzms8s3hvhsnzSVjyVu0VAQitkGMTfKAdj9SCteB3uvgeRYBQe9NlmMwiuJoSQhkDBYoFVHRazgdQkqzngSrf+WFhc2tL8TXQcMzqfds9zpKK8dv7UYSGEkEiEgsUCSa8IAxOL2UChLZOvJNDxxWXpGlAMchoLS1Md04yyYbTurbMNf2J41AHeoekPIYSEEwoWmxgNpGb6wa8YFptDstGTdklVLT7cfBSlilL4Lnf4Csf5g1qY6Ge7nI1uDlVavD91WM5KeUcIiXSYJWSBwzeExfZAase6EeXwDNh6m9FLAzZyCU1dsgXf7TuJfp2S5WUewdL03Soq148ibiVSa4vYPRS7whjQnCuLeYcIIaQ5QguLJTqiwabVwih+RLlcKrVvV0sYWVi+23cSALDzWKm3rdves/Y7uYfwn23H7HUgBLjc+qJKLWQaR7EIIbD9SLGtSRsboy8SfrmEQtQfQggJJ7SwWOCtw6JvVTENujVydSiWey04Nl1CfgzcLp+5hHzXPXK6EjP/8xMA4MaBnWxvO5gYxfqEI4Zl5a5C3PPuZvRIa9FIezTGZWB50sPo+0kIIZECLSw2MQpqNBsajNJSles4TCYzbMhM0YBkYdFPGZYoqfJaEsI10KndQOHNEvp0+3EAUFUXDhcBB92GpjuEEBJWKFgskLOEDNxA9i0syuVKl5BvWzP8sbDsOFqichEJAZRW12LFzgJU17p82ocrTkRlSTAYeRtLSzXGbuwKQ7/qsFCxEEIiHAoWC/QsIHYHEnWsi35Do/l1DLfZgIBKAYHJb/+Ae/+1Gc+t2OO77TBZWGzFsESSYrGJX3VYVK+b0EEQQkiQoGCxidEDrHmWkLVLyG8LSwMGbiGAHw6dAQB8uPmo77ZDbGIxkmZGwcln++SHflX6PcvPFSEk8qFgsUAeZA2f/I3XNXYJKbYvZQmFIOjWtz/m6zYFC4swOLeN1bemZJ1QCzara+d93XSOgBBCggcFiwV6ga/2Y1j0BxzloGgSc6tLQwZuYfjGQ6gtLEYYxbA0h6J3ocSvOiyq4Oqz8GQRQiIeChYLdAvH2TS/G7uRvK/9rsOiGbnqXPaDWqyym8IVdGvsBmr8QbgpjfXaiSzN2+q/JoSQSIF1WGwiBFBUWo2nP9uF4ee0VSw3Hh3sFJiL0hFEZigFS0FJNa6asxo3DbZXP8Vq0G+s4mxajOcSavy4jFDtJ5CU8UAr3VKvEEIiEQoWC6QsHgGBxz/Zia93F+LzHfny52aDg9EgpRvDotNWz1ukHNz/+f0vqHC68K/1eSa9UOzXom8NCej1h+paF6KjHIiNjvLZr1F8UHOPYQlEC/oTw6J291GyEEIiD7qErFCohiOnK30+tluHxfPes0A5KPptYVFstNbl38Ck19VQlb83Oi01dS4M/MtXuPS5Vbr7NbKwNJbxx5+xfmveGfzq+VX46qcCy7aBCC5/jl8dI0UIIZEHBYsFysJxek/fZgNJrSa+RBpT9CwsdlEO7nV+FmVRz4TsQV0Dxa/NBcShk5WornWjoLRaPhaj2ZqVNMVy8/f+azPyTlfinnc3+3xW6awzrC9jF+U6/li/muCpIoSQBkPBYhOjQcBscCirrlO31fwHGlaHpbYuuBaWxnIJafdnJJqM5hgKJf7sp7pWXzCWVNWi78z/4bqXvvNuNxCXkB91WNRBt1QshJDIg4LFAm+dFH3MBodSzYy/sktIVZpftuHY6o9yEKv118KiE8SqEgihLhznUFtQXLKFxSCGxZ/CaSFG7zpLMThacg+cAgDsKSiTlzXUwuJPDR3KFUJIJELBYoHSYaM3ZpgNDnYsLHpzFZmhtEbUBSGGRbm9xqjDohejYpQN1JRiWPT2Hx9j9PPxz3Vopy+WszU3cF+EENLUoWCxQK7DYjCSmT05l2ksLG7ZwqLcvokFRye+Rem28T+GRfm6Xiw0MM7Cr/1rNi8JJKNKt+Fxc9i/znGGgsUXo9RtM/yZS8moSCFpHFxugc2HT+tOKkoICQ4ULA3EyI0ihECp1sKiY2KJ8vMKKPfnb5aQniXDKKU4FAjoWw2MLClGczGFEmMLi55LyH7AdMjrsPi9dRJMFq45gN+8moupS7aEuyuERCwULBbIdViE/qBgNFBU1boMXSzqtGY/K90qLSx+VLk12oeyi35uzn+0FhY56FbZH+sA3FBiHKvku8zIwmJ1nu2iPObS6lo89elP2Jp3xqCD5vsnoeXN7w8CAL7eXRTmnhASuVCwWGCVdWw0OJRW1fks00trjjIpHKeHqwEWFj3cjRjD4hZCnZWkE3QbihiWWpcb4xetx9++3BPwNnRdQpqg29MVTuwpKFUtk66rOijW3sEovxN/+3IP3l53CDe9sk6/reo1FQshJPKgYLHAm8Nj7PrRQ4pfUT6FS9vQDbq12R+1S8g/k4heJklDa4X4u3+9/bkNYliCZWH5Zk8Rcn85hYVrDli2NY5V8l2mzBISQiBzdg5Gz/sOu1XZQdJ/xXHZvGzKfZ6ucJq2tTu/FSGENFcoWGwihP5gZvTkL8WvpCTGqrbh+e9dycyCo1uaXxV069/IJNSP4T7bC71gUfdZDro1sqSoom4D36+zruG+Lqug25o6N2rq97Nmr9ctIAVGG1mO/N2nETqXlhBCIgoKFissSucbDSpSDZbkBO90TToxt4q5hOx1R/l07m8My7f7TvgsU4qnULuEhKFLyNumycaw6JxqpUuo0unNDqlSZIroBRYHksJuRTgmiiSEkMaEgsUCh66dw4vR2FCma2GpdwkpVrJyOWlpyFxCh0/5zoWkDnj1a3N+4xbq2jF6LiE74iWUGO1Hf1oG77JKZ53itVewSNcrEPHlj/AIxIJDCCHNCQoWmwihLymsYliSlYJF/u955XAoXEIBPHX7W4dFidSHxnUJCd1CdWpLQngtLC6Dc6onZJTuLaVIUZbsl61IAcQK+eUSokYhhEQ4FCwWOCxdQvrLpSyh5ATfGBZpYw4o0qb96JM0+DUkS0gvnib0WUL6AsmwDkuQys37M7+k0TnVEw/KoGe1YFFYWNy+VjW7ly3Qy8HCcY0PzzghoYeCxQJ5rBPQvStZWViULiFpfWkNf2dqlqiTBUvDg0lVWTuNEMOitGC4dAvH6cdiBGsQtjpGI9GmJ1iUbStrlC6hOp82/swLZLZPI5glRAiJdChYLLASFUbjX0X9ANZSEXSrLc3vgLL0v96+jfbpaezvXEJ6GM2UHArcQqj67HUJedsY1mEJUuesZqQ2CmTWW01pjalQWFj0XFn+lNn37tMPwWLwmhBCIgUKFpuYDQJ6A0tt/agVr6rDIv33xrBAs8wO0kDvb1qzEmlNVdZOI6Q1WxWOM34d+H6VgdNWbi9/XELKGCKlVUWJbiZUAHVYrFBbo+yvRwghzYWABMuCBQvQvXt3JCQkYNiwYdi4caNp+2XLlqF3795ISEhA//798cUXX6g+//jjjzFq1Ci0bdsWDocD27ZtC6RbIUE5+aHROKD79F1fk0NbXEzZ3gGH32nNgFdYmAXdDu3RBpf2SjP83FuB1bvM7RaoqXPh612FKK/RH4Dtonc4biHUdVh0C8dB93Wwgm6tRJ6xS0hnWwpxo4xh0dueCMDC4l8dFqH7moSWd3MP4duffcsFRArvbTiMb/YU6n72r/WH8fgnP4bclUyIhN+CZenSpZg2bRpmzZqFLVu2YMCAAcjOzkZRkf4cGuvWrcP48eMxefJkbN26FWPGjMGYMWOwc+dOuU1FRQUuueQSPPfcc4EfSYhQemX8mbFZGhiVE+RpYm4Bh/+VbgHvAG/mEopyeMv+m6HN2vnbl3vwu3c24b5/bfajR/YQwnd/gHGmUihug5YWFqMsIZ31lDFEFQYCz6rWjBn+jAPqYGX765HA2Zp3Bk/+5ydMeHNjRAY67zpeiv/7ZCfufnuT7udPLN+JJRvysEanvhMhocBvwTJ37lxMmTIFkyZNQt++fbFw4UIkJSXhzTff1G3/4osvYvTo0Zg+fTr69OmDZ555BoMHD8b8+fPlNnfeeSdmzpyJrKyswI8kRFhlCRl9Jg1maguL9L/eJRRgn6RB0GkSdBvlcCA6yngPei4htxD4YOMRAMB3+04G2Dtj7JXmh8/n2tf+otRtVoLFcMJKPQuLoq12Zm55exaZUGb4FcOiEiyRN3g2RY4VV4W7CyGlsKzaVruSytoQ94QQD34JFqfTic2bN6uERVRUFLKyspCbm6u7Tm5uro8Qyc7ONmxvh5qaGpSWlqr+Qo0Q/lW7lawfMdFRCtGjcQk51C4nvX3q4RICQgjTLKEoh8PUwiJtW1sfRG8VIYRuMOqKnQW4eu4anwn/pHX09mldmj/4MSyqlGKLDRlZrcyuMaDOElKtZxGnY4Z/aeahtUwRXyJeF9o8PhYqJI2FX4Ll5MmTcLlcSE9PVy1PT09HQUGB7joFBQV+tbfD7NmzkZKSIv916dIl4G1ZI9VJMf5R6j9911tYohzq1GjVlh2mFhxDF5TbM/Cb3SccDiDGxMIi4VIN5vpupN/+cwOumrsGNXXqOI17/7UZ+4rK8YclW337qNM3HwuLjrtEZWFRVeEN/KZY5/Yt5GanrRKrOiw1BvMVSQJNfVzBdwkx6Lbx4Wn2EOr6TYRINMssoRkzZqCkpET+O3LkSMj2ZadUilnKq8fCoi4Op7KwmExWZHQfcAlhOEBKOCxcQvI+NEGw2uN11rmxdv8pHD5Vib2KWYiV6AXo6g3wPjEsOi4ho3olDRmEldu0qg5sbGHRaatYqCwWp0Q/E8q0CzKBpzVzAGkMzibXm5nIPotOAwkzMdZNvKSlpSE6OhqFheqo8cLCQmRkZOiuk5GR4Vd7O8THxyM+Pj7g9f1BDor10yXkjWFxqLYBKNKaAR93kRLDjBW3QI3BACkR5QCibFlY1AJBa2E5U+mUXyfF2f+66PXdTml+9cCreN2Au6JqviSLlGIjN5tu6rqibbWBgPTWYfFdZoWddm63qLe2BUfckcAI9SmvdblR5xJIjIsO8Z70cQmBKIOou1CXQyBEwi8LS1xcHIYMGYKcnBx5mdvtRk5ODjIzM3XXyczMVLUHgJUrVxq2b6qY/Sb1PpKe1GNNY1isitLp79TlFoYDpESUw4FoG9YhbV0UrcY5Ve4VLIEGgSr3VadjTTGe8DA4MSzK6ro/HitB9j++xcpd+qmagaY1G1lY6nQsLHZPo51jvmXhOlz87NeqtGoOH42PKwhFHM24as4a9J21wjAbLdRofxeBzI1FSEPx2yU0bdo0vP7661i8eDF2796N++67DxUVFZg0aRIAYMKECZgxY4bc/qGHHsKKFSswZ84c7NmzB0899RQ2bdqEqVOnym1Onz6Nbdu2YdeuXQCAvXv3Ytu2bQ2KcwkWdsrn61pY6gfJmCiHd74g2cJSv23Ax/pitV2g3iUUJAuL260VLOp1TlXUyK/9mbtIr+9uod2f9N8rKNRZQubbs4vSaPLAki3YW1iGKe/op2rWGqgEPQuY0r1kJFik4w1kziY7x7wlrxglVbUqFyHHD/sIIXDkdGVAFjzlKkbp8MEi73QlhAB2HisJ6X6M0H5nVQ8ejGEhjYTfgmXcuHH4+9//jpkzZ2LgwIHYtm0bVqxYIQfW5uXlIT8/X24/YsQILFmyBIsWLcKAAQPw4YcfYvny5ejXr5/c5tNPP8WgQYNw3XXXAQBuu+02DBo0CAsXLmzo8TUYVR0Wg2dX3aBbXQuL1F4ysUD2CekLFv0+ud3CNKUZ8AgtW0G3msBWrUBTWlj8Ca7Tayu0heOkOZE0bb0F9gJ3c2w7UowFq/aj1uX2y2Rt7IZTv/dkaXnb1tTqX4+G1GEJVHgwhsU+r6w+gEufX4V/fL3P73WV5zkY02Q0ZbQFFxtzSg9CJPyKYZGYOnWqykKiZPXq1T7Lxo4di7Fjxxpu76677sJdd90VSFcaDc/gqS8AzOIbYqK9mUDy03Z9G5WFRWe7ZhaW2jrzu0SUA/aCbjVuF61B6VSFV7D48xSpnyWktqZ450Ry+7SLdmizh/y7K45ZsBYA0MIPn7/QxNio+2R8wwaA6jqDoFvdwGJ7/bESNkbnhBYW+7zwv70AgJdy9mHa1ef5ta7yPDdkmgwrlN+1QCdMDQSlIPO1sNjPvCMkWDTLLKHGxE7hOLMMkpioKNVcNoA6hsWsDouRqdXlFpbiwQHzOizyPixjWGpUn+vvy3y7ymVKbSJbWDRPp24dC0ug98S9heWw+/BrNuhoD0fb1jpLSLmthrmEpPWNi9xxAGkMGmuctspsCxXK3Wr7oFcAkpBQQ8FigTL+xOh3aWZhiY1WihJ5Dc+2LfSEsUvI2gQdFWXPwqK98fjEsChcQmaF6nz6aCDA9CwsWvdWQzJr9HDZvOGbnVPt/rXnwijN3GqCRzMMr3/9ciOBxfGjcTCa2Tv4+wnPBdVz39r5jJBQQcFigR0LbH6JbwlrVQxL/TKfLCGYu4S0NwJJgLiEfuVZdb/tWVhcPhYWbdBtMGNY9G902mORuhSseYXsjitmViutyNAOIoZBt8JXsNgOujWxsJlth8NH42AUoB1sQuluMkP5/dJ+35Wf+fMgQ0hDoGCxiVkg4/Uvf+8zr4g6hsUgS8hhPluz1nIjTaTocQlZxbDYC7rVZuX4xrB4XUL+3DiNsp60AgnwdQnJ5ykIFhaHw49S+KYWFvV7rbipNgy69V3fflqzuWAxevKmhaVxaDwLS3gEgVmcivJe4LQosUBIsKBgsYmZSwgA1u5XTxbona05yseKomdh0Xsu1ma3xNVPpOhyW1tY7Abdakvl+xSOU1hY/DFN6xeOU4sCaUDWPqHpxbA0ZBC2228zC4tWPNq1sEjuKD2X0Cdbj2LNz8Yz3ZpVOgaMYxuaWpZQpLoMGsuyoBQHwY5nqXK6MO/rn7E733c+MJWFRZslpPj+OyM8Q4o0HShYLLATdAv4Bp7KFpYoh/yhnK6riGHxjW/xor3Px8V4BYtVTZQoh8NepVuli0aog26FECrLgd1YEMCgND+0ac2e/0aCRRXD0oBBz25as9nAqv1I29Y4hsXzXxtAfOhkBf64dDsmvrnRZJ8GFhaXJFjsW1jmfrUXf/nvLsN9hYr8kioMfmYl/vpZ8PetnduqsTH6DQa7Lkko40XmrtyLeV/vwzUvfufXfpW/KVpYSGNBwWKBMsPHzLWgTTf0Bt0aW1iM0qTl/WluEpKFxVMx1iqGBYi2qqTrVpd018awOF1u1X6CUjhOqAUS4GutEHL7hsewOGB/AGlI0K0R3rRm9bKTiuwrf9OTvRYWo/W0YsqFl77ZjzfXHsRxjesy1Ly25heUVNXije8PBnW7764/jPOfWGFYsbgxMPq+BLtUvdKaGuwA3I0HTxt+5jKx7LhU9wUKFtI4ULDYRAjzpxutNFAXjtPEsEguIcXkh3pb1g6SSguLZZaQDQuLSxNTIoR68kNnnVv19OTP051eU23hOElIaG94QrZKKLcX+I3abuyN2Y3XJ+jWz8BZ7aSOymtjZJ0xOmZp8DByCy7OPYylP+TJ76sUZfsjJQX1yeU7AQBTl2wJWx+MHhqCbQVRu4SCu23llA5m+2UMC2kKULBY4B3AjYuKqdupB2Zl4ThJlignP4SJS0i7P1mwCGH5VOMAfGqq6G1fXRdFbSly1rlVVhWjfeoVszKKYdFOBeDZrtC00xvkzY7EHKNBuqSyVvXe7PpqN2H3qdI7l5CyP1BZsowFi/42pXHSbPB69KMf5ddmg5KS0xXOoFtg7GSqNVcMXUL1X5aaOhdKqmp12/iD8uHEH7esHcy+Gy6lZUcrWGzcFwgJNhQsFihjTMxMvcr7svLHHRsVJd+09S0s9ct0bCza3cVKLiG3sHzSirKR1uwWQi0gNO9rXWphZPfJ0cjFYTT5oY+FRfNf2dZfHA7jfg/4y1f46ifvfFVmLi+rtGbD9er3rY5h8XXZ2NmnvG/ZwmKvD5VO74R5Zsc4+JmVGPG3b3yEXEOwEUbVbDGycEnf8cueX40BT3+FYsWM5wHtJ0C3rB2MgsU9+zWJYVG8r6FgIY0EBYsFyhgW07RXZVVIRbuYaO8W9MZNM02hFUgJsZ4y8846t3WWUJT1YFHnFursFU0F3Zo6l+qmZbfuhHEFVk2Qr4FLqKEWFq1gMhNaz36x21Y77Ud2szXkGBbF+kKoj9loHiJD4SdbWOz1QfkUbfS9Ue7rl5PltrZrhwg2sBg+NFTU1GFvQRkKSj31mbbknWnYflzGwqGhVJkIFrM6LKr7Al1CpJEIaC6hsxEBcwuLcgBSDvpKl5DWiqIUQ0Z1S5Qk1c+LU1XrsnzSUtZ4McLtVsewuIU6NqaiRn0zc9l8kjK7p6osNrKFxdclJISwFcPyy4lyJMZFo0NKomIf3rYOOGzHHvlTOM7uk65epVtALVIMLSwG3ZGEit3BSylYjPodquJkkewSMpqA9JZXc1V1mbRTc/iLShwE2ZoRaAyL8r3VRKyEBAtaWCxQzvVjNkAof7TKJ47YqCgAZi4hk6BbzX1AEiyVTpfl03WUw3qwcLl9XULKAU3pSgD8CDS1Kewki5WPS0j4Cji9XZ+ucOLKOWuQOfsbTT+923M4zIWm8hxVmcV6aC0s9X2PjzH/CRkKFoVIMSw6Z+JaA+yLJrVLSH9fysDJYE6w15iT9TU2RtYqbRHJBuoV1X4as6aNUZbQvzcdwa2v5crvGcNCGgsKFguUKcmmgkVxw5cG9ugoT6aOttaKMujWdPJDzbLEepdQtQ0LiyeGxbSJR7AorRhudbp0eY2xYDFLFTYXLGqBpN0uUC9YNOvpnZ9fTpTrfq49N2auPOVgokw11uJjYak/T4kWs0FL3xlt95WBtkYWFiOXkHS+ArGwGAldlWCxtVV7KL+Dwa5PEm7sxhA19HyqyuA34jk0srA88uEOVTurmeMJCRYULBYoHxDNntRVFhZl0Tj4BtZ6LSwOv2JYpMGxyumyl9ZsZWERWpcQTF1CdQZuL5/tmtxUlU9jclqzxgfuFsJHICjfVtTUYX9RmTq1UlWrQlMzwqaFRTnRoxafGJb68ySJSOP19C0sSoFgFMNidBrLq+uw6dBp2+mklYrr6DQYXPRcdcFAW9cnkrArHhpqZVLux+Vyo8rpwt++3INtR4obtF0rlBlJZtZVBt2SxoKCxSaeImvGn6ssLIoaLIBX9IxZsBZVTpfKemDk39bGcADeoNuqWmuXEADrOixal5BbnRVUYWJh8SdAVYluDIvbWrAo3//m1XXImvstNh3yFr3Ss3BJr82e7JVnyB8LiySK7FpYtF1QZmfc/sYGvLfhsOU+JSYv3oRbFubin9//YrpvCaVLyOh7o7T4BDOIUjlWG6VvN1fszvFjZCkLZD91boGXv9mHhWsOYMyCtQ3arpXFS3l4Zm0ZdEsaCwoWS7wTDpqhHjDrLSz1kxXWybEaAit3F8o3MHXtFvX29HanjGGxelqNcliH+rndmrmENGnHFdoYFlXtBRPBYmphUYoe/W1ZxbDsKSgDALy/8Yi8TDXgauJkzJ4O9SwsenMwaQcd6anXysLircOijWFRX7//+2Snz7pG3ZZqe6zaazwPkZLKWmXQrf73RhU0bnJtNx06jc935Nvar5Zwl9IPNnZjiBpanVYrwHce9533JxCUv29pYlUldi0skWY5I00XChYLpPHMKuBUecOXzO4xUZ7Te0oxgeDu/FLFbM0wzCDSe7pWxrBYu4TU8QPXXdjBp02d260aFOvc6sBibQaBfQuL8WfKp0WpDox2W0L4bkPvKVUZ3Khn4QI81hu79XOkmakzkhN82vm6hOotLFYuIZ06LNr+GtHQJ3MJpUvIaJDVc2nq9eeWhbl4YMkW7K0XjVYo9xdpFVHtBps2NChVm9YcLItGWbVXsOi5j5W/9935pYY1WxpyfB9uPoqbX1mLorLqgLdBzh4oWGwSiIUlTuepZePB04rZmo3TmvUGfZVLyLIOi7o0/5yxA3zaaF0v2gHFJ+jWIE5E21fz9G/NzVfHReHWcYfVugW+33fScNDTO/+efpq7hJQ36hP1Fpb2yfG6fVIix7BYuYR06rAA+tYGrUAJVhl9dVqz9fnTe2JeuOYAhs/Okd/vL7JXq6VOJeSbtmDxVyDarYPTUAuEunCc2/Z+rSit9hYI1HsgU97zXll9QJUZpKQh1/XPy7ZjS14x/v6/vQFvg5w9ULBYIA1nVhYWp45JPSba9/TuOFos38Q9FhZ1yrOE3j1JGXRrFfCn3LYRLo1LSHvjqTSJYanVmKmVmN33tZVzlQJGObmjdrD+7/bj+O0/N2DOV/o3NrVLSC2KzK6dysJSH8OS3srawiK5ZVonxRluG9CfSwjQT2XWlnEPVhV2VQyLgYWl1sLC8rcv96Cw1Bvjo9zmibIavJSzD/klvmX9VZbHJu468Ddl2K5LqKHVaX0sLEGqdlta5b2GLrfwEWza382OoyW62wlGWrPS2kOIERQsFtiN8FdmX5TVP7nE6FhYal1CfuI127Le07WycJylhcXhUM3WrHcYHpeQdz/ap/5ybZaQYgRVpgr7ZOWY3Pi1pfmV60pzJQkYx2+89q1+oKmhS8jltm1hkWJYMlJ8BYv2Zn66vtx625ZxcjaYHnpzCQH6Fpan/7tLNeg3poXFKAbICGWF1Gn/3oa5K3/GpLd+8GlXayKImxr+Fs+zG3Rrtx0AHDpZgay5a7Bskzc+S5XW7LKeqd0u2qB6v8oBKAhGMHUEl+shQYSCxQK7vyPp6XHH0WLcVX/jjo3SP72SL9ihCIzV3hr03CpSvIS9tGZ1DIteCK7bDY1gUd94tDc0dT0I44A8s4FWO/uz8qlbEnhC+D7tWeF0KQZlTd/sWFgqaurkQdiOS+h0vbhpkxSnK0wlpOtoJ4blk63HMG3pdvl9sLKL7cwlpJrk0kZdDaUI+m7fSQDeYGjVdpWupiYuWPy1AAVjFnAtT/5nJ/YXlWO6otaJ8vvscruDVvdEG5Oi7Wcojs+IhlYDJmcHFCxBwln/xPyCwhdrNJBV13ktLEaF44TOPUAZw2LpEoK6DoueEcClqd6rrQdiliVk9Bowd2XUamJfpHXjor2TRLqFeWq0Hsq+q/rm9nUvKZEsaKfrA6PjY6KQmujr5tEekxRI3aZlnJy+rofsEtIckNFTae4vp7zrNlCxSN8pfwvH2Rm4te5CI5SDXjCexA+cKMeof6xp8HYAncwvP/tn1zXj9MOFoze7s9bCYlYDyR+010P7O7Y7M7SeED1eXIUPNubZzwyjXiE24FxCFtg1VUo3r5bx3lNqNJDJg6tqtmY11hYWK5cQVDcBPdeWpw6L9712oDLLElK5h+qXb807A7cQaNvC10Khtw1l3ZeYaG9lXncAFpYT5TX4y3934aZBnQyDg/WQzoo0UKQkxiIh1ve6ad1cp+szitq2MBcs0u59XUL6/UpXWHcaWsDN5RaIiXaorqOdoGWlqDxWXIV3cg/5tFcOrDFRDsOncXX2XMMH2kc/3IGfC4MzOaP2mvobGxKKLCE9y6lPTFaQYlh8LCwagaJ3TfUrcnv6FR3lQJXTha92FeDPy7aj1iVwrLgKfxp1vmVfqFeIHWhhscCuqVK6GasFi2fdv47ph2v6ZSAlMRaAwiUEhZCwkSWU6Ofkh0oLi95RuDTWB58YlmrjoFtt6rCzzo2bXlmH37yaq8o+0FKrcgl5b8ax0VGqAGR/LSx//Xw33lx7EL+e/706INiiDot0iqSgv1YJMbIlS4l2VtszlZ5jbNMi3jSGRXpKNZtLSEnXNkny64ZWYZfOrbpwnH9Bt/f9azNeW+MbN1SsECx6dWv0thUMC8uZSuNqxP6iPRf+ujbsxqb4Y7nRi/9SF45zB23uHiuXkF5fDNPi649x5n924qEPtsntvtlTZKsvkTznFAkeFCwW2P0dST/YFgrBIv1ofzu8G1797RC0SvB8Vl0nZQkZb1wvUFQVdCsVpzMYLLRzCentyuVWl+bXuoTKNMJDW3FTQgh1vMvjn/yo2ydAbcVxC6+FJTY6qmEWljJvBov2Bm8WdCvdlKVjbZUQqzuhodbaJGUUtWkRq7KwaNf1xrCot2dUjl8pMhtah0U616qgW1sWFu9+jTJDJMEGGFsSAbWwDUaWUDCn0tEO0P4KAftZQva3q+fu0T4oaC0ueacqA/quVFu4hPTErdE1lL4/yzYfVS1XdqvK6cLvFm/C0h/y5L5LUK4QO1CwWGD3ZiP9kJVPm6Uaf7Q0mKksLPWfCQh8svUonluxB0II3Rtzgk7QrdFswVEOdV/0xJFUuE17DHL/TS0sWnHjbbvzmHElTq1LyDuNgcM7c7WBhUWyUFlRq4lhMZ0Dqv5Gq7SwxMfoWFg0Mx5L56ZNi3hVlVCtdcbrErIXw6K05DQ0hkU6NpVgMRjxnX66br79+QQ2Hz4DQB2rpX0q93e7VgRztmLtAO2vS8h+HRbr7f5yohzHiqsMLCzq77PynjTxzY341Qur8NWuQlt9UaIVzXYsLDUGxeMMJ/BUvF76Qx6+3l2IRz/60WcdGliIHShYLIgzEARapJux0syqNV/HxUiVaiULizLoFvjj0u14dfUBbDh42jSGpabOLe8v3qDSqmeWaPO7gHYwt1M4rqbOhdlf7sbmvDOqz8pqjN1ASpQ3QZfwZgn5WFh8onqAzq0Tbe1DXWjLt5KuEukmLVlYkhP0Y1gqnL7XNcoBpCaqLSzadSVBqL2e2ht8j7QWANTioqGxlbUuN4QQKkuZkRvDKIbFjN+8ug6A2sqnFekqC0sTEyxaa4b/LiH/LSzFlU4IIVBRU4cteWcghEBJVS2unLMGI//2ja4FTFsiX3kNv9/vydDaXj8RYp3LjTEL1uLB97da9qu6zjhGTe894DshqoTWZSqhtPxUKQTSbYtykbPb6y6y0iuL1x3CLa+u0w1KJmcPFCwWdG6dhLm3DrBsJw28yh9usaWFxWtjUQ5opVW1um4MZVVVKU4kwUBQORz6mUFK3JqgW6sYgzq3wFtrD+G1Nb/g+RXqAm6BFH5yK26+MdEOyxgWu4JFnTrttlUXxsrCohQSUkZR66Q4REU5VAUCtRYWafs+LiHNuf5zfWBilTN4FpZalxs1dW51yrKtuYS8r/XEm5Iqp0v1pK79zivFYzDmEgpWbRpAz8Lir0vIv6DbNT+fwMC/rMQ/Vv6McYtycfMr6/D9/pM4rphiokjh2pTWU83W7HbrWoKkZ5NtR4qx7UgxPt1+3NJNpI1h0QpKvSwhoweTqlqXYel+iZbx3t/G+l9O4w8KUWWV9Tjr05+w6fAZvG5Qh4mcHVCw2ODmwZ0NXS8S0s1F+aPV3i+kbUg3bqWFRTngx0ZH6ZfmVwykUnulhUXZR8/khzZma1bFsJjfcL7bdxLPrdij+1kggkVZtTMuOgpS2Rqtq0qic+skn2V6nFbM3VRnZWGRXEI1yqBb32utdAlJNVhat/CkPytdQtq5haTz65PWrDHHt2vlyQ6qMvn++IvHdVWrWWYeNKltoxeArORkeQ3KFedGa1V0mlhYHv1wB+54Y71fVhOfeacM2gkhcOBEublYbbBLyD8LyxPLPa6Ql77ZL7tNv9xZoLJkKrcpiWTlMVTXunXjSKqcUnC3d5nVA4hPWrPWwqJzPox+51VOl2puLwnl/cXM4msU06XldBCDrknzg4LFJlY3bulmXOU0HvQlcaH34yxWBDHWuty6FoaoKIc8mEpmfqVISVJYYBywtrBo67BUGPRdOYAbDaLaAF07KINuYxQxLG6hv58uNi0sygDcWgsLizSgqoNuzS0skgiQYmpUQbc+MSz1gsXHwqI+15JgUWb0aEWr3oy6ZjjrhM8AI53vbUeKMXret1jzs2fGZ1WsidLConMulBw5U6m6ViWVxoHaSsFyrLgKSzcdwdr9p3DwZIXPdrXbkdBeSyMX17/WH8ZVc9Zg1qe+s2BL+KTxhszCIuq37/s97NYmSSWwlUj3EuV+tC43uW290FW5YEzuRYCvhcVOxWojwVJd60be6Uqf5dqgWyPsWt+aevFBElooWGxiZWGRBYuJlUJ2CckWFoeiDoj3plVV6zIcZKUneCnoU9kv5dN9lEM9+aEeWguLEVYzEgMNsbD4xrAInbmEAKBtS2+NErNUYqVgcbnMg26l/ZdWW1hYFNdVmrJAyghT9kXrovNOfqgJRtXceOUMslq34fxDVuJBS63L7XNdpEHzd4t/wJ6CMkx8c6OnP0qXkMFEkhIDu6TK6ddHNINUcZV68DXKElq91xu/oB2sXs7ZhwF/+QqrdFJitddSqgFS63LjllfX4a63NkIIgefrCzj+a32ezzb0+qbtnxVC2J/TR/qO6VlkKp0unDEQLJJ4Vd4LjGI43t+Yh2tf/E41M3ylhcVU++CkPX69/ho9mFTXulSuLQnlFrSZdqq+2BQiFCxnNxQsNrG0sMgxLN4f1D8nXqRq441hqQ+6hdclpLSwVDpd+FCTHijRKkGdKaO0BihjXDwxLOaC5Y9Lt+lOwqfFjmDRBujawSUUdViivJVuBQzq0Cj60cnE2nKiXGlhMZ+t2Rt0KwkWawuLNJBIPvlYkxgWaT4WbTyBNqVUaR3zPi2r+2AUYG2ER7BoXUKe/Z4s17huDIJu9a5rmxZx6F4fJHz4lEawVOrvT7uP1XtPyK+1A9mclT8DAP5PJz1evzaIG7uOl2LT4TNYvfcEjpz2HTj18E1rDtw1ZWc/ehacSmedKkVcyZlKJ3YcLVb10yzodFd+KRauOSC//7mwzHSA1wpF30q3vsdoZuHRe2hRfu8ra43vEWaCRVWFmYLlrIaVbm1i18JSXX/zfe93wzCyZ5pmG1KWkCKGpd7GorzRr9pTZJimOLJnW+Rt9A4S8bFKl5D3cmrrsOhRU+fW9TtrSYizHijNisUZ4XZ7J3KLjfGW/XW7hW42glKQtWsZjy6tk+QsCSXamix1buNrp80SapUQozqnUQ7PU7yyzow0iEvnW53WbGRhUe9XGy+ktJ5U1brQIj7Gx5pgFQCrxaljYTEKblQH3UouDLeuoI2LjkJKoqe/hzUWFu2AWqsKuvW+/umYt76Lds4qeT86vzk98VnnFtid702l36LJYDOiIYXj/JkoUZoYVW+wrXS64HDoW1gmvfWDT2kBqywZ5Xd/0ls/YPg5bfDBPZm6bbXXVmtN0ztGbX8kqpwun0KTAHDgRAWW/pCHcRd3NXcJmViDlG7Spj7jNwkttLDYxI6FRQghPx3rtY/TZgkpgm6V2RXb6lMU9ci+IEP1XimkUpO81pcoGxYWuyTZECyBuoSkm3isZi4hSUAkxEahU2oiHr+2t+qcxsdG4d3JQ/Gnq8/z2a5KsFhaWER96q8yS8h7TmPqI4GVLiFpgJWqGptlCRm5d6Qb7/2Xn4uNj1+FqCiHauoFvXWsvoN6x2ZW/E/VH525hIximuJjo9C2PuA4T2Nh0Q5ayon6lIJFOfAauQpOlNWoXEeA/iBaW+fGzuNeAWRbsDSgcJy/bSuddbrns8rpMoxh0RMHVq4T7e9w/S+nDdv6VrrVWlh89zW33vqlparWZWhlffSjH5F74JSpS8jMcqLcbiCxcsFACIGlP+Rhr84En6TxoGCxid7T7b2XnYutT14NwGO+d7mFfBPQc6P4uoS8gqKkUh3DYsSIc9NUA6rSfZGRnCC/9tRhMT8mu9iJnQhUsEgDUEyUIoYFQr5Z9+mQjLWPXYl7fnWu6hrE1Zfy13sKP6XNErKI01EO7MkJsapsBqkomvJmWyHHsHjOSwuFoIuLtmdhkQaHId1ao339dZOEobQv7Xjhr4WlyllnGHSrRc8lpHyyTdIcY5uWHsFy+JQ6YNando/b15xf63KrBm+lhUXZjwqnC3e99QPW108I6XYL3SfsWrdbVazQrmDRDtD+uITsuFK923WjoKRa97MKZ51hDEsg+OOa1dZhCXS2ZsAjfszuAQdOlJve18yEmF5Jgcbm8x/z8ehHPyJ73rd+r1vp9P/eSPShYLGJXlxDlEPtknG63PKPMlHHKiG1rdZJa1ZaWMxMp3ExUeiQ4hUmyv1nKJa73cJn8FTywBXnGn6mRe9YtATy5ONSZAnFxXjnPhJCnbUj90MhAiWhYuWqq7PIEgLUwalS8KuEVC1YeU2kQUEKupXSmwG1tQXwxgEY1cRQxr8kyoKlTncdf4Nu7/3XFvyj/olYEhxGg7K2VktJVS3u+9cWAB7L3ftThsufKy0sWitAWY1WIPkG3WrjIJQDkjL+SGLjQY+VoLrOpZs9VusSqiffw6cqjfOdFWhdIP5YTfxxgda63Cgo1RcslU6XnApu9nsNBVLQrfQdtxPDYkSV04Vyk+KR0sSIhn0xyRJSijBtjFRjsd3E6m3G377cg/5PfYUfDaa4IP5BwWITvadbh0M94Djr3BYWFnVas6dsnO8TvNWTTbrCkqIUUsrldW6BYee0xfBz2uC3w7v6bGNQl9aG2z+3XQvVe+2xPHhlT591GlqHRXK9AB5XiJ6AUAonqWpwnMUgXuc2r8MCeJ4OpfOvDWqWMoDKa+pw5ZzVuPW1XNmdIbmE2iR5BUucJvXYZeASklAJFh+XkLqtvy4hwOvWaVMvMGpd+pPnKZ9wa+sEXs7ZJ7smW8Sp43rioqMNZ+Q2s+g46wclrcipqBdox4qrMPofvk+wkig1qrJaXOlUPb2XVdf5WNX0BKPP3DkuT0zXT8etBxd/Kq46NYJKiUeweLb1zuSheHn8IPTOaGV723ZQukQXfXsA97yzCbUut/zgJH2PfSwsflicTlc6UVplfA9wuYUsxP92c3+fz83qsFQqrnuxQVHNUOMIcI6vhWsOwOUW+NuK3X7tT6pSTdRQsNhEL0MjyuFATJRDfkIpq66TB2Azl5D8NOFwWNek1kFpSVFaGJQuIafLjegoBz64JxN/HeN7g+jcRj/L5saBHfGv3w1TLVMKhSeu64NpOtPFN7QOi28Mi+fmlqwQLEoLgyQkrKZOEMLa1K/MmEnWWFiUFpNfTlRg48HT2FI/h44UdJuqsLBoJwI0qsPibe/9Aignt/Ss07CgWyWSYKlzCR8XhBDq+WmcLjf2FnoH2KS4aJUwjo/1uoQkJItLuU/MjG8hNO1gL7mEXvp6n4+FBvAKeKPgXClmSZlernwAmPf1z7j42RyfFGztAO10Cdz++npc99L3lk/E/giW2jo3fjikH0tSqYhhSWsZh18P6Ig+HZJtb9sOysJ+/++LPfhqVyH+91OB7NaSBIv2QcmOhUX6Tr619hBy6113epRW18pCvE2LOJ/PzVxCSguLy+1bWyiYGMXSKN3rZq6tYFBeU4dLn1uFKe9sDul+miMULDa5aWAnn2WetGSHLBT2nyiXP0uI8z21umnNAfRFZWFRDGJtFYOIMthRj06p+oJlzMBOSG+VoFqmFF9al4lEoBaWUtlaES1XulXOf6NyCSmEkzSYW7mEAOuiVJK5PiUx1selo1fvRYqRkdKalRYWpZgE/LSwaGNYgmBhkWhd30eny62K8QE8N2BtDIuqGFxVreo8x0VHIU1jYena1lOXZUteMV7O2QeX2xPMrIw5OVUvDH0Fi+d4jSyLxfUukwqDWACpnH1ay3h58FUy7+t9OFleg5e/2Ye1+09i7f6TWLEzHz8Xqq0epVW1cpr2r+d/j2n/3qa7P6mtXWpdbmw86BG5U6/oidSkWEy+pAcAoKCkSj4fafV1huy4YP1h1Z4i3PnPDdhT4I3zqaipkzNzpN90IDEsdr+TpVV18ve6ZbxvrSOny1t/6HSFU9UXrVDVVlMOFjm7C3H+k19iyQbf2j3K+6lRGnqwWLWnCAWl1fh6dyGtLBooWGxyVZ/2+M8DI3HDgI7yMslMKBXR+rne7Bvl0PdHS1YaZZZQILRv5R0slE++yicXK398q4RYH2sCACQnxiAqyqEaoBJUgkV/xmR/BItkFckvqcbRM5606vbJCarZmmWXkGIAUvZJEgJ2Jqe0srAU1guWtjpPfmY3bW8Mi/ecJMXF4If/y8Lzv7nQ008hxbDob0MpWCSLjfQk6hPD0gDBklxflbfO7fYJXCytqlMXjnO5cfi0N5i2qKxGLVhifC0s0m8A8NRR+XDzEZ8ndGm/2sE+73Qlbpj/PT7aol97SBogzLKJAE+sjdmM3sWVtbjjjQ24440NuPdfW/D3r9QZLzuOFqvef7zlGKqcLlQ66/Dh5qMqy5R0DNFWtQPgeZA5WV6DuOgoTL2yJ7Y+eTV+M7iz6th6tm+J1HpRmdSA66zHQx9sw3f7TuL21zfIy1xuby0gr0vIe72+/DEfJ3XiibTYeWAAPCJVun6JcdFoEed773G63MgvqcLw2TnI/se3ciE6bdCqXpxToKzYmS8Hdc9d+TOEAB7/5Ecft5NSZOsFSb+25gBeU9TAAfRT8O2gtDYFUt8qFDz7+S48sfzHsAsoChabOBwODOiSqrohSoKjS7175edCj4UlMTZad96M+PrBSRoEJQuNHW4a5LXwpLXUjx9ITbIvWADIxb+USMenfMpTZogYWVj8+WG1q+//6QonPt1+HIDHaqScrVmaZE25P7Uf2fNfKVjslq6PjnJg0sju8vs19UXMWusIFrN0S0mwKIViTJQD7VrFy9Yuo7RmvT5rg27NXEJpCsFgdE3Ux+EZLHYeK8VXPxWoPhs+OwebD3sza8qq62QhKaF1ibaIi1ade6VgAYDd+WU+Yu9URY08O7GSb/YUYYfCBaMVAdIAYeUSSk2KVaX2ayksMx/olOdAIr+kCs98tht/XrYdf1RYXKRj0HNvaJEuY9+OyUiovzdoSwVcoqjZZKeMQCAoherpihr5u92y/vsjpXkLIXDfe1tsbdPubPal1bWyKyUpLkbXilRT68n2cta58cvJCjy53DOtQrkmdim/PuPK7Rb4wqaw0uPI6Urc+68tuG2RZz4r5Xdnw0G1C08lWBQWnkMnK/Dh5qOY/eUezP5yj2pKiUBdV0pBf6o8PFlRSopKq/H6dwfxr/V5KCwNnlgMBAoWP1HeTKO0FpZ6E7PRk3C8xgyqLM1vxif3j8Bz9U/sgNr1o5yUT2kxsVNgqYeOYEmut6Ao3UCJNiwsWuaNG4isPum6n7Vt6XuTb98qXhYkyhgWo/3puYRaJ8XZGrx7pLXArF9fIM/f8/mP+QD0Bx+lYNEKRekpUekSki6oNC3C9qMl2JJ3Ru6v1sWksrDUn+cKI5eQwprWTuG207MMSdx3+bno2iYJYxQuzcW5hw3bA54BQamVhnZv4/Mk7XA4kKbYbxeNYAF8v4O1LoGymjrL+A9thWhpgDByBby97hAAz/U3s7D8onDZKtFmPKUkxsrf+fySary/0eMiUFbnVba1S9+O3tiUpHhjwaInnLXYtWwYcazYm7WkDbr1x4Khlz2pR2lVrSzEk+KidUVZTZ1LlU21/pdTqmBdifx6y8vr3/2C+9/bgsmLN8HtFsgvqULObv2Cm3ooRfmxM1UqcfD9fu+1Lq+pU007oBR+o1/8Fn9etl1+f7zE2075fdWKLjMKy7zn4FRF8ATC9iPFAVlslDWO8kvsVZEOFRQsfqIsxia96mJXsGhv+rDnFhrUtbXqSaa9YrBSmsmVFgg7Ef66giVRR7DoWFiyL9AXIxJX9mmPTqnefiozj/QGWKWFRQihmttHD8ndoJpLKS5aFiFmSKJBKx5UwqMepaVqxLltVfuT6rAoLVuV9TcE5bb/vGy7LD46amKHYhXb61F/jqTsHK1JWfm9UsYgmT3lPzq6N7595Aqka2Jr7NC3QzL+OqYf5t8+SDeWR+kW6qYRLDV1LtV3ULIOnS53yinBHQ36pM1AKq6sxYZfTmHFzgLd9hKpSXGmFhajJ95z27VUve/XKRkXdfdk0enNjwN4J2e8sFMKAM/1Vv6WlRY8ib6KYNokjUvkwi4p8muttUqPZD+Ekh7K4/LGsHiu17Ez9gclu6nYxZW1cuxeYlw0EnVcQjV1bhQoBsQKpwv7i8p9Btn8kmqUVtfK80VtP1KM/+44jptfWYfJizfhi/oHECsKFeLowIlyVdXvvPrpHaprXcj+x7fYpaikLFn88kuqfOrx5BsIlmI/4m6KFFYM7RQagbJ86zHcuGAtZv5nJ3YcLfbLXfXjUe+xG9UTaiwoWPxE+ftsn+y5sUqCRfI9GgXNaZ9Gat1CZWGxYx0AgPPSW+La/hkYO6SzoV/fjktIT7BIg6LSBaAcpKU+zrl1IObfPggDOqdAj6TYaNx7+bm4Y1hXfPOny1SWqbY6Lq30ZK2FxTfoVon0e1M+2R8+VSm7m8yQisFpn9i1cRmAx30nxS1NvbInurX17k96MlWKyZL61E6lsP3lRAV2Hff86DumqgfpWMV5kZ6y1x84hTqX28clpAweVroI2xikGKv34/9Pffg5bfHb4d088UU6ylq5X60QKyqtkV0MUQ6vdepURY1s8u5gEPjdtmWcqoLxLycrMG7RevzvJ/On59ZJsUhJtLZOaGnXKl4VK5XWMh4dUzx9252vDsyVfPiSlWhQ11T8d+ol2PyENy7lyt7tMevXF2D1ny9XravM/tFmESq/t3rWKi168Wf+IAmW6CiHfF+S6tLYma5DQms1NqJIYTVIiotWFVuUqKlzoaBEbVHYduSM7AqUkhsKSqrx7c8nVDFSX/yYL7uKvqwXtqv3FmGnYgoILcrj3HakWCVo8+oLIu7OL/U5HzuOlWDJhjyVxU3ieHE1al1uLP0hD/uKvBY9f4oDKkWBZPWpcrrk796ZCqehkDbiiXr32sdbjuGG+WuxOPeQ7XWVFpbjFCzNC6UOuKh7GwC+T5d6T+qAr4VFa6Luk2EvndHhcOCVO4bghbEDfMprS9iZJExPsEgoYys6K46vVbxHQLSMj8H1F3bEb4Z01l0/JjoKHVIS8exN/XFOu5aqAVzPJZSSGCs/xR84UY5fTnhuGEYiThrM27dKwDNj+gEAbhjQ0fQJW+JMhWew0T4dGV23f4wbiK1PXo3z0lupLBvap2TAW1BscNfWGH5OG3m5ZDXxsbAoFPAFHVOQkhiLspo6bD9a7OMSUpqwldtu08L6mGMs4ntmXNMb/Tqpv38DuuiLUQllcKjWynO8pBoPL91Wv+8oWaSeKnfKg702o0q5rT9c1QsbHr/KdP9arFxCRrRtGSdnOQEewdKhXli+ufagqq1UxE46huTEWPTvnIKUpFjM/HVfzBk7AC/eNhCA2nrmcEBVX0Up4FOT1NWVu7Q2Fyyt4mMaPO2GNOAlxETJv/UFqw7gyOnKkFhYlLEPCTHRurEv1bVu2eqRXv8wuPnwGdlF2rO9xxKWX1KFPfVCsnP9JKgrFXOv1da5saegFHe99QOuf/l7w3uh0hry7T61+NhTUIYVO/Nld6OSj7ccw+Of/IgZH/tOzplfUoWXcvbh0Y9+xCMf7pCXl1bX6U6LobdM5RIqr8EnW4+iz8wVuOONDcgvqcINC75H1tw1PkKqoqYOQviWLSivqfOxUj39310++y2trsW0f29TnUshhCrFv6A5uoQWLFiA7t27IyEhAcOGDcPGjRtN2y9btgy9e/dGQkIC+vfvjy+++EL1uRACM2fORIcOHZCYmIisrCzs27cvkK6FHGVRqXPqB/y2LeNVT0/aSQ8ltE8jZdV1qhvV+QEUjPrTqPPQOikWj47urVrubwzLzYM6Yf7tg+T3PyqeTH7Vqx3+30398cItF/pYjyZkdseKhy+V3981ojsW3TnEZ1/K49QbVBwOBwZ19ZjhX6g39QLemBotSuvDncO7Ye1jV+LvYwfI53780C666wHGT5BGrpXoKIccV6AUHHo3XWkbiXHR+OCeTB8LlPTkDngGHqVpPzrKgUt6efqfs7vIx8LywBU90bVNEl69Y7BqvaE92qJ/J19xoSzwp60Po+X3l52LRXeqY0cGdknVbSs96SnHTG1Mwu78Uqw74Mm+cNa5ZTfg6QqnXK3UyCUkWfnsBLQqsQq6NeLi7m3Qr6P3/LVrFa+6TkrGLVqPL37Ml4Wp8jokJ8TiN0M6y1ZBpejvnZEsB2lrUdZPAqzTmi/skuJXFVo9JBGQEBut+m7cuGAtDmnmhzLDbtCtREJsFKKiHCorgiQ6SqpqZREhxVx9s+cENtTPh3RBvaDOL6mWJ7uU2ilPx/4T5XIgPQDD+jDHFXE8W/OKAXjviTV1btz7ry34z7bjfh3fglUH8PI3+3U/K66qRVFZNYY++zXueWcTXs7Zh/5PfYV3cw9ha94ZvLJ6P2pdbhQqLSwVTizb5MmeW3fgFDJnf4Mjp6tQ6XRh+dZjKKuuxZ+XbceN87/HBbP+hx4zvsCgZ1bikQ+346ufCvDp9uN4XydNGwB+8+o6FJZWo6bOhcc+2oGr5qzBx1uOYco7m9D/qf/hmz2F+OVkhSquKNwWFr/tikuXLsW0adOwcOFCDBs2DPPmzUN2djb27t2L9u3b+7Rft24dxo8fj9mzZ+P666/HkiVLMGbMGGzZsgX9+nmejJ9//nm89NJLWLx4MXr06IEnn3wS2dnZ2LVrFxIS/Pe9hxJVDIvi9eXnt5N/RFf29j0PgKdCqBZl5sMFHdVPuOelt8StFxkPvADQs30rbHnyarkv1/bPwBc/FuDu+joPZrRKiMXUK3qiuMrpU1xOGisdDs9Aevsw32q5Er0zkvHnUech73QlZl7fVw44VaKcTdcoSPSafhlYqEkNNLKw9NTEHUiWjwmZ3XHjwE5ISYzF+xuPGPZZDzsDZKfW+gPZW3ddjC935uOuEd3VH2iehJUi5JHR5/tkxGRfkIHPd+TjldXq8wAA/Tql4NtHrvBZXudy479/uAT7i8pwzYvfYdLIHrhzeDd5IAD0M6jiYqLgrHPLafLKgSutZbxlLIXy0Kyy3aRzu3JXoZyB0U9HZCmJjY5CSmKs7SJtyYmxAQ3kQ3u0QWpSLJZu8nxfUhNj0S7Z2M32F8XTqZlFR2l9+FUv/YcYAPJcUnYZcW4a/r3Jv++2Ef07p6iqAp+ucMpBxnawCv795P4RuOmVdfJ7SZwdUsxBdV56Kxw9U4VHPtwhP0yMGdQJ764/LGcAnZ/eCncO74bX1vyCE+U18iztl/ZKw3sbDqtqoxw8WYFVikkzP99xHIO7pgLwWDov7t4GyzYfxTd71BNrAp7A6IMnK3yWK2nbIk5Vy+i7R67A0h+OYP4qfaEicf1L32PUBekoKqvBV7sK8VW9JePJ//wkt9l+pFg1z9ax4ird7DUA+PemI8gvqcKHm33LAfx701H8e5N+mQCJzYfP4NXVB9CmRRw++EH9fSqrrsOjH/2Imwer64/l++mKCjZ+W1jmzp2LKVOmYNKkSejbty8WLlyIpKQkvPnmm7rtX3zxRYwePRrTp09Hnz598Mwzz2Dw4MGYP38+AM/T2rx58/DEE0/gxhtvxIUXXoh33nkHx48fx/Llyxt0cKFg5q/7YmTPtvjwXvWU7VKcQ5sWcT7CQ0LP6qFMybtxYCdkX5COdq3iMe3q8/DVHy/D7y49x7JPysFiwe2DsW3m1Rjc1bj0vpI/Z5+vWwn3iev6IC4myuc4jZh6ZS88f8sAXbECeEXKgM4puHlwZ1zZuz1GX5CBpLho/HmUJ17hws4pqkGyZ/uWPgPCx/ePwN0je+BhnVmaJYwGEasB2E7mxW0Xd0VqUqxPBtQVvdvj+VsG+DxF/+EK9TQGewvK8O7koXj2pn747fBuPtu/4vx2ln3QIsVO9WzfCrv+MhqPX9sHXdokWYqI9343DMPPaYN3Jg8F4BGHUlzO87f091lfSt+/uq9nxnB7OW4eJDdgzp4iuNwCo/qmY/g5beXPz0/Xty4qY3Uk9AKAAc+9RO/atzKwbEikJycgU9GXNi3icFG31ujZviWGdm+DYT3aqNoXlFarig0aoRSAIwysrgBUwelaOqYk4O9jB+BOxXdl+DltdYPq7cbAKRkzsBN2HLE3z832maNwcPa1WPvYlfIyp6IfWX3a49U7BsvvoxweK510/uNjovDsTZ57Te9693en1ETMvrk/eqS1UFk+u7VNwq96eX4LSXHRWHDHYHRKTUTn1okQwvud790h2cfN6nIL1SzV/950FP2f+gr9n/oKd/5zI3o/uUJOmQY8WXCAJ1V/qub3quWDe4bj20euwNQresLhAF67cwi6tEnCiJ5tTdcDPN+bdywy9KQ4LekBY+WuQtTUuX0eOJITYnD4VCX+td4jLi/tlYZL60Vxmo7LfVDXVN17y9vrDvnMwH3/5Z555k6U1eC1Nb8AAEb19dzvwh1069c33Ol0YvPmzZgxY4a8LCoqCllZWcjNzdVdJzc3F9OmTVMty87OlsXIwYMHUVBQgKysLPnzlJQUDBs2DLm5ubjtttt8tllTU4OaGu9AX1pa6tMmVPTpkIz3fjdcd/lH941AWss4w0G7d0YrpCTGwuHwDJ6/HdYNaa3i8Pf//YxnxvRDYlw0XtOY5f3F4XCoslaULPndMPzx39vw/27yFShafnfpOZg0soetwlh2eGHshfhmTxEeGd0bsdFRePOuiwF4rANSdVmHw4G3Jl2Mw6cqMOLcNMREOXzO5eCurW2LsUFdU7E1rxgOB9CvYwoeu6Y37nhjg2wFmXxJD/zze2+MguQjB4A3JlyEBz/YiudvuVC1zTYt4rB+xlW2ffdZfdOx9rEr8dHmo3gxZx8mjewhu330aJUQi4mZ3eTU4xb13wllsK/EXSO6Y+WuQlXKspHrp2ubJNw5vBsqaurw6fbjGDOoEy7u3gYf3OMVpAmx0fh06kjERkfpBn5+9fBlOFleI3829cqe+PzHfIyrtwL265SsmjU5ITYKsdFRuLRXGi7q1gavwXPzG9mzLf46pp/qe7rgjsG4858bcPdItWXwz9nnY/0vp1BYWo1KpwuX9mqH313aAw9/sA3tWsXjp+MlOC+9FercApf2aicXaOvSJhHP33IhdueX4dcXdsT9SzZj7f5TeGPCRXjpm31o3yoelU4XbqmPwYqJjsL7U4Zjw8FTyOqTjqgoB76edpncj3//cASPfbxD5Xpo1yresGI04BloB3RJRZ3LjRHn+g5ov7/sHHy0+RgeuspXfL896WL85bNdeOGWCzGkWxvcPKgTNhw8hSiHAwO7pOLmwZ3w8jf7MbBLKnq1b4llm49i4W+H4I43Nsjb7tI6Cf/ZdgzJCbH449XnoaKmDl3aJOHJ5TuRs6cIqUmxuLqv51hzfzmFcRd1wZBurfHWukNIT47HH67siV9OVGD6hzs8Ac317rZOqYloFR+Dspo63D2yO779+QRaxcfgjYme3/QV57fDqr0ncPuwrnA4HFhwx2Dkna7Etf07yJa2f4wbiNfWHMB9l5+L9OQEvDHxItw4fy3Ka+rQvW0SkuJiMOVXPXDoVAX+ePV58m/zzbsuxn3/2owDJyrQp0MyUhJjcWmvdvjpeCl6Z7TC1X3TZZfM5ee3w4WdUvDyqv2GhRtbxcfg9QkX4ZOtR3Fxjzbo0yEZj13TGy/n7MPrEy7C7fXn84nr+mBQ11QM6eYRN9OuPg+/u7SH/B3u1d4ruM9Lb4mOqYmyK6tn+5YqF7vElb3b4/Fr++DhpVtVv5tbhnTGbRd3wS0LvWPq9Rd2REFJNXJ/OYW/3HgBhvZog5nLf8LGQ6dxTloLvHXXxYiOcqCgtBqtEmIx6C9fyVlf56S1wGt3DoEDDsxduRfnpLXEN3uKVK6y1KRYFFfWomubJDwyujduGtQJf/18N9YdOAmHw4G7RnbHV7sKUVhWA5dbBG1c8BvhB8eOHRMAxLp161TLp0+fLoYOHaq7TmxsrFiyZIlq2YIFC0T79u2FEEKsXbtWABDHjx9XtRk7dqy49dZbdbc5a9YsAc98rKq/kpISfw4nLJRV1wpnnSvc3TgrqHLWicLSKlHncova+nN+oqxauFxuIYQQbrdblFfXioKSKvFzQanP+nX17YJFZU2drXZut2e/RaXV4sjpCltt/aG4wimfg4ZSXOmU+3Cmokas2VskzlTUiB1HikV1bZ2oc7nlfZ0qrxHFlU7V+kWl1eJkWbXpPupcbvlaafutd05LqnyPr6TKKQ6dLPf7+JRU19aJ6to6cfBEuSgoqRJVTuvr6arvuxH+XD9nnUs+rppal/jfznxRXOE5/2cqaoQQQhwoKtP9Lmv3ueXwaXHwRLn8fl9hmeF96ZcT5aKsula1TLrGQni+T8rrUFrlFCt25ts6P0pOldeIb/YUioKSKtN2LpdbbDp0WuQXV8n7+3zHcbkPPxw8Jb76qUA+V6VVTnHwRLl4N/eQ2H7kjPh4yxH5+3CgqMxwH0II8XNBqdh+5Iyt/u88ViwOn/T+Xl2K+47L5RYFJVXiv9uPiUMny0VJlVO+v7jdblFZUyd+PFoslm89Kn9nlm89Kl7/9oBYtOaAKCypEseLK8WXP+bL3xm323MeCnXO15bDp8Wn246JmlqX4XXdX1Qm3sk9JNbuPyGEEOLrXQXilxPq30hplVOcLKsWdS63eGfdQbHyp4Kgj18lJSW2x2+HEPZr7R4/fhydOnXCunXrkJnpfTJ75JFHsGbNGmzYsMFnnbi4OCxevBjjx4+Xl73yyit4+umnUVhYiHXr1mHkyJE4fvw4OnToILe59dZb4XA4sHTpUp9t6llYunTpgpKSEiQnB3fiMEIIIYSEhtLSUqSkpNgav/2KYUlLS0N0dDQKC9X1EAoLC5GRkaG7TkZGhml76b8/24yPj0dycrLqjxBCCCGRi1+CJS4uDkOGDEFOTo68zO12IycnR2VxUZKZmalqDwArV66U2/fo0QMZGRmqNqWlpdiwYYPhNgkhhBByduF3WPm0adMwceJEXHTRRRg6dCjmzZuHiooKTJo0CQAwYcIEdOrUCbNnzwYAPPTQQ7jsssswZ84cXHfddfjggw+wadMmLFq0CIAn0PLhhx/GX//6V/Tq1UtOa+7YsSPGjBkTvCMlhBBCSLPFb8Eybtw4nDhxAjNnzkRBQQEGDhyIFStWID3dk/aUl5eHKEUZ8BEjRmDJkiV44okn8Pjjj6NXr15Yvny5XIMF8MTAVFRU4J577kFxcTEuueQSrFixosnVYCGEEEJIePAr6Lap4k/QDiGEEEKaBiELuiWEEEIICQcULIQQQghp8lCwEEIIIaTJQ8FCCCGEkCYPBQshhBBCmjwULIQQQghp8lCwEEIIIaTJQ8FCCCGEkCaP35VumyJS7bvS0tIw94QQQgghdpHGbTs1bCNCsJSVlQEAunTpEuaeEEIIIcRfysrKkJKSYtomIkrzu91uHD9+HK1atYLD4QjqtktLS9GlSxccOXKEZf9DCM9z48Fz3TjwPDcOPM+NRyjOtRACZWVl6Nixo2oeQj0iwsISFRWFzp07h3QfycnJ/DE0AjzPjQfPdePA89w48Dw3HsE+11aWFQkG3RJCCCGkyUPBQgghhJAmDwWLBfHx8Zg1axbi4+PD3ZWIhue58eC5bhx4nhsHnufGI9znOiKCbgkhhBAS2dDCQgghhJAmDwULIYQQQpo8FCyEEEIIafJQsBBCCCGkyUPBQgghhJAmDwWLBQsWLED37t2RkJCAYcOGYePGjeHuUrPi22+/xa9//Wt07NgRDocDy5cvV30uhMDMmTPRoUMHJCYmIisrC/v27VO1OX36NO644w4kJycjNTUVkydPRnl5eSMeRdNn9uzZuPjii9GqVSu0b98eY8aMwd69e1Vtqqur8cADD6Bt27Zo2bIlfvOb36CwsFDVJi8vD9dddx2SkpLQvn17TJ8+HXV1dY15KE2aV199FRdeeKFc6TMzMxNffvml/DnPcWj429/+BofDgYcfflhexnMdHJ566ik4HA7VX+/eveXPm9R5FsSQDz74QMTFxYk333xT/PTTT2LKlCkiNTVVFBYWhrtrzYYvvvhC/N///Z/4+OOPBQDxySefqD7/29/+JlJSUsTy5cvF9u3bxQ033CB69Oghqqqq5DajR48WAwYMEOvXrxffffed6Nmzpxg/fnwjH0nTJjs7W7z11lti586dYtu2beLaa68VXbt2FeXl5XKbe++9V3Tp0kXk5OSITZs2ieHDh4sRI0bIn9fV1Yl+/fqJrKwssXXrVvHFF1+ItLQ0MWPGjHAcUpPk008/FZ9//rn4+eefxd69e8Xjjz8uYmNjxc6dO4UQPMehYOPGjaJ79+7iwgsvFA899JC8nOc6OMyaNUtccMEFIj8/X/47ceKE/HlTOs8ULCYMHTpUPPDAA/J7l8slOnbsKGbPnh3GXjVftILF7XaLjIwM8cILL8jLiouLRXx8vHj//feFEELs2rVLABA//PCD3ObLL78UDodDHDt2rNH63twoKioSAMSaNWuEEJ7zGhsbK5YtWya32b17twAgcnNzhRAecRkVFSUKCgrkNq+++qpITk4WNTU1jXsAzYjWrVuLN954g+c4BJSVlYlevXqJlStXissuu0wWLDzXwWPWrFliwIABup81tfNMl5ABTqcTmzdvRlZWlrwsKioKWVlZyM3NDWPPIoeDBw+ioKBAdY5TUlIwbNgw+Rzn5uYiNTUVF110kdwmKysLUVFR2LBhQ6P3ublQUlICAGjTpg0AYPPmzaitrVWd6969e6Nr166qc92/f3+kp6fLbbKzs1FaWoqffvqpEXvfPHC5XPjggw9QUVGBzMxMnuMQ8MADD+C6665TnVOA3+dgs2/fPnTs2BHnnHMO7rjjDuTl5QFoeuc5ImZrDgUnT56Ey+VSXQQASE9Px549e8LUq8iioKAAAHTPsfRZQUEB2rdvr/o8JiYGbdq0kdsQNW63Gw8//DBGjhyJfv36AfCcx7i4OKSmpqraas+13rWQPiMefvzxR2RmZqK6uhotW7bEJ598gr59+2Lbtm08x0Hkgw8+wJYtW/DDDz/4fMbvc/AYNmwY3n77bZx//vnIz8/H008/jUsvvRQ7d+5scueZgoWQCOOBBx7Azp078f3334e7KxHJ+eefj23btqGkpAQffvghJk6ciDVr1oS7WxHFkSNH8NBDD2HlypVISEgId3cimmuuuUZ+feGFF2LYsGHo1q0b/v3vfyMxMTGMPfOFLiED0tLSEB0d7RMNXVhYiIyMjDD1KrKQzqPZOc7IyEBRUZHq87q6Opw+fZrXQYepU6fis88+w6pVq9C5c2d5eUZGBpxOJ4qLi1Xtteda71pInxEPcXFx6NmzJ4YMGYLZs2djwIABePHFF3mOg8jmzZtRVFSEwYMHIyYmBjExMVizZg1eeuklxMTEID09nec6RKSmpuK8887D/v37m9x3moLFgLi4OAwZMgQ5OTnyMrfbjZycHGRmZoaxZ5FDjx49kJGRoTrHpaWl2LBhg3yOMzMzUVxcjM2bN8ttvvnmG7jdbgwbNqzR+9xUEUJg6tSp+OSTT/DNN9+gR48eqs+HDBmC2NhY1bneu3cv8vLyVOf6xx9/VAnElStXIjk5GX379m2cA2mGuN1u1NTU8BwHkauuugo//vgjtm3bJv9ddNFFuOOOO+TXPNehoby8HAcOHECHDh2a3nc6qCG8EcYHH3wg4uPjxdtvvy127dol7rnnHpGamqqKhibmlJWVia1bt4qtW7cKAGLu3Lli69at4vDhw0IIT1pzamqq+M9//iN27NghbrzxRt205kGDBokNGzaI77//XvTq1YtpzRruu+8+kZKSIlavXq1KT6ysrJTb3HvvvaJr167im2++EZs2bRKZmZkiMzNT/lxKTxw1apTYtm2bWLFihWjXrh3TQBU89thjYs2aNeLgwYNix44d4rHHHhMOh0N89dVXQgie41CizBISguc6WPzpT38Sq1evFgcPHhRr164VWVlZIi0tTRQVFQkhmtZ5pmCx4OWXXxZdu3YVcXFxYujQoWL9+vXh7lKzYtWqVQKAz9/EiROFEJ7U5ieffFKkp6eL+Ph4cdVVV4m9e/eqtnHq1Ckxfvx40bJlS5GcnCwmTZokysrKwnA0TRe9cwxAvPXWW3Kbqqoqcf/994vWrVuLpKQkcdNNN4n8/HzVdg4dOiSuueYakZiYKNLS0sSf/vQnUVtb28hH03S5++67Rbdu3URcXJxo166duOqqq2SxIgTPcSjRChae6+Awbtw40aFDBxEXFyc6deokxo0bJ/bv3y9/3pTOs0MIIYJrsyGEEEIICS6MYSGEEEJIk4eChRBCCCFNHgoWQgghhDR5KFgIIYQQ0uShYCGEEEJIk4eChRBCCCFNHgoWQgghhDR5KFgIIYQQ0uShYCGEEEJIk4eChRBCCCFNHgoWQgghhDR5/j8gkEGmEdl36gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not model_loaded:\n",
    "    # plt.plot(test_total_losses)\n",
    "    plt.plot(test_feature_losses)\n",
    "    # plt.plot(edge_losses)\n",
    "    # plt.plot(kl_losses)\n",
    "    plt.title(\"Test Feature Loss\")\n",
    "    plt.legend(['Feature Loss', 'KL Loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not model_loaded:\n",
    "    plt.plot(test_position_losses)\n",
    "    plt.title(\"Test Position Loss\")\n",
    "\n",
    "    # atomic radius of oxygen is 0.74 Angstrom\n",
    "    # atomic radius of hydrogen is 0.53 Angstrom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh1tn4jHZzNy",
    "outputId": "baaf7ea4-07e8-41bd-aac6-9575569172ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error 0.001669103133448804\n"
     ]
    }
   ],
   "source": [
    "from torch.functional import F\n",
    "\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "\n",
    "embeddings = []\n",
    "input_feature = []\n",
    "decoded_feature = []\n",
    "\n",
    "for ind in range(len(test_loader)):\n",
    "    test_graph = test_loader.dataset[ind]\n",
    "\n",
    "    model.double()\n",
    "    z,encoded_edge_index = model.encode(test_graph.x,test_graph.edge_index)\n",
    "    decoded_x,decoded_edge_index = model.decode(z,encoded_edge_index)\n",
    "    heavy_indices = torch.where(test_graph.x[:,4] > torch.tensor([1]).to(device))\n",
    "\n",
    "    embeddings.append(z)\n",
    "    decoded_feature.append(decoded_x)\n",
    "    input_feature.append(test_graph.x)\n",
    "    \n",
    "    Error_wo_s = F.mse_loss(decoded_x[heavy_indices], test_graph.x[heavy_indices]).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    avg1 += Error_wo_s\n",
    "\n",
    "    # print(\"Error\" , Error_wo_s, Error_af_s)\n",
    "\n",
    "print(\"Average Error\", avg1/len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.8339,  9.9647, 10.8328,  0.1527,  8.0056]], dtype=torch.float64,\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([[10.7963,  9.9279, 10.7336,  0.1520,  8.0000]], dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "heavy_indices = torch.where(input_feature[0][:,4] > torch.tensor([1]).to(device))\n",
    "heavy_indices\n",
    "decoded_feature[0][heavy_indices],input_feature[0][heavy_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "YdJKGevGm0sr",
    "outputId": "476d0e1c-deb3-41e1-a68a-e71d58f173df"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_self_loops=False\n",
    "adj_binary = convert_to_adj(decoded_edge_index, num_nodes=decoded_x.shape[0])\n",
    "indices = torch.where(adj_binary)\n",
    "G = nx.Graph()\n",
    "if not add_self_loops:\n",
    "    edges = [(i, j) for i, j in zip(indices[0].tolist(), indices[1].tolist()) if i != j]\n",
    "    G.add_edges_from(edges)\n",
    "else:\n",
    "    G.add_edges_from(zip(indices[0].tolist(), indices[1].tolist()))\n",
    "nx.draw_networkx(G)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQZK2tNWrgPu"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f9761786ac07e4eab4386916b2ac1a9951f01c213aa09aceac38efe2713e05d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "174bcfbaa57647a791816ea2f5f95aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "",
      "disabled": false,
      "icon": "compress",
      "layout": "IPY_MODEL_f7e90ca6eca44a02aa7dbd7c721963d2",
      "style": "IPY_MODEL_d0b06dda6324492e96af92e3aeea444b",
      "tooltip": ""
     }
    },
    "1ccf61fe60854532adca37efa0ce3d8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dbdb82571c54cdd93dc2852bfff8d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51f160dd2cbe413ca4340f08c1c556c6",
       "IPY_MODEL_f25cd88e94d7471fba0524c195300dbd"
      ],
      "layout": "IPY_MODEL_c842ad6e08ac425eade8ae91843af6cf"
     }
    },
    "51f160dd2cbe413ca4340f08c1c556c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PlayModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PlayModel",
      "_playing": false,
      "_repeat": false,
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PlayView",
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "interval": 100,
      "layout": "IPY_MODEL_8cb134fe0b18494bbefe6c95adc7d14e",
      "max": 0,
      "min": 0,
      "show_repeat": true,
      "step": 1,
      "style": "IPY_MODEL_65d323feef3b4d44a7846a7c208946f1",
      "value": 0
     }
    },
    "65d323feef3b4d44a7846a7c208946f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83451c0f082c4aa888b1dd14e9c775bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb134fe0b18494bbefe6c95adc7d14e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3e2e11d45734b7d9224fb987459470b": {
     "model_module": "nglview-js-widgets",
     "model_module_version": "3.0.1",
     "model_name": "NGLModel",
     "state": {
      "_camera_orientation": [
       -10.103352365027183,
       6.385389408422379,
       -0.592550746983955,
       0,
       3.959195270940704,
       5.341158002393939,
       -9.949816445385695,
       0,
       -5.0447088212804285,
       -8.596561905384883,
       -6.622090275149148,
       0,
       -1.7100000381469727,
       -0.8059999942779541,
       -0.2979999780654907,
       1
      ],
      "_camera_str": "orthographic",
      "_dom_classes": [],
      "_gui_theme": null,
      "_ibtn_fullscreen": "IPY_MODEL_174bcfbaa57647a791816ea2f5f95aba",
      "_igui": null,
      "_iplayer": "IPY_MODEL_1dbdb82571c54cdd93dc2852bfff8d40",
      "_model_module": "nglview-js-widgets",
      "_model_module_version": "3.0.1",
      "_model_name": "NGLModel",
      "_ngl_color_dict": {},
      "_ngl_coordinate_resource": {},
      "_ngl_full_stage_parameters": {
       "ambientColor": 14540253,
       "ambientIntensity": 0.2,
       "backgroundColor": "white",
       "cameraEyeSep": 0.3,
       "cameraFov": 40,
       "cameraType": "perspective",
       "clipDist": 10,
       "clipFar": 100,
       "clipNear": 0,
       "fogFar": 100,
       "fogNear": 50,
       "hoverTimeout": 0,
       "impostor": true,
       "lightColor": 14540253,
       "lightIntensity": 1,
       "mousePreset": "default",
       "panSpeed": 1,
       "quality": "medium",
       "rotateSpeed": 2,
       "sampleLevel": 0,
       "tooltip": true,
       "workerDefault": true,
       "zoomSpeed": 1.2
      },
      "_ngl_msg_archive": [
       {
        "args": [
         {
          "binary": false,
          "data": "MODEL     1\nATOM      1    O MOL     1       1.736   0.839   0.257  1.00  0.00           O  \nATOM      2    H MOL     1       1.777   0.781   0.322  1.00  0.00           H  \nATOM      3    H MOL     1       1.643   0.831   0.274  1.00  0.00           H  \nATOM      4    X MOL     1       1.730   0.831   0.267  1.00  0.00           X  \nENDMDL\n",
          "type": "blob"
         }
        ],
        "kwargs": {
         "defaultRepresentation": true,
         "ext": "pdb"
        },
        "methodName": "loadFile",
        "reconstruc_color_scheme": false,
        "target": "Stage",
        "type": "call_method"
       }
      ],
      "_ngl_original_stage_parameters": {
       "ambientColor": 14540253,
       "ambientIntensity": 0.2,
       "backgroundColor": "white",
       "cameraEyeSep": 0.3,
       "cameraFov": 40,
       "cameraType": "perspective",
       "clipDist": 10,
       "clipFar": 100,
       "clipNear": 0,
       "fogFar": 100,
       "fogNear": 50,
       "hoverTimeout": 0,
       "impostor": true,
       "lightColor": 14540253,
       "lightIntensity": 1,
       "mousePreset": "default",
       "panSpeed": 1,
       "quality": "medium",
       "rotateSpeed": 2,
       "sampleLevel": 0,
       "tooltip": true,
       "workerDefault": true,
       "zoomSpeed": 1.2
      },
      "_ngl_repr_dict": {
       "0": {
        "0": {
         "params": {
          "aspectRatio": 1.5,
          "assembly": "default",
          "bondScale": 0.3,
          "bondSpacing": 0.75,
          "clipCenter": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "clipNear": 0,
          "clipRadius": 0,
          "colorMode": "hcl",
          "colorReverse": false,
          "colorScale": "",
          "colorScheme": "element",
          "colorValue": 9474192,
          "cylinderOnly": false,
          "defaultAssembly": "",
          "depthWrite": true,
          "diffuse": 16777215,
          "diffuseInterior": false,
          "disableImpostor": false,
          "disablePicking": false,
          "flatShaded": false,
          "interiorColor": 2236962,
          "interiorDarkening": 0,
          "lazy": false,
          "lineOnly": false,
          "linewidth": 2,
          "matrix": {
           "elements": [
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1
           ]
          },
          "metalness": 0,
          "multipleBond": "off",
          "opacity": 1,
          "openEnded": true,
          "quality": "high",
          "radialSegments": 20,
          "radiusData": {},
          "radiusScale": 2,
          "radiusSize": 0.15,
          "radiusType": "size",
          "roughness": 0.4,
          "sele": "",
          "side": "double",
          "sphereDetail": 2,
          "useInteriorColor": true,
          "visible": true,
          "wireframe": false
         },
         "type": "ball+stick"
        }
       },
       "1": {
        "0": {
         "params": {
          "aspectRatio": 1.5,
          "assembly": "default",
          "bondScale": 0.3,
          "bondSpacing": 0.75,
          "clipCenter": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "clipNear": 0,
          "clipRadius": 0,
          "colorMode": "hcl",
          "colorReverse": false,
          "colorScale": "",
          "colorScheme": "element",
          "colorValue": 9474192,
          "cylinderOnly": false,
          "defaultAssembly": "",
          "depthWrite": true,
          "diffuse": 16777215,
          "diffuseInterior": false,
          "disableImpostor": false,
          "disablePicking": false,
          "flatShaded": false,
          "interiorColor": 2236962,
          "interiorDarkening": 0,
          "lazy": false,
          "lineOnly": false,
          "linewidth": 2,
          "matrix": {
           "elements": [
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1
           ]
          },
          "metalness": 0,
          "multipleBond": "off",
          "opacity": 1,
          "openEnded": true,
          "quality": "high",
          "radialSegments": 20,
          "radiusData": {},
          "radiusScale": 2,
          "radiusSize": 0.15,
          "radiusType": "size",
          "roughness": 0.4,
          "sele": "",
          "side": "double",
          "sphereDetail": 2,
          "useInteriorColor": true,
          "visible": true,
          "wireframe": false
         },
         "type": "ball+stick"
        }
       }
      },
      "_ngl_serialize": false,
      "_ngl_version": "2.0.0-dev.36",
      "_ngl_view_id": [
       "5FF00EC2-ABC3-45F3-A902-138379E769E1"
      ],
      "_player_dict": {},
      "_scene_position": {},
      "_scene_rotation": {},
      "_synced_model_ids": [],
      "_synced_repr_model_ids": [],
      "_view_count": null,
      "_view_height": "",
      "_view_module": "nglview-js-widgets",
      "_view_module_version": "3.0.1",
      "_view_name": "NGLView",
      "_view_width": "",
      "background": "white",
      "frame": 0,
      "gui_style": null,
      "layout": "IPY_MODEL_83451c0f082c4aa888b1dd14e9c775bf",
      "max_frame": 0,
      "n_components": 2,
      "picked": {}
     }
    },
    "c842ad6e08ac425eade8ae91843af6cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0b06dda6324492e96af92e3aeea444b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "e8f4eabea82a4f928fa75a55769ed112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "f25cd88e94d7471fba0524c195300dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_1ccf61fe60854532adca37efa0ce3d8c",
      "max": 0,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_e8f4eabea82a4f928fa75a55769ed112",
      "value": 0
     }
    },
    "f7e90ca6eca44a02aa7dbd7c721963d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "34px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
