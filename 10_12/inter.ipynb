{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7983c5d4cf794fa78c2e562fe3a55c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stage1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes,natoms,nmols=(0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage2 import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (encoder): VariationalGCNEncoder(\n",
       "    (conv1): GATConv(5, 15, heads=3)\n",
       "    (head_transform1): Linear(45, 15, bias=True)\n",
       "    (bn1): BatchNorm(15)\n",
       "    (conv2): GCNConv(15, 9)\n",
       "    (bn2): BatchNorm(9)\n",
       "    (linear1): Linear(9, 100, bias=True)\n",
       "    (linear2): Linear(100, 4, bias=True)\n",
       "    (transform): Linear(16, 3, bias=True)\n",
       "    (mu): Linear(3, 3, bias=True)\n",
       "    (logstd): Linear(3, 3, bias=True)\n",
       "  )\n",
       "  (decoder): VariationalGCNDecoder(\n",
       "    (inv_transform): Linear(3, 4, bias=True)\n",
       "    (conv1): GCNConv(1, 9)\n",
       "    (bn1): BatchNorm(9)\n",
       "    (conv2): GCNConv(9, 3)\n",
       "    (bn2): BatchNorm(3)\n",
       "    (conv3): GCNConv(3, 3)\n",
       "    (linear1): Linear(3, 512, bias=True)\n",
       "    (linear2): Linear(512, 128, bias=True)\n",
       "    (linear3): Linear(128, 5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testframe=md.load_xtc(\"../../xtc_files/50000eql2.xtc\",top=\"../../xtc_files/conf.gro\",frame=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf=condenseframe(testframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50001 4 592\n"
     ]
    }
   ],
   "source": [
    "meltframes=md.load_xtc(\"../../xtc_files/50000eql2.xtc\",top=\"../../xtc_files/conf.gro\")\n",
    "meltframes.xyz=meltframes.xyz*10\n",
    "global nframes,natoms,nmols \n",
    "nframes = meltframes.xyz.shape[0]\n",
    "natoms = meltframes.topology.residue(0).n_atoms\n",
    "nmols = meltframes.topology.n_residues\n",
    "print (nframes,natoms,nmols)\n",
    "meltframes=meltframes[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.84576243e+02, -9.36140506e+01, -1.56635818e+02,\n",
       "         2.28225017e+00,  9.52250063e-01,  1.95350003e+00],\n",
       "       [ 7.79803099e+02, -9.30955292e+01, -1.55628271e+02,\n",
       "         1.36549997e+00,  1.45650005e+00,  2.59900022e+00],\n",
       "       [ 8.75985383e+02, -1.05724399e+02, -1.74737958e+02,\n",
       "         8.33750010e-01,  1.77175009e+00,  7.37500072e-01],\n",
       "       ...,\n",
       "       [ 7.41200941e+02, -8.83453476e+01, -1.47991849e+02,\n",
       "         2.56474996e+00,  1.57500005e+00,  2.47574997e+00],\n",
       "       [ 7.57661722e+02, -9.03470056e+01, -1.51268077e+02,\n",
       "         1.61825013e+00,  1.92200017e+00,  2.49900007e+00],\n",
       "       [ 8.03441321e+02, -9.64539095e+01, -1.60332419e+02,\n",
       "         7.91500092e-01,  2.24175000e+00,  2.16525006e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:34<00:00,  1.47it/s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.83it/s]\n"
     ]
    }
   ],
   "source": [
    "melt_condensed=condenseAllFrames(meltframes)\n",
    "graphs_melt_cpu=get_graphs(melt_condensed,\"melt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(graphs_melt_cpu,f'./graphs/melt_neigh{n_neigh}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_graph(cf,1,n_neigh,\"cry\")\n",
    "# print(g.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_cpu=graphs_melt_cpu\n",
    "np.random.shuffle(graphs_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "in_channels = graphs_cpu[0].num_features\n",
    "out_channels = 5\n",
    "lr = 1e-4\n",
    "n_epochs = 400\n",
    "batch_size=64\n",
    "test_train_split = 0.8\n",
    "model_name = \"Inter.pt\"\n",
    "model_loaded = False\n",
    "force_train = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if os.path.exists(\"./\"+model_name) and not force_train:\n",
    "    model = torch.load(\"./\"+model_name)\n",
    "    model_loaded = True\n",
    "else:\n",
    "    model = VGAE_S2(VariationalGCNEncoder_S2(in_channels, out_channels,batch_size,n_neigh+1),\n",
    "                    VariationalGCNDecoder_S2(out_channels, in_channels,batch_size,n_neigh+1))\n",
    "\n",
    "model = model.to(device)\n",
    "model = model.double()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30192/30192 [00:00<00:00, 57752.63it/s]\n"
     ]
    }
   ],
   "source": [
    "graphs_device = []\n",
    "for graph in tqdm(graphs_cpu):\n",
    "    graphs_device.append(graph.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = graphs_device\n",
    "total_graphs = len(graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "total_graphs: 30192\n",
      "batch Size: 64\n",
      "number of batches: 471\n",
      "Neighbours: 15\n",
      "Model\n",
      " VGAE_S2(\n",
      "  (encoder): VariationalGCNEncoder_S2(\n",
      "    (conv1): GATConv(6, 20, heads=6)\n",
      "    (head_transform1): Linear(120, 20, bias=True)\n",
      "    (bn1): BatchNorm(20)\n",
      "    (conv2): GATConv(20, 10, heads=6)\n",
      "    (head_transform2): Linear(60, 10, bias=True)\n",
      "    (bn2): BatchNorm(10)\n",
      "    (linear1): Linear(10, 100, bias=True)\n",
      "    (linear2): Linear(100, 4, bias=True)\n",
      "    (transform): Linear(64, 5, bias=True)\n",
      "    (mu): Linear(5, 5, bias=True)\n",
      "    (logstd): Linear(5, 5, bias=True)\n",
      "  )\n",
      "  (decoder): VariationalGCNDecoder_S2(\n",
      "    (inv_transform): Linear(5, 80, bias=True)\n",
      "    (conv1): GCNConv(5, 3)\n",
      "    (conv2): GCNConv(3, 10)\n",
      "    (conv3): GCNConv(10, 30)\n",
      "    (bn): BatchNorm(30)\n",
      "    (linear1): Linear(30, 128, bias=True)\n",
      "    (linear2): Linear(128, 64, bias=True)\n",
      "    (linear3): Linear(64, 6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Using:\",device )\n",
    "print(\"total_graphs:\", total_graphs)\n",
    "print(\"batch Size:\" , batch_size)\n",
    "print(\"number of batches:\",total_graphs//batch_size)\n",
    "print(\"Neighbours:\",n_neigh)\n",
    "print(\"Model\\n\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(test_train_split * total_graphs)\n",
    "\n",
    "train_loader = DataLoader(graphs[:split], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(graphs[split:], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "MSE_loss = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    all_loss_mse = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        \n",
    "        loss = MSE_loss(decoded_x, data.x)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        all_loss_mse += float(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    return all_loss_mse/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "    all_loss_mse = 0\n",
    "    for data in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        loss = MSE_loss(decoded_x, data.x)\n",
    "\n",
    "        all_loss_mse += float(loss)\n",
    "\n",
    "\n",
    "    return all_loss_mse/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/imami/watermodel/10_12/inter.ipynb Cell 20\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         train_loss_mse \u001b[39m=\u001b[39m train()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         test_loss_mse \u001b[39m=\u001b[39m test()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/imami/watermodel/10_12/inter.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss \u001b[39m=\u001b[39m MSE_loss(decoded_x, data\u001b[39m.\u001b[39mx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     all_loss_mse \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_12/inter.ipynb#X41sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mreturn\u001b[39;00m all_loss_mse\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "if model_loaded:\n",
    "    print(\"Pretrained Model Loaded, no training required\")\n",
    "else:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss_mse = train()\n",
    "        test_loss_mse = test()\n",
    "\n",
    "        print(f\"Epoch: {epoch:03d}\")\n",
    "        print(f'\\tTrain:\\tMSE Loss: {train_loss_mse:.4f}')\n",
    "        print(f'\\tTest: \\tMSE Loss: {test_loss_mse:.4f}')\n",
    "\n",
    "        train_losses.append([train_loss_mse]);\n",
    "        test_losses.append([test_loss_mse]);\n",
    "\n",
    "        scheduler.step()\n",
    "    torch.save(model,\"./\"+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_loaded:\n",
    "    plt.figure()\n",
    "    plt.plot(test_losses, label='Total Test Loss')\n",
    "    plt.plot(train_losses, label='Total Train Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Total Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_melt = DataLoader(graphs_melt_cpu[::100], batch_size=1)\n",
    "pred_melt=[]\n",
    "for data in tqdm(test_loader_melt):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    pred = model(data.x.float(),data.edge_index)\n",
    "    pred_melt.append(pred.cpu().detach().numpy())\n",
    "pred_melt = np.array(pred_melt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_test = test_loader_melt\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "ConfusionMatrixDisplay(cm).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "data_melt = pred_melt\n",
    "data_cry = pred_cry\n",
    "\n",
    "plt.scatter(data_melt[:,0],data_melt[:,1],c=\"r\",label=\"melt\")\n",
    "plt.scatter(data_cry[:,0],data_cry[:,1],c=\"b\",label=\"crystal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
