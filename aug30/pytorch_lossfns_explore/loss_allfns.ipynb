{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Import the cuda module\n",
    "    from torch import cuda\n",
    "\n",
    "    # Now you can use cuda for GPU operations\n",
    "    # For example, you can create a CUDA device object like this:\n",
    "    device = torch.device(\"cuda:0\")  # Assuming you have a GPU with device index 0\n",
    "\n",
    "   \n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cuda_ext_available' from 'torch' (/home/imami/.local/lib/python3.10/site-packages/torch/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m GCNConv\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_ext_available\n\u001b[1;32m     10\u001b[0m \u001b[39m#from torch_geometric import cuda_ext_available\u001b[39;00m\n\u001b[1;32m     12\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mhuber_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfirst_derivative_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlp_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mssim\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpsnr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mchamfer_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39memd_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtv_reg\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mspectral_norm\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cuda_ext_available' from 'torch' (/home/imami/.local/lib/python3.10/site-packages/torch/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "#import torch\n",
    "#cuda_available = torch.cuda.is_available()\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric import utils\n",
    "from torch import cuda_ext_available\n",
    "#from torch_geometric import cuda_ext_available\n",
    "\n",
    "__all__ = ['huber_loss', 'first_derivative_loss', 'lp_loss', 'ssim', 'psnr', 'chamfer_loss', 'emd_loss', 'tv_reg',\n",
    "           'spectral_norm']\n",
    "\n",
    "\n",
    "def huber_loss(x, y, reduce='mean'):\n",
    "    \"\"\"\n",
    "    An alias for :func:`torch.nn.functional.smooth_l1_loss`.\n",
    "    \"\"\"\n",
    "\n",
    "    return F.smooth_l1_loss(x, y, reduce=reduce)\n",
    "\n",
    "def first_derivative_loss(x, y, p=2):\n",
    "    \"\"\"\n",
    "    Calculates lp loss between the first derivatives of the inputs.\n",
    "\n",
    "    :param x:\n",
    "        a :class:`torch.Tensor`.\n",
    "    :param y:\n",
    "        a :class:`torch.Tensor` of the same shape as x.\n",
    "    :param p:\n",
    "        order of the norm.\n",
    "    :return:\n",
    "        the scalar loss between the first derivatives of the inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.ndimension() != 4 and y.ndimension() != 4:\n",
    "        raise TypeError('y and y_pred should have four dimensions')\n",
    "\n",
    "    kern_x = T.from_numpy(np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype='float32')).requires_grad_(False)\n",
    "    kern_x = T.flip(kern_x.expand(y.shape[1], y.shape[1], 3, 3), (0, 1)).to(x.device)\n",
    "\n",
    "    kern_y = T.from_numpy(np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype='float32')).requires_grad_(False)\n",
    "    kern_y = T.flip(kern_y.expand(y.shape[1], y.shape[1], 3, 3), (0, 1)).to(x.device)\n",
    "\n",
    "    x_grad_x = F.conv2d(x, kern_x, padding=1)\n",
    "    x_grad_y = F.conv2d(x, kern_y, padding=1)\n",
    "    x_grad = T.sqrt(x_grad_x ** 2 + x_grad_y ** 2 + 1e-10)\n",
    "\n",
    "    y_grad_x = F.conv2d(y, kern_x, padding=1)\n",
    "    y_grad_y = F.conv2d(y, kern_y, padding=1)\n",
    "    y_grad = T.sqrt(y_grad_x ** 2 + y_grad_y ** 2 + 1e-10)\n",
    "    return lp_loss(x_grad, y_grad, p)\n",
    "\n",
    "\n",
    "def lp_loss(x, y, p=2, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Calculates p-norm of (x - y).\n",
    "\n",
    "    :param x:\n",
    "        a :class:`torch.Tensor`.\n",
    "    :param y:\n",
    "        a :class:`torch.Tensor` of the same shape as x.\n",
    "    :param p:\n",
    "        order of the norm.\n",
    "    :param reduction:\n",
    "        ``'mean'`` or ``'sum'``.\n",
    "    :return:\n",
    "        the p-norm of (x - y).\n",
    "    \"\"\"\n",
    "    assert reduction in ('sum', 'mean'), 'Unknown choice of reduction'\n",
    "\n",
    "    if y.ndimension() != x.ndimension():\n",
    "        raise TypeError('y should have the same shape as y_pred', ('y', y.data.type(), 'y_pred', x.data.type()))\n",
    "\n",
    "    if p == 1:\n",
    "        return F.l1_loss(x, y, reduction=reduction)\n",
    "    elif p == 2:\n",
    "        return F.mse_loss(x, y, reduction=reduction)\n",
    "    else:\n",
    "        reduce = T.mean if reduction == 'mean' else T.sum\n",
    "        return reduce(T.abs(x - y) ** p)\n",
    "\n",
    "def chamfer_loss(xyz1, xyz2, reduce='mean', c_code=cuda_ext_available):\n",
    "    \"\"\"\n",
    "    Calculates the Chamfer distance between two batches of point clouds.\n",
    "    The Pytorch code is adapted from DenseLidarNet_.\n",
    "    The CUDA code is adapted from AtlasNet_.\n",
    "\n",
    "    .. _DenseLidarNet: https://github.com/345ishaan/DenseLidarNet/blob/master/code/chamfer_loss.py\n",
    "    .. _AtlasNet: https://github.com/ThibaultGROUEIX/AtlasNet/tree/master/extension\n",
    "\n",
    "    :param xyz1:\n",
    "        a point cloud of shape ``(b, n1, k)`` or ``(n1, k)``.\n",
    "    :param xyz2:\n",
    "        a point cloud of shape (b, n2, k) or (n2, k).\n",
    "    :param reduce:\n",
    "        ``'mean'`` or ``'sum'``. Default: ``'mean'``.\n",
    "    :param c_code:\n",
    "        whether to use CUDA implementation.\n",
    "        This version is much more memory-friendly and slightly faster.\n",
    "    :return:\n",
    "        the Chamfer distance between the inputs.\n",
    "    \"\"\"\n",
    "    assert len(xyz1.shape) in (2, 3) and len(xyz2.shape) in (2, 3), 'Unknown shape of tensors'\n",
    "\n",
    "    if xyz1.dim() == 2:\n",
    "        xyz1 = xyz1.unsqueeze(0)\n",
    "\n",
    "    if xyz2.dim() == 2:\n",
    "        xyz2 = xyz2.unsqueeze(0)\n",
    "\n",
    "    assert reduce in ('mean', 'sum'), 'Unknown reduce method'\n",
    "    reduce = T.sum if reduce == 'sum' else T.mean\n",
    "\n",
    "    if c_code:\n",
    "        from .extensions import chamfer_distance\n",
    "        dist1, dist2 = chamfer_distance(xyz1, xyz2)\n",
    "    else:\n",
    "        P = utils.batch_pairwise_sqdist(xyz1, xyz2, c_code=c_code)\n",
    "        dist2, _ = T.min(P, 1)\n",
    "        dist1, _ = T.min(P, 2)\n",
    "    loss_2 = reduce(dist2)\n",
    "    loss_1 = reduce(dist1)\n",
    "    return loss_1 + loss_2\n",
    "\n",
    "def emd_loss(xyz1, xyz2, reduce='mean', sinkhorn=False):\n",
    "    \"\"\"\n",
    "    Calculates the Earth Mover Distance (or Wasserstein metric) between two sets\n",
    "    of points.\n",
    "\n",
    "    :param xyz1:\n",
    "        a point cloud of shape ``(b, n1, k)`` or ``(n1, k)``.\n",
    "    :param xyz2:\n",
    "        a point cloud of shape (b, n2, k) or (n2, k).\n",
    "    :param reduce:\n",
    "        ``'mean'`` or ``'sum'``. Default: ``'mean'``.\n",
    "    :param sinkhorn:\n",
    "        whether to use the Sinkhorn approximation of the Wasserstein distance.\n",
    "        ``False`` will fall back to a CUDA implementation, which is only available\n",
    "        if the CUDA-extended neuralnet-pytorch is installed.\n",
    "        Default: ``True``.\n",
    "    :return:\n",
    "        the EMD between the inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    assert reduce in ('mean', 'sum'), 'Reduce method should be mean or sum'\n",
    "    if sinkhorn:\n",
    "        import geomloss\n",
    "        return geomloss.SamplesLoss()(xyz1, xyz2)\n",
    "    else:\n",
    "        from .extensions import earth_mover_distance as emd\n",
    "        emd_dist = (emd(xyz1, xyz2) + emd(xyz2, xyz1)) / 2.\n",
    "        return T.mean(emd_dist) if reduce == 'mean' else T.sum(emd_dist)\n",
    "\n",
    "def _fspecial_gauss(size, sigma):\n",
    "    x, y = np.mgrid[-size // 2 + 1:size // 2 + 1, -size // 2 + 1:size // 2 + 1]\n",
    "    g = np.exp(-((x ** 2 + y ** 2) / (2.0 * sigma ** 2)))\n",
    "    return g / np.sum(g)\n",
    "\n",
    "def ssim(img1, img2, max_val=1., filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03, cs_map=False):\n",
    "    \"\"\"\n",
    "    Returns the Structural Similarity Map between `img1` and `img2`.\n",
    "    This function attempts to match the functionality of ssim_index_new.m by\n",
    "    Zhou Wang: http://www.cns.nyu.edu/~lcv/ssim/msssim.zip\n",
    "\n",
    "    :param img1:\n",
    "        a 4D :class:`torch.Tensor`.\n",
    "    :param img2:\n",
    "        a 4D :class:`torch.Tensor` of the same shape as `img1`.\n",
    "    :param max_val:\n",
    "        the dynamic range of the images (i.e., the difference between the\n",
    "        maximum the and minimum allowed values).\n",
    "    :param filter_size:\n",
    "        size of blur kernel to use (will be reduced for small images).\n",
    "    :param filter_sigma:\n",
    "        standard deviation for Gaussian blur kernel (will be reduced\n",
    "        for small images).\n",
    "    :param k1:\n",
    "        constant used to maintain stability in the SSIM calculation (0.01 in\n",
    "        the original paper).\n",
    "    :param k2:\n",
    "        constant used to maintain stability in the SSIM calculation (0.03 in\n",
    "        the original paper).\n",
    "    :return:\n",
    "        pair containing the mean SSIM and contrast sensitivity between `img1` and `img2`.\n",
    "    :raise:\n",
    "        RuntimeError: If input images don't have the same shape or don't have four\n",
    "        dimensions: [batch_size, height, width, depth].\n",
    "    \"\"\"\n",
    "    if img1.ndimension() != 4:\n",
    "        raise RuntimeError('Input images must have four dimensions, not %d', img1.ndimension())\n",
    "\n",
    "    _, _, height, width = img1.shape\n",
    "\n",
    "    # Filter size can't be larger than height or width of images.\n",
    "    size = min((filter_size, height, width))\n",
    "\n",
    "    # Scale down sigma if a smaller filter size is used.\n",
    "    sigma = (size * filter_sigma / filter_size) if filter_size else 1.\n",
    "\n",
    "    if filter_size:\n",
    "        window = T.flip(T.tensor(_fspecial_gauss(size, sigma)), (0, 1)).view(1, 1, size, size)\\\n",
    "            .requires_grad_(False).to(device=img1.device, dtype=img1.dtype)\n",
    "\n",
    "        mu1 = F.conv2d(img1, window)\n",
    "        mu2 = F.conv2d(img2, window)\n",
    "        sigma11 = F.conv2d(img1 * img1, window)\n",
    "        sigma22 = F.conv2d(img2 * img2, window)\n",
    "        sigma12 = F.conv2d(img1 * img2, window)\n",
    "    else:\n",
    "        # Empty blur kernel so no need to convolve.\n",
    "        mu1, mu2 = img1, img2\n",
    "        sigma11 = img1 * img1\n",
    "        sigma22 = img2 * img2\n",
    "        sigma12 = img1 * img2\n",
    "\n",
    "    mu1 = mu1 * mu1\n",
    "    mu2 = mu2 * mu2\n",
    "    mu12 = mu1 * mu2\n",
    "    sigma11 -= mu1\n",
    "    sigma22 -= mu2\n",
    "    sigma12 -= mu12\n",
    "\n",
    "    # Calculate intermediate values used by both ssim and cs_map.\n",
    "    c1 = (k1 * max_val) ** 2\n",
    "    c2 = (k2 * max_val) ** 2\n",
    "    v1 = 2.0 * sigma12 + c2\n",
    "    v2 = sigma11 + sigma22 + c2\n",
    "    ssim = T.mean((((2.0 * mu12 + c1) * v1) / ((mu1 + mu2 + c1) * v2 + 1e-10)))\n",
    "    output = ssim if not cs_map else (ssim, T.mean(v1 / v2))\n",
    "    return output\n",
    "def psnr(x, y):\n",
    "    \"\"\"\n",
    "    Peak-signal-to-noise ratio for [0,1] images.\n",
    "\n",
    "    :param x:\n",
    "        a :class:`torch.Tensor`.\n",
    "    :param y:\n",
    "        a :class:`torch.Tensor` of the same shape as `x`.\n",
    "    \"\"\"\n",
    "\n",
    "    return -10 * T.log(T.mean((y - x) ** 2)) / np.log(10.)\n",
    "\n",
    "def tv_reg(y):\n",
    "    \"\"\"\n",
    "    Total variation regularization.\n",
    "\n",
    "    :param y:\n",
    "        a tensor of at least 2D.\n",
    "        The last 2 dimensions will be regularized.\n",
    "    :return:\n",
    "        the total variation loss.\n",
    "    \"\"\"\n",
    "\n",
    "    return T.sum(T.abs(y[..., :-1] - y[..., 1:])) + T.sum(T.abs(y[..., :-1, :] - y[..., 1:, :]))\n",
    "\n",
    "\n",
    "\n",
    "def spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None):\n",
    "    \"\"\"\n",
    "    Applies :func:`torch.nn.utils.spectral_norm` recursively to `module` and all of\n",
    "    its submodules.\n",
    "\n",
    "    :param module:\n",
    "        containing module.\n",
    "    :param name:\n",
    "        name of weight parameter.\n",
    "        Default: ``'weight'``.\n",
    "    :param n_power_iterations:\n",
    "        number of power iterations to calculate spectral norm.\n",
    "    :param eps:\n",
    "        epsilon for numerical stability in calculating norms.\n",
    "    :param dim:\n",
    "        dimension corresponding to number of outputs,\n",
    "        the default is ``0``, except for modules that are instances of\n",
    "        ConvTranspose{1,2,3}d, when it is ``1``.\n",
    "    :return:\n",
    "        the original module with the spectral norm hook.\n",
    "    \"\"\"\n",
    "    if hasattr(module, 'weight'):\n",
    "        if dim is None:\n",
    "            dim = 1 if isinstance(module, layers.ConvTranspose2d) else 0\n",
    "\n",
    "        if not isinstance(module, (nn.modules.batchnorm._BatchNorm,\n",
    "                                   nn.GroupNorm,\n",
    "                                   nn.LayerNorm)):\n",
    "            module = nn.utils.spectral_norm(module, name, n_power_iterations, eps, dim)\n",
    "\n",
    "        return module\n",
    "    else:\n",
    "        for mod_name, mod in module.named_children():\n",
    "            mod = spectral_norm(mod, name, n_power_iterations, eps, dim)\n",
    "            module.__setattr__(mod_name, mod)\n",
    "        return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
