{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "from ase import Atoms\n",
    "import nglview as nv\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, SAGPooling, InnerProductDecoder\n",
    "import torch_geometric.data as data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PyEMD import EMD\n",
    "import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd=EMD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = md.load_xtc(\"../../aug23/eql2.xtc\", top=\"../../aug23/conf.gro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_fatures = []\n",
    "\n",
    "for i in range(all_frames.xyz.shape[0]):\n",
    "    mol_com_pos = []\n",
    "\n",
    "    for res in all_frames.top.residues:\n",
    "        # print(res.index,end=\" \")\n",
    "        pos = []\n",
    "        for atom in res.atoms:\n",
    "            # print(atom.index,\"-->\" , frame.xyz[0][atom.index],end=\" \")\n",
    "            pos.append(all_frames.xyz[i][atom.index])\n",
    "        mol_com_pos.append(np.mean(pos,axis=0))\n",
    "        \n",
    "        # print()\n",
    "    mol_com_pos = np.array(mol_com_pos).astype(np.float32)  \n",
    "    all_frames_fatures.append(mol_com_pos)\n",
    "\n",
    "all_frames_fatures = np.array(all_frames_fatures).astype(np.float32)\n",
    "print(all_frames_fatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(all_frames.topology.residue(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = all_frames.xyz.shape[0]\n",
    "n_atoms = all_frames.topology.residue(0).n_atoms\n",
    "n_mols = all_frames.topology.n_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of molecules\",n_mols)\n",
    "print(\"number of atoms in molecule\",n_atoms)\n",
    "print(\"number of frames\",n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "frame = 10\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "ax1 = fig.add_subplot(projection='3d')\n",
    "ax1.scatter(all_frames_fatures[frame][:,0],all_frames_fatures[frame][:,1],all_frames_fatures[frame][:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adj(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max() + 1\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    return adj\n",
    "\n",
    "def convert_to_edge_index(adj):\n",
    "    edge_index = adj.nonzero().t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.5\n",
    "\n",
    "all_edge_list = []\n",
    "for frame_i in range(n_frames):\n",
    "    from_list = []\n",
    "    to_list = []\n",
    "\n",
    "    for i in range(len(all_frames_fatures[frame_i])):\n",
    "        for j in range(i+1,len(all_frames_fatures[frame_i])):\n",
    "            if np.linalg.norm(all_frames_fatures[frame_i][i]-all_frames_fatures[frame_i][j]) < cutoff:\n",
    "                # print(i,j,np.linalg.norm(mol_com_pos[i]-mol_com_pos[j]))\n",
    "                from_list.append(i)\n",
    "                to_list.append(j)\n",
    "\n",
    "                to_list.append(i)\n",
    "                from_list.append(j)\n",
    "\n",
    "    edge_list = np.array([from_list,to_list]).astype(np.int64)\n",
    "    all_edge_list.append(edge_list)\n",
    "\n",
    "print(len(all_edge_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "frame = 10\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "adj_binary = convert_to_adj(all_edge_list[frame], num_nodes=592)\n",
    "indices = torch.where(adj_binary)\n",
    "G = nx.Graph()\n",
    "edges = [(i, j) for i, j in zip(indices[0].tolist(), indices[1].tolist()) if i != j]\n",
    "G.add_edges_from(edges)\n",
    "nx.draw_networkx(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to pytorch graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for frame in range(n_frames):\n",
    "    g = data.Data(x=torch.tensor(all_frames_fatures[frame]).float(), edge_index=torch.tensor(all_edge_list[frame]).long(), y=torch.tensor([0]))\n",
    "    graphs.append(g)\n",
    "\n",
    "print(graphs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "EPS = 1e-15\n",
    "MAX_LOGSTD = 10\n",
    "edgeShape = None\n",
    "featureShape = None\n",
    "\n",
    "\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    r\"\"\"The inner product decoder from the `\"Variational Graph Auto-Encoders\"\n",
    "    <https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})\n",
    "\n",
    "    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent\n",
    "    space produced by the encoder.\"\"\"\n",
    "\n",
    "    def forward(self, z: Tensor, edge_index: Tensor,\n",
    "                sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into edge probabilities for\n",
    "        the given node-pairs :obj:`edge_index`.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z: Tensor, sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    r\"\"\"The Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper based on user-defined encoder and decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\n",
    "        GAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        reset(self.encoder)\n",
    "        reset(self.decoder)\n",
    "\n",
    "    def forward(self, *args, **kwargs) -> Tensor:  # pragma: no cover\n",
    "        r\"\"\"Alias for :meth:`encode`.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the decoder and computes edge probabilities.\"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "\n",
    "    def recon_loss(self, z: Tensor, pos_edge_index: Tensor,\n",
    "                   neg_edge_index: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to train against.\n",
    "            neg_edge_index (torch.Tensor, optional): The negative edges to\n",
    "                train against. If not given, uses negative sampling to\n",
    "                calculate negative edges. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True)[0] + EPS).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 -\n",
    "                              self.decoder(z, neg_edge_index.long(), sigmoid=True)[0] +\n",
    "                              EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def test(self, z: Tensor, pos_edge_index: Tensor,\n",
    "             neg_edge_index: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"Given latent variables :obj:`z`, positive edges\n",
    "        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,\n",
    "        computes area under the ROC curve (AUC) and average precision (AP)\n",
    "        \n",
    "        scores.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to evaluate\n",
    "                against.\n",
    "            neg_edge_index (torch.Tensor): The negative edges to evaluate\n",
    "                against.\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n",
    "\n",
    "\n",
    "class VGAE(GAE):\n",
    "    r\"\"\"The Variational Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module to compute :math:`\\mu`\n",
    "            and :math:`\\log\\sigma^2`.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__(encoder, decoder)\n",
    "\n",
    "    def reparametrize(self, mu: Tensor, logstd: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        self.__mu__, self.__logstd__, self.edge_index = self.encoder(\n",
    "            *args, **kwargs)\n",
    "        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)\n",
    "        z = self.reparametrize(self.__mu__, self.__logstd__)\n",
    "        return z, self.edge_index\n",
    "\n",
    "    def kl_loss(self, mu: Optional[Tensor] = None,\n",
    "                logstd: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logstd`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor, optional): The latent space for :math:`\\mu`. If\n",
    "                set to :obj:`None`, uses the last computation of :math:`\\mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logstd (torch.Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logstd = self.__logstd__ if logstd is None else logstd.clamp(\n",
    "            max=MAX_LOGSTD)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_g(g):\n",
    "    degrees = torch.sum(g, 1)\n",
    "    g = g / degrees\n",
    "    return g\n",
    "\n",
    "\n",
    "def top_k_graph(scores, g, h, k):\n",
    "    num_nodes = g.shape[0]\n",
    "    values, idx = torch.topk(scores, max(2, int(k*num_nodes)))\n",
    "    new_h = h[idx, :]\n",
    "    values = torch.unsqueeze(values, -1)\n",
    "    new_h = torch.mul(new_h, values)\n",
    "    un_g = g.bool().float()\n",
    "    un_g = torch.matmul(un_g, un_g).bool().float()\n",
    "    un_g = un_g[idx, :]\n",
    "    un_g = un_g[:, idx]\n",
    "    g = norm_g(un_g)\n",
    "    return g, new_h, idx\n",
    "\n",
    "class Pool(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, k, in_dim, p):\n",
    "        super(Pool, self).__init__()\n",
    "        self.k = k\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.proj = torch.nn.Linear(in_dim, 1)\n",
    "        self.drop = torch.nn.Dropout(p=p) if p > 0 else torch.nn.Identity()\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        Z = self.drop(h)\n",
    "        weights = self.proj(Z).squeeze()\n",
    "        scores = self.sigmoid(weights)\n",
    "        return top_k_graph(scores, g, h, self.k)\n",
    "\n",
    "\n",
    "class Unpool(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        super(Unpool, self).__init__()\n",
    "\n",
    "    def forward(self, h, edge_indices,factor=1):\n",
    "        # add zeros to h factor times\n",
    "        global featureShape\n",
    "        h = torch.cat([h, torch.zeros(max(featureShape[0]- h.shape[0],0), h.shape[1]).to(h.device)], dim=0)\n",
    "        return h\n",
    "\n",
    "class Unpool2(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Unpool2, self).__init__()\n",
    "\n",
    "    def forward(self, batch, unpool_ratio):\n",
    "        num_nodes = batch[-1].item() + 1\n",
    "        expanded_batch = batch.unsqueeze(1).repeat(1, unpool_ratio)  # Repeat batch indices\n",
    "        expanded_batch = expanded_batch.view(-1)  # Flatten the batch indices\n",
    "        return  expanded_batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2*out_channels, 1 * out_channels)\n",
    "        self.conv_mu = GCNConv(1 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(1 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        global edgeShape, featureShape\n",
    "        # print(\"input:\",x.shape, edge_index.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv1:\",x.shape, edge_index.shape)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv2:\",x.shape, edge_index.shape)\n",
    "        \n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index), edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNDecoder(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, 1 * out_channels)\n",
    "    def forward(self, x, edge_index, sigmoid=True):\n",
    "        global edgeShape, featureShape\n",
    "        # print(\"input:\",x.shape, edge_index.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv1:\",x.shape, edge_index.shape)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv2:\",x.shape, edge_index.shape)\n",
    "        return x, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "in_channels = graphs[0].num_features\n",
    "out_channels = 2\n",
    "lr = 1e-4\n",
    "n_epochs = 100\n",
    "batch_size=2\n",
    "force_train=True\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(in_channels, out_channels),\n",
    "            VariationalGCNDecoder(out_channels, in_channels))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_loader = DataLoader(graphs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyEMD import EMD\n",
    "import emd\n",
    "emd=EMD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import _emd_ext._emd as emd\n",
    "\n",
    "\n",
    "class EMDFunction(torch.autograd.Function):\n",
    "\t@staticmethod\n",
    "\tdef forward(self, xyz1, xyz2):\n",
    "\t\tcost, match = emd.emd_forward(xyz1, xyz2)\n",
    "\t\tself.save_for_backward(xyz1, xyz2, match)\n",
    "\t\treturn cost\n",
    "\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef backward(self, grad_output):\n",
    "\t\txyz1, xyz2, match = self.saved_tensors\n",
    "\t\tgrad_xyz1, grad_xyz2 = emd.emd_backward(xyz1, xyz2, match)\n",
    "\t\treturn grad_xyz1, grad_xyz2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EMDLoss(nn.Module):\n",
    "\t'''\n",
    "\tComputes the (approximate) Earth Mover's Distance between two point sets. \n",
    "\n",
    "\tIMPLEMENTATION LIMITATIONS:\n",
    "\t- Double tensors must have <=11 dimensions\n",
    "\t- Float tensors must have <=23 dimensions\n",
    "\tThis is due to the use of CUDA shared memory in the computation. This shared memory is limited by the hardware to 48kB.\n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EMDLoss, self).__init__()\n",
    "\n",
    "\tdef forward(self, xyz1, xyz2):\n",
    "\n",
    "\t\tassert xyz1.shape[-1] == xyz2.shape[-1], 'Both point sets must have the same dimensionality'\n",
    "\t\tif xyz1.dtype == torch.float64 and xyz1.shape[-1] > 11:\n",
    "\t\t\terror('Tensors of type double can have a maximum of 11 dimensions')\n",
    "\t\tif xyz1.dtype == torch.float32 and xyz1.shape[-1] > 23:\n",
    "\t\t\terror('Tensors of type float can have a maximum of 23 dimensions')\n",
    "\n",
    "\t\treturn EMDFunction.apply(xyz1, xyz2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist=EMDLoss()\n",
    "p1 = torch.rand(1,5,3).cuda().double()\n",
    "p2 = torch.rand(1,10,3).cuda().double()\n",
    "p1.requires_grad = True\n",
    "p2.requires_grad = True\n",
    "\n",
    "cost = dist(p1, p2)\n",
    "\n",
    "\n",
    "print(cost)\n",
    "loss = torch.sum(cost)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(p1.grad)\n",
    "print(p2.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_set = DataLoader(graphs[:int(n_frames*0.6)], batch_size=batch_size, shuffle=True)\n",
    "validation_loader_set = DataLoader(graphs[int(n_frames*0.6):int(n_frames*0.8)], batch_size=batch_size, shuffle=True)\n",
    "test_loader_set = DataLoader(graphs[int(n_frames*0.8):], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    model.float()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    kl_loss_all = 0\n",
    "\n",
    "    for data in train_loader_set:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        FeatureLoss = lossFxn(decoded_x, data.x)\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        loss = FeatureLoss + EdgeLoss\n",
    "        loss = loss \n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        kl_loss_all += float(model.kl_loss()/data.num_nodes)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    return loss_all / len(train_loader_set.dataset), feature_loss_all / len(train_loader_set.dataset), edge_loss_all / len(train_loader_set.dataset), kl_loss_all / len(train_loader_set.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "    model.float()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    kl_loss_all = 0\n",
    "    type_loss_all = 0\n",
    "\n",
    "    for data in test_loader_set:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index= model.decode(z, encoded_edge_index)\n",
    "        FeatureLoss = lossFxn(decoded_x, data.x)\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        loss = FeatureLoss + EdgeLoss \n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        \n",
    "\n",
    "    return loss_all / len(test_loader_set), feature_loss_all / len(test_loader_set), edge_loss_all / len(test_loader_set), kl_loss_all / len(test_loader_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def validate():\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "    model.float()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    kl_loss_all = 0\n",
    "    type_loss_all = 0\n",
    "\n",
    "    for data in validation_loader_set:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index= model.decode(z, encoded_edge_index)\n",
    "        \n",
    "        FeatureLoss = lossFxn(decoded_x, data.x)\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        loss = FeatureLoss + EdgeLoss \n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        \n",
    "\n",
    "    return loss_all / len(validation_loader_set), feature_loss_all / len(validation_loader_set), edge_loss_all / len(validation_loader_set), kl_loss_all / len(validation_loader_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = []\n",
    "feature_losses = []\n",
    "edge_losses = []\n",
    "kl_losses = []\n",
    "val_total_losses = []\n",
    "val_feature_losses = []\n",
    "val_edge_losses = []\n",
    "val_kl_losses = []\n",
    "test_total_losses = []\n",
    "test_feature_losses = []\n",
    "test_edge_losses = []\n",
    "test_kl_losses = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    total_loss, feature_loss, edge_loss, kl_loss = train()\n",
    "    val_total_loss, val_feature_loss, val_edge_loss, val_kl_loss = validate()\n",
    "    test_total_loss, test_feature_loss, test_edge_loss, test_kl_loss = test()\n",
    "    print(f'Epoch: {epoch:03d}')\n",
    "    print(f'TRAIN : Total Loss: {total_loss:.4f}, Feature Loss: {feature_loss:.4f}, Edge Loss: {edge_loss:.4f}')\n",
    "    print(f'VALIDATE : Total Loss: {val_total_loss:.4f}, Feature Loss: {val_feature_loss:.4f}, Edge Loss: {val_edge_loss:.4f}')\n",
    "    print(f'TEST : Total Loss: {test_total_loss:.4f}, Feature Loss: {test_feature_loss:.4f}, Edge Loss: {test_edge_loss:.4f}')\n",
    "    total_losses.append(total_loss)\n",
    "    feature_losses.append(feature_loss)\n",
    "    edge_losses.append(edge_loss)\n",
    "    kl_losses.append(kl_loss)\n",
    "    val_total_losses.append(val_total_loss)\n",
    "    val_feature_losses.append(val_feature_loss)\n",
    "    val_edge_losses.append(val_edge_loss)\n",
    "    val_kl_losses.append(val_kl_loss)\n",
    "    test_total_losses.append(test_total_loss)\n",
    "    test_feature_losses.append(test_feature_loss)\n",
    "    test_edge_losses.append(test_edge_loss)\n",
    "    test_kl_losses.append(test_kl_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(total_losses, label='Total Loss')\n",
    "plt.legend()\n",
    "plt.title('Total Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(feature_losses, label='Feature Loss')\n",
    "plt.legend()\n",
    "plt.title('Feature Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(total_losses, label='train Loss')\n",
    "plt.plot(test_total_losses, label='test loss')\n",
    "plt.plot(val_total_losses, label='validate loss')\n",
    "plt.legend()\n",
    "plt.title('Total Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(feature_losses, label='Feature Loss')\n",
    "plt.legend()\n",
    "plt.title('Feature Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(graphs, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data=[]\n",
    "for data in train_loader:\n",
    "    model.eval()\n",
    "    z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "    decoded_data.append(z.detach().numpy())\n",
    "\n",
    "decoded_data = np.array(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 49\n",
    "plt.figure(figsize=(14, 5))\n",
    "data = decoded_data[frame]\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f9761786ac07e4eab4386916b2ac1a9951f01c213aa09aceac38efe2713e05d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
