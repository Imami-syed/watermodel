{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a71847310b4b2380045e08fc3a6c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frames=md.load_xtc(\"./singlesim/it50k/eql2.xtc\",top=\"./singlesim/it50k/conf.gro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc6a0d0dbad4b89aa871efb46fb98a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing the molecule\n",
    "molecule = frames[0]\n",
    "atomic_numbers = [atom.element.atomic_number for atom in molecule.top.atoms]\n",
    "water = Atoms(positions=molecule.xyz[0], numbers=atomic_numbers)\n",
    "show_ase(water)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate3D(features,psi,theta,phi):\n",
    "    xyz = features[:,:3]\n",
    "    rest = features[:,3:]\n",
    "    matrix = np.array([[np.cos(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.sin(psi),np.cos(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.sin(psi),np.sin(psi)*np.sin(theta)],\n",
    "                          [-np.sin(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.cos(psi),-np.sin(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.cos(psi),np.cos(psi)*np.sin(theta)],\n",
    "                            [np.sin(theta)*np.sin(phi),-np.sin(theta)*np.cos(phi),np.cos(theta)]])\n",
    "    return np.concatenate((np.dot(xyz,matrix) *10 , rest),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:02<00:00, 18388.01it/s]\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for molecule in tqdm(frames):\n",
    "    atomic_numbers = np.array([[atom.element.atomic_number for atom in molecule.top.atoms]]).T\n",
    "    vdwr = np.array([[atom.element.radius for atom in molecule.top.atoms]]).T\n",
    "    mass = np.array([[atom.element.mass for atom in molecule.top.atoms]]).T\n",
    "    positions = molecule.xyz[0]*10\n",
    "    \n",
    "    positions = positions - positions[0]\n",
    "    \n",
    "    node_features = np.concatenate((positions,vdwr,atomic_numbers),axis=1)\n",
    "    features.append(node_features)\n",
    "    \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features:\n",
      " [[ 0.          0.          0.          0.152       8.        ]\n",
      " [ 0.928936   -0.22790241  0.03701782  0.12        1.        ]\n",
      " [-0.43196297 -0.800951   -0.29684734  0.12        1.        ]\n",
      " [ 0.05301476 -0.10975456 -0.02771759  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Node Features:\\n\",features[50000])\n",
    "# positions , vdwr , atomic_numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edge list\n",
    "from_list = []\n",
    "\n",
    "to_list = []\n",
    "for edge in frames.topology.bonds:\n",
    "    from_list.append(edge.atom1.index)\n",
    "    to_list.append(edge.atom2.index)\n",
    "    from_list.append(edge.atom2.index)\n",
    "    to_list.append(edge.atom1.index)\n",
    "\n",
    "edge_list = np.array([from_list,to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 2],\n",
       "       [1, 0, 2, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adj(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max() + 1\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    return adj\n",
    "\n",
    "def convert_to_edge_index(adj):\n",
    "    edge_index = adj.nonzero().t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 58681.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for node_feature in tqdm(features):\n",
    "    graph = data.Data(x=torch.from_numpy(node_feature),edge_index=torch.from_numpy(edge_list))\n",
    "    graphs.append(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 5], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0])\n",
    "# 4 atoms with 5 features each and 4 edges with 2 features each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis = to_networkx(graphs[0])\n",
    "nx.draw_networkx(vis, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 170465.46it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graphs_device = []\n",
    "for graph in tqdm(graphs):\n",
    "    graphs_device.append(graph.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "in_channels = graph.num_features\n",
    "out_channels = 3\n",
    "n_atoms = 20\n",
    "lr = 1e-3\n",
    "n_epochs = 500\n",
    "batch_size=256\n",
    "test_train_split = 0.8\n",
    "model_name = \"IntraGVAE_l3_final.pt\"\n",
    "model_loaded = False\n",
    "force_train = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if os.path.exists(\"./models/\"+model_name) and not force_train:\n",
    "    model = torch.load(\"./models/\"+model_name)\n",
    "    model_loaded = True\n",
    "else:\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels,batch_size,n_atoms),\n",
    "                VariationalGCNDecoder(out_channels, in_channels,batch_size,n_atoms))\n",
    "    \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(test_train_split * len(graphs_device))\n",
    "train_loader = DataLoader(graphs_device[:split], batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(graphs_device[split:], batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n",
      "total_graphs: 50001\n",
      "Graphs in a batch: 256\n",
      "Train Graphs Batches: 157 (Total graphs: 40192)\n",
      "Test Graphs Batches: 40 (Total graphs: 10240)\n",
      "Model Specifics:\n",
      " VGAE(\n",
      "  (encoder): VariationalGCNEncoder(\n",
      "    (conv1): GATConv(5, 15, heads=3)\n",
      "    (head_transform1): Linear(45, 15, bias=True)\n",
      "    (bn1): BatchNorm(15)\n",
      "    (conv2): GCNConv(15, 9)\n",
      "    (bn2): BatchNorm(9)\n",
      "    (linear1): Linear(9, 100, bias=True)\n",
      "    (linear2): Linear(100, 4, bias=True)\n",
      "    (transform): Linear(80, 3, bias=True)\n",
      "    (mu): Linear(3, 3, bias=True)\n",
      "    (logstd): Linear(3, 3, bias=True)\n",
      "  )\n",
      "  (decoder): VariationalGCNDecoder(\n",
      "    (inv_transform): Linear(3, 20, bias=True)\n",
      "    (conv1): GCNConv(1, 9)\n",
      "    (bn1): BatchNorm(9)\n",
      "    (conv2): GCNConv(9, 3)\n",
      "    (bn2): BatchNorm(3)\n",
      "    (conv3): GCNConv(3, 3)\n",
      "    (linear1): Linear(3, 512, bias=True)\n",
      "    (linear2): Linear(512, 128, bias=True)\n",
      "    (linear3): Linear(128, 5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Using:\",device )\n",
    "print(\"total_graphs:\", len(graphs_device))\n",
    "print(\"Graphs in a batch:\", batch_size)\n",
    "print(\"Train Graphs Batches:\",len(train_loader),f\"(Total graphs: {len(train_loader)*batch_size})\")\n",
    "print(\"Test Graphs Batches:\",len(test_loader),f\"(Total graphs: {len(test_loader)*batch_size})\")\n",
    "print(\"Model Specifics:\\n\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    model.double()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "     \n",
    "        \n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "\n",
    "\n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "\n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "#         positionLoss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / len(train_loader), feature_loss_all / len(train_loader), edge_loss_all / len(train_loader) ,position_loss_all / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.double()\n",
    "    \n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "        \n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "   \n",
    "        \n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        \n",
    "        \n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "\n",
    "\n",
    "    return loss_all / len(test_loader), feature_loss_all / len(test_loader), edge_loss_all / len(test_loader), position_loss_all / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[51, 20, -1]' is invalid for input of size 4096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/imami/watermodel/10_7/intra.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         train_total_loss, train_feature_loss, train_edge_loss,train_position_loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         test_total_loss, test_feature_loss, test_edge_loss,test_position_loss \u001b[39m=\u001b[39m test()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/imami/watermodel/10_7/intra.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     z,encoded_edge_index \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     decoded_x, decoded_edge_index \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(z, encoded_edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/intra.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     heavy_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(data\u001b[39m.\u001b[39mx[:,\u001b[39m4\u001b[39m] \u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/watermodel/10_7/model.py:191\u001b[0m, in \u001b[0;36mVGAE.encode\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    190\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__mu__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    192\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__\u001b[39m.\u001b[39mclamp(\u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mMAX_LOGSTD)\n\u001b[1;32m    194\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparametrize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__mu__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__)\n",
      "File \u001b[0;32m~/anaconda3/envs/3dpytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/watermodel/10_7/model.py:260\u001b[0m, in \u001b[0;36mVariationalGCNEncoder.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    258\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(x)\n\u001b[1;32m    259\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(x)\n\u001b[0;32m--> 260\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mreshape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_atoms,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    261\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    263\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[51, 20, -1]' is invalid for input of size 4096"
     ]
    }
   ],
   "source": [
    "train_total_losses = []\n",
    "train_feature_losses = []\n",
    "train_edge_losses = []\n",
    "train_position_losses = []\n",
    "\n",
    "test_total_losses = []\n",
    "test_feature_losses = []\n",
    "test_edge_losses = []\n",
    "test_position_losses = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "\n",
    "\n",
    "if model_loaded:        \n",
    "    print(\"Pretrained Model Loaded, no training required\")\n",
    "else:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_total_loss, train_feature_loss, train_edge_loss,train_position_loss = train()\n",
    "        test_total_loss, test_feature_loss, test_edge_loss,test_position_loss = test()\n",
    "        \n",
    "        print(f\"Epoch: {epoch:03d}\")\n",
    "        print(f'\\tTrain:\\tTotal Loss: {train_total_loss:.4f}, Feature Loss: {train_feature_loss:.4f}, Position Loss: {train_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        print(f'\\tTest: \\tTotal Loss: {test_total_loss:.4f}, Feature Loss: {test_feature_loss:.4f}, Position Loss: {test_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        \n",
    "        if(early_stopper.early_stop(test_total_loss)):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "\n",
    "        train_total_losses.append(train_total_loss)\n",
    "        train_feature_losses.append(train_feature_loss)\n",
    "        train_edge_losses.append(train_edge_loss)\n",
    "        train_position_losses.append(train_position_loss)\n",
    "\n",
    "        test_total_losses.append(test_total_loss)\n",
    "        test_feature_losses.append(test_feature_loss)\n",
    "        test_edge_losses.append(test_edge_loss)\n",
    "        test_position_losses.append(test_position_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model,\"./models/\"+model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
