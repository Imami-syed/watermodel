{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aa1bc418e44415ab4a82917768ccd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frames=md.load_xtc(\"./singlesim/it50k/eql2.xtc\",top=\"./singlesim/it50k/conf.gro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbfa8b9c55d41f6b991e45e5c107dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing the molecule\n",
    "molecule = frames[0]\n",
    "atomic_numbers = [atom.element.atomic_number for atom in molecule.top.atoms]\n",
    "water = Atoms(positions=molecule.xyz[0], numbers=atomic_numbers)\n",
    "show_ase(water)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate3D(features,psi,theta,phi):\n",
    "    xyz = features[:,:3]\n",
    "    rest = features[:,3:]\n",
    "    matrix = np.array([[np.cos(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.sin(psi),np.cos(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.sin(psi),np.sin(psi)*np.sin(theta)],\n",
    "                          [-np.sin(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.cos(psi),-np.sin(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.cos(psi),np.cos(psi)*np.sin(theta)],\n",
    "                            [np.sin(theta)*np.sin(phi),-np.sin(theta)*np.cos(phi),np.cos(theta)]])\n",
    "    return np.concatenate((np.dot(xyz,matrix) *10 , rest),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:01<00:00, 43129.91it/s]\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for molecule in tqdm(frames):\n",
    "    atomic_numbers = np.array([[atom.element.atomic_number for atom in molecule.top.atoms]]).T\n",
    "    vdwr = np.array([[atom.element.radius for atom in molecule.top.atoms]]).T\n",
    "    mass = np.array([[atom.element.mass for atom in molecule.top.atoms]]).T\n",
    "    positions = molecule.xyz[0]*10\n",
    "    \n",
    "    positions = positions - positions[0]\n",
    "    \n",
    "    node_features = np.concatenate((positions,vdwr,atomic_numbers),axis=1)\n",
    "    features.append(node_features)\n",
    "    \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features:\n",
      " [[ 0.          0.          0.          0.152       8.        ]\n",
      " [ 0.928936   -0.22790241  0.03701782  0.12        1.        ]\n",
      " [-0.43196297 -0.800951   -0.29684734  0.12        1.        ]\n",
      " [ 0.05301476 -0.10975456 -0.02771759  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Node Features:\\n\",features[50000])\n",
    "# positions , vdwr , atomic_numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edge list\n",
    "from_list = []\n",
    "\n",
    "to_list = []\n",
    "for edge in frames.topology.bonds:\n",
    "    from_list.append(edge.atom1.index)\n",
    "    to_list.append(edge.atom2.index)\n",
    "    from_list.append(edge.atom2.index)\n",
    "    to_list.append(edge.atom1.index)\n",
    "\n",
    "edge_list = np.array([from_list,to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 2],\n",
       "       [1, 0, 2, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adj(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max() + 1\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    return adj\n",
    "\n",
    "def convert_to_edge_index(adj):\n",
    "    edge_index = adj.nonzero().t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 68871.19it/s]\n"
     ]
    }
   ],
   "source": [
    "for node_feature in tqdm(features):\n",
    "    graph = data.Data(x=torch.from_numpy(node_feature),edge_index=torch.from_numpy(edge_list))\n",
    "    graphs.append(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 5], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0])\n",
    "# 4 atoms with 5 features each and 4 edges with 2 features each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis = to_networkx(graphs[0])\n",
    "nx.draw_networkx(vis, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 216435.61it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graphs_device = []\n",
    "for graph in tqdm(graphs):\n",
    "    graphs_device.append(graph.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "in_channels = graph.num_features\n",
    "out_channels = 3\n",
    "n_atoms = 4\n",
    "lr = 1e-3\n",
    "n_epochs = 500\n",
    "batch_size=256\n",
    "test_train_split = 0.8\n",
    "model_name = \"IntraGVAE_l3_final.pt\"\n",
    "model_loaded = False\n",
    "force_train = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if os.path.exists(\"./models/\"+model_name) and not force_train:\n",
    "    model = torch.load(\"./models/\"+model_name)\n",
    "    model_loaded = True\n",
    "else:\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels,batch_size,n_atoms),\n",
    "                VariationalGCNDecoder(out_channels, in_channels,batch_size,n_atoms))\n",
    "    \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(test_train_split * len(graphs_device))\n",
    "train_loader = DataLoader(graphs_device[:split], batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(graphs_device[split:], batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n",
      "total_graphs: 50001\n",
      "Graphs in a batch: 256\n",
      "Train Graphs Batches: 157 (Total graphs: 40192)\n",
      "Test Graphs Batches: 40 (Total graphs: 10240)\n",
      "Model Specifics:\n",
      " VGAE(\n",
      "  (encoder): VariationalGCNEncoder(\n",
      "    (conv1): GATConv(5, 16, heads=3)\n",
      "    (head_transform1): Linear(48, 16, bias=True)\n",
      "    (bn1): BatchNorm(16)\n",
      "    (conv2): GCNConv(16, 8)\n",
      "    (bn2): BatchNorm(8)\n",
      "    (linear1): Linear(32, 32, bias=True)\n",
      "    (linear2): Linear(32, 16, bias=True)\n",
      "    (transform): Linear(16, 3, bias=True)\n",
      "    (mu): Linear(3, 3, bias=True)\n",
      "    (logstd): Linear(3, 3, bias=True)\n",
      "  )\n",
      "  (decoder): VariationalGCNDecoder(\n",
      "    (inv_transform): Linear(5, 16, bias=True)\n",
      "    (conv1): GCNConv(16, 4)\n",
      "    (bn1): BatchNorm(4)\n",
      "    (conv2): GCNConv(4, 8)\n",
      "    (bn2): BatchNorm(8)\n",
      "    (conv3): GCNConv(8, 4)\n",
      "    (linear1): Linear(16, 32, bias=True)\n",
      "    (linear2): Linear(32, 16, bias=True)\n",
      "    (linear3): Linear(16, 5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Using:\",device )\n",
    "print(\"total_graphs:\", len(graphs_device))\n",
    "print(\"Graphs in a batch:\", batch_size)\n",
    "print(\"Train Graphs Batches:\",len(train_loader),f\"(Total graphs: {len(train_loader)*batch_size})\")\n",
    "print(\"Test Graphs Batches:\",len(test_loader),f\"(Total graphs: {len(test_loader)*batch_size})\")\n",
    "print(\"Model Specifics:\\n\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    model.double()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "     \n",
    "        \n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "\n",
    "\n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "\n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "#         positionLoss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / len(train_loader), feature_loss_all / len(train_loader), edge_loss_all / len(train_loader) ,position_loss_all / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.double()\n",
    "    \n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "        \n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "   \n",
    "        \n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        \n",
    "        \n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "\n",
    "\n",
    "    return loss_all / len(test_loader), feature_loss_all / len(test_loader), edge_loss_all / len(test_loader), position_loss_all / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.DoubleTensor' as child module 'conv1' (torch.nn.Module or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/imami/watermodel/10_7/try.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         train_total_loss, train_feature_loss, train_edge_loss,train_position_loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         test_total_loss, test_feature_loss, test_edge_loss,test_position_loss \u001b[39m=\u001b[39m test()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/imami/watermodel/10_7/try.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     z,encoded_edge_index \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     decoded_x, decoded_edge_index \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(z, encoded_edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/imami/watermodel/10_7/try.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     heavy_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(data\u001b[39m.\u001b[39mx[:,\u001b[39m4\u001b[39m] \u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/watermodel/10_7/model2.py:188\u001b[0m, in \u001b[0;36mVGAE.encode\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    187\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__mu__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    189\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    190\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__\u001b[39m.\u001b[39mclamp(\u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mMAX_LOGSTD)\n\u001b[1;32m    191\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparametrize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__mu__, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__logstd__)\n",
      "File \u001b[0;32m~/anaconda3/envs/3dpytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/watermodel/10_7/model2.py:255\u001b[0m, in \u001b[0;36mVariationalGCNEncoder.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):       \n\u001b[1;32m    254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 255\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index)\n\u001b[1;32m    256\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_transform1(x)\n\u001b[1;32m    257\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x) \n",
      "File \u001b[0;32m~/anaconda3/envs/3dpytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1653\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[39melif\u001b[39;00m modules \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1652\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1653\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot assign \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m as child module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1654\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m(torch.nn.Module or None expected)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1655\u001b[0m                         \u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mtypename(value), name))\n\u001b[1;32m   1656\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m _global_module_registration_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m   1657\u001b[0m         output \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, name, value)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'torch.DoubleTensor' as child module 'conv1' (torch.nn.Module or None expected)"
     ]
    }
   ],
   "source": [
    "train_total_losses = []\n",
    "train_feature_losses = []\n",
    "train_edge_losses = []\n",
    "train_position_losses = []\n",
    "\n",
    "test_total_losses = []\n",
    "test_feature_losses = []\n",
    "test_edge_losses = []\n",
    "test_position_losses = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "\n",
    "\n",
    "if model_loaded:        \n",
    "    print(\"Pretrained Model Loaded, no training required\")\n",
    "else:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_total_loss, train_feature_loss, train_edge_loss,train_position_loss = train()\n",
    "        test_total_loss, test_feature_loss, test_edge_loss,test_position_loss = test()\n",
    "        \n",
    "        print(f\"Epoch: {epoch:03d}\")\n",
    "        print(f'\\tTrain:\\tTotal Loss: {train_total_loss:.4f}, Feature Loss: {train_feature_loss:.4f}, Position Loss: {train_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        print(f'\\tTest: \\tTotal Loss: {test_total_loss:.4f}, Feature Loss: {test_feature_loss:.4f}, Position Loss: {test_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        \n",
    "        if(early_stopper.early_stop(test_total_loss)):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "\n",
    "        train_total_losses.append(train_total_loss)\n",
    "        train_feature_losses.append(train_feature_loss)\n",
    "        train_edge_losses.append(train_edge_loss)\n",
    "        train_position_losses.append(train_position_loss)\n",
    "\n",
    "        test_total_losses.append(test_total_loss)\n",
    "        test_feature_losses.append(test_feature_loss)\n",
    "        test_edge_losses.append(test_edge_loss)\n",
    "        test_position_losses.append(test_position_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model,\"./models/\"+model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
