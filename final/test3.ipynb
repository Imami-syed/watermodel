{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z6q45sKwPSUb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694480e4fc48448ea44e86c73b0f34e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mdtraj as md \n",
    "from ase import Atoms\n",
    "from nglview import show_ase\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import  GCNConv,BatchNorm,GATConv,Linear\n",
    "import torch_geometric.data as data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center the molecule at com           -> Done\n",
    "# train on actual positions            -> loss not decreasing beyond 9\n",
    "# loss focus more on heavy atoms       -> Done\n",
    "# ignore H\n",
    "# change latent space and check which is good dimension -> tried for 2,3,4 all losses are converging to 9..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the edge index to be learned in eoncoder\n",
    "# try EGNN models \n",
    "# input graph have equiverent properties\n",
    "# rotationally equivarient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LGVGTD4dPaQG"
   },
   "outputs": [],
   "source": [
    "# load water mol \n",
    "all_frames = md.load_xtc(\"../10_7/singlesim/it50k/eql2.xtc\",top=\"../10_7/singlesim/it50k/conf.gro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317,
     "referenced_widgets": [
      "b3e2e11d45734b7d9224fb987459470b",
      "83451c0f082c4aa888b1dd14e9c775bf",
      "174bcfbaa57647a791816ea2f5f95aba",
      "1dbdb82571c54cdd93dc2852bfff8d40",
      "8cb134fe0b18494bbefe6c95adc7d14e",
      "65d323feef3b4d44a7846a7c208946f1",
      "1ccf61fe60854532adca37efa0ce3d8c",
      "e8f4eabea82a4f928fa75a55769ed112",
      "51f160dd2cbe413ca4340f08c1c556c6",
      "f25cd88e94d7471fba0524c195300dbd",
      "f7e90ca6eca44a02aa7dbd7c721963d2",
      "d0b06dda6324492e96af92e3aeea444b",
      "c842ad6e08ac425eade8ae91843af6cf"
     ]
    },
    "id": "LfhgrqRRuEAv",
    "outputId": "82b81f8f-849f-4a0e-e6ef-549b93adb26c"
   },
   "outputs": [],
   "source": [
    "molecule = all_frames[0]\n",
    "atomic_nums = [atom.element.atomic_number for atom in molecule.top.atoms] \n",
    "water = Atoms(positions= molecule.xyz[0], numbers=atomic_nums)\n",
    "# show_ase(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate3D(features,psi,theta,phi):\n",
    "    xyz = features[:,:3]\n",
    "    rest = features[:,3:]\n",
    "    matrix = np.array([[np.cos(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.sin(psi),np.cos(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.sin(psi),np.sin(psi)*np.sin(theta)],\n",
    "                          [-np.sin(psi)*np.cos(phi)-np.cos(theta)*np.sin(phi)*np.cos(psi),-np.sin(psi)*np.sin(phi)+np.cos(theta)*np.cos(phi)*np.cos(psi),np.cos(psi)*np.sin(theta)],\n",
    "                            [np.sin(theta)*np.sin(phi),-np.sin(theta)*np.cos(phi),np.cos(theta)]])\n",
    "    return np.concatenate((np.dot(xyz,matrix) *10 , rest),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:01<00:00, 29593.09it/s]\n"
     ]
    }
   ],
   "source": [
    "frames = all_frames\n",
    "features = []\n",
    "for molecule in tqdm(frames):\n",
    "    atomic_nums = np.array([[atom.element.atomic_number for atom in molecule.top.atoms]]).T\n",
    "    vdwr = np.array([[atom.element.radius for atom in molecule.top.atoms]]).T\n",
    "    mass = np.array([[atom.element.mass for atom in molecule.top.atoms]]).T\n",
    "    positions = molecule.xyz[0]\n",
    "    \n",
    "    # positions = positions - positions[0]\n",
    "    \n",
    "    node_features = np.concatenate((positions,vdwr,atomic_nums),axis=1)\n",
    "    features.append(node_features)\n",
    "    \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfFrEF-W5vpx",
    "outputId": "4187ae4a-503a-4cef-ccc1-b5e557719f05"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # atomic Number\n",
    "# atomic_nums = np.array([[atom.element.atomic_number for atom in molecule.top.atoms]]).T\n",
    "\n",
    "# # Vander wall Radii\n",
    "# vdwr = np.array([[atom.element.radius for atom in molecule.top.atoms]]).T\n",
    "\n",
    "# # Atomic Mass \n",
    "# mass = np.array([[atom.element.mass for atom in molecule.top.atoms]]).T\n",
    "\n",
    "# atom_type = np.array([[2,1,1,0]]).T\n",
    "\n",
    "# # Relative position of atoms on one molecule\n",
    "# poitions = molecule.xyz[0]*10\n",
    "# # calculate weighted average of the positions of the atoms in the molecule\n",
    "# com = np.average(poitions, axis=0, weights=mass.T[0])\n",
    "# # relative position of atoms in the molecule\n",
    "\n",
    "# relative_pos = poitions-com\n",
    "\n",
    "\n",
    "# print(\"Absolute positions:\\n\",poitions)\n",
    "# print(\"\\nRelative positions:\\n\",relative_pos)\n",
    "# print(\"\\natomic_numbers:\\n\",atomic_nums)\n",
    "# print(\"\\nVander wall Radii:\\n\", vdwr)\n",
    "# print(\"\\nAtomic Mass:\\n\",mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wsal5pY3rTDA",
    "outputId": "c52d834d-061e-4913-c825-e9ab07d2ecfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features:\n",
      " [[1.34608388 1.25728524 1.34837246 0.152      8.        ]\n",
      " [1.30402577 1.32220209 1.40475726 0.12       1.        ]\n",
      " [1.28402805 1.24392235 1.27672875 0.12       1.        ]\n",
      " [1.33497727 1.26278484 1.34674466 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# node_features = np.concatenate((relative_pos,vdwr,atomic_nums),axis=1)\n",
    "print(\"Node Features:\\n\",features[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VQ0Tk6jn_Eug"
   },
   "outputs": [],
   "source": [
    "from_list = []\n",
    "to_list = []\n",
    "for edge in all_frames.topology.bonds:\n",
    "    from_list.append(edge.atom1.index)\n",
    "    to_list.append(edge.atom2.index)\n",
    "    from_list.append(edge.atom2.index)\n",
    "    to_list.append(edge.atom1.index)\n",
    "\n",
    "edge_list = np.array([from_list,to_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adj(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max() + 1\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    return adj\n",
    "\n",
    "def convert_to_edge_index(adj):\n",
    "    edge_index = adj.nonzero().t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2e7qnLIQaisN"
   },
   "outputs": [],
   "source": [
    "graphs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:01<00:00, 40661.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for node_feature in tqdm(features):\n",
    "    graph = data.Data(x=torch.from_numpy(node_feature),edge_index=torch.from_numpy(edge_list))\n",
    "    graphs.append(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = []\n",
    "# real_node_features = []\n",
    "\n",
    "# for i in range(n_graphs):\n",
    "#     rotated = rotate3D(node_features,np.random.uniform(0,2*np.pi),np.random.uniform(0,2*np.pi),np.random.uniform(0,2*np.pi))\n",
    "#     noisy_node_features = rotated + np.random.normal(0,0.1,rotated.shape)\n",
    "\n",
    "#     all_features.append(noisy_node_features)\n",
    "#     real_node_features.append(rotated)\n",
    "\n",
    "# all_features = np.array(all_features)    \n",
    "# real_node_features = np.array(real_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed Scaling/normalization\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(all_features.reshape(-1,1))\n",
    "# normalized_node_features = scaler.transform(all_features.reshape(-1,1)).reshape(all_features.shape)\n",
    "\n",
    "# normalized_real_node_features = scaler.transform(real_node_features.reshape(-1,1)).reshape(real_node_features.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in zip(normalized_node_features,normalized_real_node_features):\n",
    "#     graph = data.Data(x=torch.from_numpy(x),edge_index=torch.from_numpy(edge_list),y=torch.from_numpy(y))\n",
    "#     graphs.append(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4, 5], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis = to_networkx(graphs[0])\n",
    "nx.draw_networkx(vis, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple \n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "EPS = 1e-15\n",
    "MAX_LOGSTD = 10\n",
    "\n",
    "\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    r\"\"\"The inner product decoder from the `\"Variational Graph Auto-Encoders\"\n",
    "    <https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})\n",
    "\n",
    "    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent\n",
    "    space produced by the encoder.\"\"\"\n",
    "\n",
    "    def forward(self, z: Tensor, edge_index: Tensor,\n",
    "                sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into edge probabilities for\n",
    "        the given node-pairs :obj:`edge_index`.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z: Tensor, sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    r\"\"\"The Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper based on user-defined encoder and decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\n",
    "        GAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        reset(self.encoder)\n",
    "        reset(self.decoder)\n",
    "\n",
    "    def forward(self, *args, **kwargs) -> Tensor:  # pragma: no cover\n",
    "        r\"\"\"Alias for :meth:`encode`.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the decoder and computes edge probabilities.\"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "\n",
    "    def recon_loss(self, z: Tensor, pos_edge_index: Tensor,\n",
    "                   neg_edge_index: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to train against.\n",
    "            neg_edge_index (torch.Tensor, optional): The negative edges to\n",
    "                train against. If not given, uses negative sampling to\n",
    "                calculate negative edges. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True)[0] + EPS).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 -\n",
    "                              self.decoder(z, neg_edge_index.long(), sigmoid=True)[0] +\n",
    "                              EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def test(self, z: Tensor, pos_edge_index: Tensor,\n",
    "             neg_edge_index: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"Given latent variables :obj:`z`, positive edges\n",
    "        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,\n",
    "        computes area under the ROC curve (AUC) and average precision (AP)\n",
    "        \n",
    "        scores.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to evaluate\n",
    "                against.\n",
    "            neg_edge_index (torch.Tensor): The negative edges to evaluate\n",
    "                against.\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n",
    "\n",
    "\n",
    "class VGAE(GAE):\n",
    "    r\"\"\"The Variational Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module to compute :math:`\\mu`\n",
    "            and :math:`\\log\\sigma^2`.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__(encoder, decoder)\n",
    "\n",
    "    def reparametrize(self, mu: Tensor, logstd: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        self.__mu__, self.__logstd__, self.edge_index = self.encoder(\n",
    "            *args, **kwargs)\n",
    "        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)\n",
    "        z = self.reparametrize(self.__mu__, self.__logstd__)\n",
    "        return z, self.edge_index\n",
    "\n",
    "    def kl_loss(self, mu: Optional[Tensor] = None,\n",
    "                logstd: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logstd`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor, optional): The latent space for :math:`\\mu`. If\n",
    "                set to :obj:`None`, uses the last computation of :math:`\\mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logstd (torch.Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logstd = self.__logstd__ if logstd is None else logstd.clamp(\n",
    "            max=MAX_LOGSTD)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [00:00<00:00, 148634.59it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graphs_device = []\n",
    "for graph in tqdm(graphs):\n",
    "    graphs_device.append(graph.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "K1H_72HfZhHF"
   },
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,batch_size,n_atoms):\n",
    "        \n",
    "        self.embedding_size1 = 15\n",
    "        self.embedding_size2 = 9\n",
    "        self.linear_size1 = 100\n",
    "        self.linear_size2 = 4\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.n_atoms = n_atoms\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(self.in_channels,self.embedding_size1,heads=3)\n",
    "        self.head_transform1 = Linear(self.embedding_size1*3, self.embedding_size1)\n",
    "        self.bn1 = BatchNorm(self.embedding_size1)\n",
    "        \n",
    "        self.conv2 = GCNConv(self.embedding_size1,self.embedding_size2)\n",
    "        self.bn2 = BatchNorm(self.embedding_size2)\n",
    "        \n",
    "        self.linear1 = Linear(self.embedding_size2, self.linear_size1)\n",
    "        self.linear2 = Linear(self.linear_size1,self.linear_size2)\n",
    "        \n",
    "        self.transform = Linear(self.linear_size2*self.n_atoms,self.out_channels)\n",
    "        \n",
    "        self.mu = Linear(self.out_channels, self.out_channels)\n",
    "        self.logstd = Linear(self.out_channels, self.out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        self.batch_size = x.shape[0]//self.n_atoms\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.head_transform1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = x.reshape(self.batch_size,self.n_atoms,-1)\n",
    "        x = x.reshape(self.batch_size,-1)\n",
    "        \n",
    "        x = self.transform(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        \n",
    "        x,y,z = self.mu(x), self.logstd(x), edge_index\n",
    "        return x,y,z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNDecoder(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,batch_size,n_atoms):\n",
    "        self.embedding_size1 = 9\n",
    "        self.embedding_size2 = 3\n",
    "        self.embedding_size3 = 3\n",
    "        self.linear_size1 = 512\n",
    "        self.linear_size2 = 128\n",
    "        self.batch_size = batch_size\n",
    "        self.n_atoms = n_atoms\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        super().__init__()\n",
    "        self.inv_transform = Linear(self.in_channels,self.n_atoms) \n",
    "        \n",
    "        self.conv1 = GCNConv(1, self.embedding_size1)\n",
    "        self.bn1 = BatchNorm(self.embedding_size1)\n",
    "\n",
    "        self.conv2 = GCNConv(self.embedding_size1,self.embedding_size2)\n",
    "        self.bn2 = BatchNorm(self.embedding_size2)\n",
    "\n",
    "        self.conv3 = GCNConv(self.embedding_size2,self.embedding_size3)\n",
    "\n",
    "        self.linear1 = Linear(self.embedding_size3, self.linear_size1)\n",
    "        self.linear2 = Linear(self.linear_size1, self.linear_size2)\n",
    "        self.linear3 = Linear(self.linear_size2, self.out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, sigmoid=True):\n",
    "        self.batch_size = x.shape[0]//self.n_atoms\n",
    "\n",
    "        x = self.inv_transform(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0]*x.shape[1],1)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)        \n",
    "        x = self.conv3(x,edge_index)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        \n",
    "        return x, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vu-V-Dsc1D_B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "in_channels = graph.num_features\n",
    "out_channels = 3\n",
    "n_atoms = 4\n",
    "lr = 1e-3\n",
    "n_epochs = 500\n",
    "batch_size=256\n",
    "test_train_split = 0.8\n",
    "model_name = \"IntraGVAE_l3_final.pt\"\n",
    "model_loaded = False\n",
    "force_train = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if os.path.exists(\"./models/\"+model_name) and not force_train:\n",
    "    model = torch.load(\"./models/\"+model_name)\n",
    "    model_loaded = True\n",
    "else:\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels,batch_size,n_atoms),\n",
    "                VariationalGCNDecoder(out_channels, in_channels,batch_size,n_atoms))\n",
    "    \n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hqwvxYdccl4g"
   },
   "outputs": [],
   "source": [
    "split = int(test_train_split * len(graphs_device))\n",
    "train_loader = DataLoader(graphs_device[:split], batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(graphs_device[split:], batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n",
      "total_graphs: 50001\n",
      "Graphs in a batch: 256\n",
      "Train Graphs Batches: 157 (Total graphs: 40192)\n",
      "Test Graphs Batches: 40 (Total graphs: 10240)\n",
      "Model Specifics:\n",
      " VGAE(\n",
      "  (encoder): VariationalGCNEncoder(\n",
      "    (conv1): GATConv(5, 15, heads=3)\n",
      "    (head_transform1): Linear(45, 15, bias=True)\n",
      "    (bn1): BatchNorm(15)\n",
      "    (conv2): GCNConv(15, 9)\n",
      "    (bn2): BatchNorm(9)\n",
      "    (linear1): Linear(9, 100, bias=True)\n",
      "    (linear2): Linear(100, 4, bias=True)\n",
      "    (transform): Linear(16, 3, bias=True)\n",
      "    (mu): Linear(3, 3, bias=True)\n",
      "    (logstd): Linear(3, 3, bias=True)\n",
      "  )\n",
      "  (decoder): VariationalGCNDecoder(\n",
      "    (inv_transform): Linear(3, 4, bias=True)\n",
      "    (conv1): GCNConv(1, 9)\n",
      "    (bn1): BatchNorm(9)\n",
      "    (conv2): GCNConv(9, 3)\n",
      "    (bn2): BatchNorm(3)\n",
      "    (conv3): GCNConv(3, 3)\n",
      "    (linear1): Linear(3, 512, bias=True)\n",
      "    (linear2): Linear(512, 128, bias=True)\n",
      "    (linear3): Linear(128, 5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Using:\",device )\n",
    "print(\"total_graphs:\", len(graphs_device))\n",
    "print(\"Graphs in a batch:\", batch_size)\n",
    "print(\"Train Graphs Batches:\",len(train_loader),f\"(Total graphs: {len(train_loader)*batch_size})\")\n",
    "print(\"Test Graphs Batches:\",len(test_loader),f\"(Total graphs: {len(test_loader)*batch_size})\")\n",
    "print(\"Model Specifics:\\n\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PSlEaKJOczEn"
   },
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    model.double()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "     \n",
    "        \n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "\n",
    "\n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "\n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "#         positionLoss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / len(train_loader), feature_loss_all / len(train_loader), edge_loss_all / len(train_loader) ,position_loss_all / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.double()\n",
    "    \n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    position_loss_all = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        decoded_pos = decoded_x[:,:3]\n",
    "        decoded_features = decoded_x[:,3:]\n",
    "        orignal_pos = data.x[:,:3]\n",
    "        orignal_features = data.x[:,3:]\n",
    "        \n",
    "        \n",
    "        heavy_indices = torch.where(data.x[:,4] > torch.tensor([1]).to(device))\n",
    "   \n",
    "        \n",
    "        positionLoss = lossFxn(decoded_pos[heavy_indices], orignal_pos[heavy_indices])\n",
    "        FeatureLoss = lossFxn(decoded_features[heavy_indices], orignal_features[heavy_indices])\n",
    "        loss = lossFxn(decoded_x[heavy_indices], data.x[heavy_indices])\n",
    "\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        \n",
    "        \n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        position_loss_all += float(positionLoss)\n",
    "\n",
    "\n",
    "\n",
    "    return loss_all / len(test_loader), feature_loss_all / len(test_loader), edge_loss_all / len(test_loader), position_loss_all / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9117KpSc9uP",
    "outputId": "eae0f70e-c05e-42fe-a20c-477e5cab54fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001\n",
      "\tTrain:\tTotal Loss: 0.8823, Feature Loss: 1.9845, Position Loss: 0.1475, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0236, Feature Loss: 0.0000, Position Loss: 0.0394, LR: 0.001000\n",
      "Epoch: 002\n",
      "\tTrain:\tTotal Loss: 0.0356, Feature Loss: 0.0001, Position Loss: 0.0592, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0245, Feature Loss: 0.0001, Position Loss: 0.0407, LR: 0.001000\n",
      "Epoch: 003\n",
      "\tTrain:\tTotal Loss: 0.0357, Feature Loss: 0.0000, Position Loss: 0.0595, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0247, Feature Loss: 0.0000, Position Loss: 0.0412, LR: 0.001000\n",
      "Epoch: 004\n",
      "\tTrain:\tTotal Loss: 0.0356, Feature Loss: 0.0000, Position Loss: 0.0594, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0237, Feature Loss: 0.0000, Position Loss: 0.0394, LR: 0.001000\n",
      "Epoch: 005\n",
      "\tTrain:\tTotal Loss: 0.0357, Feature Loss: 0.0000, Position Loss: 0.0595, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0239, Feature Loss: 0.0000, Position Loss: 0.0399, LR: 0.001000\n",
      "Epoch: 006\n",
      "\tTrain:\tTotal Loss: 0.0356, Feature Loss: 0.0000, Position Loss: 0.0594, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0247, Feature Loss: 0.0000, Position Loss: 0.0411, LR: 0.001000\n",
      "Epoch: 007\n",
      "\tTrain:\tTotal Loss: 0.0357, Feature Loss: 0.0000, Position Loss: 0.0595, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0236, Feature Loss: 0.0000, Position Loss: 0.0394, LR: 0.001000\n",
      "Epoch: 008\n",
      "\tTrain:\tTotal Loss: 0.0358, Feature Loss: 0.0000, Position Loss: 0.0596, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0246, Feature Loss: 0.0000, Position Loss: 0.0410, LR: 0.001000\n",
      "Epoch: 009\n",
      "\tTrain:\tTotal Loss: 0.0356, Feature Loss: 0.0000, Position Loss: 0.0594, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0240, Feature Loss: 0.0001, Position Loss: 0.0400, LR: 0.001000\n",
      "Epoch: 010\n",
      "\tTrain:\tTotal Loss: 0.0357, Feature Loss: 0.0000, Position Loss: 0.0595, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0239, Feature Loss: 0.0000, Position Loss: 0.0398, LR: 0.001000\n",
      "Epoch: 011\n",
      "\tTrain:\tTotal Loss: 0.0358, Feature Loss: 0.0000, Position Loss: 0.0596, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0243, Feature Loss: 0.0000, Position Loss: 0.0404, LR: 0.001000\n",
      "Epoch: 012\n",
      "\tTrain:\tTotal Loss: 0.0358, Feature Loss: 0.0000, Position Loss: 0.0596, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0237, Feature Loss: 0.0000, Position Loss: 0.0395, LR: 0.001000\n",
      "Epoch: 013\n",
      "\tTrain:\tTotal Loss: 0.0360, Feature Loss: 0.0001, Position Loss: 0.0600, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0238, Feature Loss: 0.0000, Position Loss: 0.0397, LR: 0.001000\n",
      "Epoch: 014\n",
      "\tTrain:\tTotal Loss: 0.0358, Feature Loss: 0.0001, Position Loss: 0.0597, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0236, Feature Loss: 0.0001, Position Loss: 0.0392, LR: 0.001000\n",
      "Epoch: 015\n",
      "\tTrain:\tTotal Loss: 0.0359, Feature Loss: 0.0001, Position Loss: 0.0597, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0254, Feature Loss: 0.0004, Position Loss: 0.0420, LR: 0.001000\n",
      "Epoch: 016\n",
      "\tTrain:\tTotal Loss: 0.0027, Feature Loss: 0.0014, Position Loss: 0.0036, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0028, Position Loss: 0.0019, LR: 0.001000\n",
      "Epoch: 017\n",
      "\tTrain:\tTotal Loss: 0.0012, Feature Loss: 0.0008, Position Loss: 0.0015, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0002, Position Loss: 0.0038, LR: 0.001000\n",
      "Epoch: 018\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0006, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0030, Feature Loss: 0.0000, Position Loss: 0.0051, LR: 0.001000\n",
      "Epoch: 019\n",
      "\tTrain:\tTotal Loss: 0.0010, Feature Loss: 0.0008, Position Loss: 0.0012, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 020\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0009, Feature Loss: 0.0000, Position Loss: 0.0015, LR: 0.001000\n",
      "Epoch: 021\n",
      "\tTrain:\tTotal Loss: 0.0010, Feature Loss: 0.0009, Position Loss: 0.0011, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0007, Position Loss: 0.0030, LR: 0.001000\n",
      "Epoch: 022\n",
      "\tTrain:\tTotal Loss: 0.0010, Feature Loss: 0.0007, Position Loss: 0.0012, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0011, Feature Loss: 0.0005, Position Loss: 0.0015, LR: 0.001000\n",
      "Epoch: 023\n",
      "\tTrain:\tTotal Loss: 0.0011, Feature Loss: 0.0009, Position Loss: 0.0012, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 024\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0040, Feature Loss: 0.0004, Position Loss: 0.0064, LR: 0.001000\n",
      "Epoch: 025\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0005, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 026\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0005, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0013, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 027\n",
      "\tTrain:\tTotal Loss: 0.0009, Feature Loss: 0.0006, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0001, Position Loss: 0.0039, LR: 0.001000\n",
      "Epoch: 028\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0005, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0000, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 029\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0006, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0011, Feature Loss: 0.0003, Position Loss: 0.0017, LR: 0.001000\n",
      "Epoch: 030\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0005, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.001000\n",
      "Epoch: 031\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0002, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0001, Position Loss: 0.0017, LR: 0.001000\n",
      "Epoch: 032\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0026, LR: 0.001000\n",
      "Epoch: 033\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0000, Position Loss: 0.0008, LR: 0.001000\n",
      "Epoch: 034\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0006, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0037, Feature Loss: 0.0000, Position Loss: 0.0061, LR: 0.001000\n",
      "Epoch: 035\n",
      "\tTrain:\tTotal Loss: 0.0009, Feature Loss: 0.0005, Position Loss: 0.0011, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0009, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 036\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 037\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0003, Position Loss: 0.0011, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0001, Position Loss: 0.0016, LR: 0.001000\n",
      "Epoch: 038\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0003, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0000, Position Loss: 0.0022, LR: 0.001000\n",
      "Epoch: 039\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0004, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 040\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0003, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0038, Feature Loss: 0.0008, Position Loss: 0.0058, LR: 0.001000\n",
      "Epoch: 041\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0001, Position Loss: 0.0028, LR: 0.001000\n",
      "Epoch: 042\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 043\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0001, Position Loss: 0.0011, LR: 0.001000\n",
      "Epoch: 044\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 045\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 046\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0011, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 047\n",
      "\tTrain:\tTotal Loss: 0.0009, Feature Loss: 0.0006, Position Loss: 0.0012, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0000, Position Loss: 0.0029, LR: 0.001000\n",
      "Epoch: 048\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0005, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0012, Position Loss: 0.0013, LR: 0.001000\n",
      "Epoch: 049\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0005, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 050\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0004, Position Loss: 0.0028, LR: 0.001000\n",
      "Epoch: 051\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0010, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0001, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 052\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0005, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0009, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 053\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0003, Position Loss: 0.0014, LR: 0.001000\n",
      "Epoch: 054\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0011, Feature Loss: 0.0004, Position Loss: 0.0016, LR: 0.001000\n",
      "Epoch: 055\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0003, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 056\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0016, Position Loss: 0.0019, LR: 0.001000\n",
      "Epoch: 057\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0048, Feature Loss: 0.0018, Position Loss: 0.0068, LR: 0.001000\n",
      "Epoch: 058\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0016, Position Loss: 0.0012, LR: 0.001000\n",
      "Epoch: 059\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0005, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0008, LR: 0.001000\n",
      "Epoch: 060\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0003, Position Loss: 0.0011, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0037, Feature Loss: 0.0006, Position Loss: 0.0058, LR: 0.001000\n",
      "Epoch: 061\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0009, Feature Loss: 0.0000, Position Loss: 0.0014, LR: 0.001000\n",
      "Epoch: 062\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0039, Feature Loss: 0.0005, Position Loss: 0.0062, LR: 0.001000\n",
      "Epoch: 063\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0004, Position Loss: 0.0012, LR: 0.001000\n",
      "Epoch: 064\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 065\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0000, Position Loss: 0.0036, LR: 0.001000\n",
      "Epoch: 066\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0015, Position Loss: 0.0024, LR: 0.001000\n",
      "Epoch: 067\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0021, Feature Loss: 0.0000, Position Loss: 0.0035, LR: 0.001000\n",
      "Epoch: 068\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0012, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 069\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0002, Position Loss: 0.0018, LR: 0.001000\n",
      "Epoch: 070\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 071\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 072\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 073\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0004, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 074\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0000, Position Loss: 0.0009, LR: 0.001000\n",
      "Epoch: 075\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 076\n",
      "\tTrain:\tTotal Loss: 0.0008, Feature Loss: 0.0006, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0010, Position Loss: 0.0019, LR: 0.001000\n",
      "Epoch: 077\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 078\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0004, Position Loss: 0.0020, LR: 0.001000\n",
      "Epoch: 079\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0002, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0005, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 080\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 081\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 082\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0003, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 083\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0005, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 084\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0002, Position Loss: 0.0025, LR: 0.001000\n",
      "Epoch: 085\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 086\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0015, Feature Loss: 0.0001, Position Loss: 0.0024, LR: 0.001000\n",
      "Epoch: 087\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0005, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 088\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0009, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 089\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0006, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 090\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0002, Position Loss: 0.0008, LR: 0.001000\n",
      "Epoch: 091\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0003, Position Loss: 0.0011, LR: 0.001000\n",
      "Epoch: 092\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.001000\n",
      "Epoch: 093\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0004, LR: 0.001000\n",
      "Epoch: 094\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0001, Position Loss: 0.0013, LR: 0.001000\n",
      "Epoch: 095\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0004, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 096\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0000, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 097\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0002, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 098\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 099\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0005, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0017, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 100\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0004, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 101\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0022, Feature Loss: 0.0004, Position Loss: 0.0033, LR: 0.001000\n",
      "Epoch: 102\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0005, Position Loss: 0.0009, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0001, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 103\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0006, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0011, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 104\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0000, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 105\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 106\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0011, Feature Loss: 0.0000, Position Loss: 0.0018, LR: 0.001000\n",
      "Epoch: 107\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 108\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0009, Feature Loss: 0.0001, Position Loss: 0.0015, LR: 0.001000\n",
      "Epoch: 109\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0001, Position Loss: 0.0012, LR: 0.001000\n",
      "Epoch: 110\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 111\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0017, Feature Loss: 0.0015, Position Loss: 0.0019, LR: 0.001000\n",
      "Epoch: 112\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0002, Position Loss: 0.0020, LR: 0.001000\n",
      "Epoch: 113\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 114\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 115\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 116\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0001, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 117\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0000, Position Loss: 0.0012, LR: 0.001000\n",
      "Epoch: 118\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 119\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 120\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 121\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0000, Position Loss: 0.0012, LR: 0.001000\n",
      "Epoch: 122\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0006, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 123\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 124\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0007, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 125\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0001, Position Loss: 0.0027, LR: 0.001000\n",
      "Epoch: 126\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0006, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0024, Feature Loss: 0.0004, Position Loss: 0.0038, LR: 0.001000\n",
      "Epoch: 127\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 128\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.001000\n",
      "Epoch: 129\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0004, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 130\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 131\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0007, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 132\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0020, Feature Loss: 0.0001, Position Loss: 0.0033, LR: 0.001000\n",
      "Epoch: 133\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 134\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 135\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0000, Position Loss: 0.0038, LR: 0.001000\n",
      "Epoch: 136\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0000, Position Loss: 0.0016, LR: 0.001000\n",
      "Epoch: 137\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 138\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 139\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0016, Feature Loss: 0.0005, Position Loss: 0.0024, LR: 0.001000\n",
      "Epoch: 140\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0006, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 141\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0000, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 142\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0007, LR: 0.001000\n",
      "Epoch: 143\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0004, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0002, Position Loss: 0.0019, LR: 0.001000\n",
      "Epoch: 144\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0026, Feature Loss: 0.0014, Position Loss: 0.0034, LR: 0.001000\n",
      "Epoch: 145\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0003, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 146\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0014, Feature Loss: 0.0000, Position Loss: 0.0023, LR: 0.001000\n",
      "Epoch: 147\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0001, Position Loss: 0.0009, LR: 0.001000\n",
      "Epoch: 148\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 149\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0012, Feature Loss: 0.0002, Position Loss: 0.0018, LR: 0.001000\n",
      "Epoch: 150\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0002, Position Loss: 0.0008, LR: 0.001000\n",
      "Epoch: 151\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0004, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 152\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0004, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0023, Feature Loss: 0.0032, Position Loss: 0.0016, LR: 0.001000\n",
      "Epoch: 153\n",
      "\tTrain:\tTotal Loss: 0.0007, Feature Loss: 0.0006, Position Loss: 0.0008, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 154\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 155\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 156\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0007, Feature Loss: 0.0001, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 157\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 158\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0000, Position Loss: 0.0008, LR: 0.001000\n",
      "Epoch: 159\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0006, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 160\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0007, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 161\n",
      "\tTrain:\tTotal Loss: 0.0006, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0005, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 162\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0025, Feature Loss: 0.0001, Position Loss: 0.0041, LR: 0.001000\n",
      "Epoch: 163\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0018, Feature Loss: 0.0004, Position Loss: 0.0027, LR: 0.001000\n",
      "Epoch: 164\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0000, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 165\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 166\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 167\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0000, Position Loss: 0.0010, LR: 0.001000\n",
      "Epoch: 168\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0005, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 169\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0009, Feature Loss: 0.0000, Position Loss: 0.0014, LR: 0.001000\n",
      "Epoch: 170\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 171\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 172\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0000, Position Loss: 0.0012, LR: 0.001000\n",
      "Epoch: 173\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0007, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 174\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 175\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0004, Position Loss: 0.0014, LR: 0.001000\n",
      "Epoch: 176\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 177\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 178\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0010, Feature Loss: 0.0022, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 179\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0003, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 180\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 181\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0004, LR: 0.001000\n",
      "Epoch: 182\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0000, Position Loss: 0.0006, LR: 0.001000\n",
      "Epoch: 183\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0006, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 184\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 185\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0008, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 186\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.001000\n",
      "Epoch: 187\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0003, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 188\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0003, Position Loss: 0.0011, LR: 0.001000\n",
      "Epoch: 189\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0005, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 190\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0004, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 191\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0001, Position Loss: 0.0013, LR: 0.001000\n",
      "Epoch: 192\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0005, Feature Loss: 0.0007, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 193\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 194\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0008, Feature Loss: 0.0017, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 195\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0007, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 196\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 197\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0005, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.001000\n",
      "Epoch: 198\n",
      "\tTrain:\tTotal Loss: 0.0005, Feature Loss: 0.0003, Position Loss: 0.0006, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.001000\n",
      "Epoch: 199\n",
      "\tTrain:\tTotal Loss: 0.0004, Feature Loss: 0.0003, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0003, Position Loss: 0.0002, LR: 0.001000\n",
      "Epoch: 200\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.001000\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.001000\n",
      "Epoch: 201\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 202\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 203\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 204\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 205\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 206\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0004, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 207\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 208\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 209\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 210\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 211\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0003, LR: 0.000500\n",
      "Epoch: 212\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 213\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 214\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0005, LR: 0.000500\n",
      "Epoch: 215\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 216\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0002, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 217\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0013, Feature Loss: 0.0005, Position Loss: 0.0019, LR: 0.000500\n",
      "Epoch: 218\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 219\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0004, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 220\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 221\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 222\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 223\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 224\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0001, Position Loss: 0.0006, LR: 0.000500\n",
      "Epoch: 225\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 226\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 227\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0006, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 228\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 229\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0007, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 230\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0003, LR: 0.000500\n",
      "Epoch: 231\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 232\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 233\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0003, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 234\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 235\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0003, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 236\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0002, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 237\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 238\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 239\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 240\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0002, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 241\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 242\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 243\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 244\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 245\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 246\n",
      "\tTrain:\tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 247\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 248\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.000500\n",
      "Epoch: 249\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0004, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 250\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0004, Position Loss: 0.0003, LR: 0.000500\n",
      "Epoch: 251\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 252\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0004, Feature Loss: 0.0000, Position Loss: 0.0007, LR: 0.000500\n",
      "Epoch: 253\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 254\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 255\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 256\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 257\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 258\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 259\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 260\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 261\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0002, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 262\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 263\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 264\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0001, Position Loss: 0.0009, LR: 0.000500\n",
      "Epoch: 265\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0002, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 266\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 267\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 268\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 269\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 270\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 271\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 272\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 273\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 274\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 275\n",
      "\tTrain:\tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 276\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 277\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 278\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 279\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 280\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 281\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 282\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0001, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 283\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 284\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 285\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0001, Position Loss: 0.0003, LR: 0.000500\n",
      "Epoch: 286\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 287\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 288\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 289\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0006, Feature Loss: 0.0000, Position Loss: 0.0010, LR: 0.000500\n",
      "Epoch: 290\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 291\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 292\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 293\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 294\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 295\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 296\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0004, LR: 0.000500\n",
      "Epoch: 297\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 298\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 299\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0009, Feature Loss: 0.0002, Position Loss: 0.0013, LR: 0.000500\n",
      "Epoch: 300\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.000500\n",
      "Epoch: 301\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 302\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 303\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 304\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 305\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 306\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 307\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 308\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0002, LR: 0.000500\n",
      "Epoch: 309\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 310\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 311\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0003, Feature Loss: 0.0000, Position Loss: 0.0005, LR: 0.000500\n",
      "Epoch: 312\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 313\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 314\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 315\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 316\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 317\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 318\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 319\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 320\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 321\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 322\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 323\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 324\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 325\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 326\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 327\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 328\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 329\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 330\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 331\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 332\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 333\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 334\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 335\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 336\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 337\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 338\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 339\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 340\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 341\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 342\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0002, Feature Loss: 0.0000, Position Loss: 0.0003, LR: 0.000500\n",
      "Epoch: 343\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 344\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 345\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 346\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0009, Feature Loss: 0.0002, Position Loss: 0.0014, LR: 0.000500\n",
      "Epoch: 347\n",
      "\tTrain:\tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 348\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 349\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 350\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 351\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 352\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 353\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 354\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 355\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 356\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 357\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 358\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 359\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 360\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 361\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 362\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 363\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 364\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 365\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 366\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 367\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 368\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 369\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 370\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 371\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 372\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 373\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 374\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 375\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 376\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 377\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 378\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 379\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 380\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 381\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 382\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000500\n",
      "Epoch: 383\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 384\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 385\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 386\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 387\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 388\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 389\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 390\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 391\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 392\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 393\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 394\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 395\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 396\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 397\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0001, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 398\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 399\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 400\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000500\n",
      "Epoch: 401\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 402\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 403\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 404\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 405\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 406\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 407\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 408\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 409\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 410\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 411\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 412\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 413\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 414\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 415\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 416\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 417\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 418\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 419\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 420\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 421\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 422\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 423\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 424\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 425\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 426\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 427\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 428\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 429\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 430\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 431\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 432\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 433\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 434\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 435\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 436\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 437\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 438\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 439\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 440\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 441\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000250\n",
      "Epoch: 442\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 443\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 444\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 445\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 446\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 447\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 448\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 449\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 450\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 451\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 452\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 453\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 454\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 455\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 456\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 457\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 458\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 459\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 460\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 461\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 462\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 463\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 464\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 465\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 466\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 467\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 468\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 469\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 470\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 471\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 472\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 473\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 474\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 475\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 476\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 477\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 478\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 479\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 480\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 481\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 482\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 483\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 484\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 485\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 486\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 487\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 488\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 489\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 490\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 491\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 492\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 493\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 494\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0001, Feature Loss: 0.0000, Position Loss: 0.0001, LR: 0.000250\n",
      "Epoch: 495\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 496\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 497\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 498\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 499\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "Epoch: 500\n",
      "\tTrain:\tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n",
      "\tTest: \tTotal Loss: 0.0000, Feature Loss: 0.0000, Position Loss: 0.0000, LR: 0.000250\n"
     ]
    }
   ],
   "source": [
    "train_total_losses = []\n",
    "train_feature_losses = []\n",
    "train_edge_losses = []\n",
    "train_position_losses = []\n",
    "\n",
    "test_total_losses = []\n",
    "test_feature_losses = []\n",
    "test_edge_losses = []\n",
    "test_position_losses = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "\n",
    "\n",
    "if model_loaded:        \n",
    "    print(\"Pretrained Model Loaded, no training required\")\n",
    "else:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_total_loss, train_feature_loss, train_edge_loss,train_position_loss = train()\n",
    "        test_total_loss, test_feature_loss, test_edge_loss,test_position_loss = test()\n",
    "        \n",
    "        print(f\"Epoch: {epoch:03d}\")\n",
    "        print(f'\\tTrain:\\tTotal Loss: {train_total_loss:.4f}, Feature Loss: {train_feature_loss:.4f}, Position Loss: {train_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        print(f'\\tTest: \\tTotal Loss: {test_total_loss:.4f}, Feature Loss: {test_feature_loss:.4f}, Position Loss: {test_position_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        \n",
    "        if(early_stopper.early_stop(test_total_loss)):\n",
    "            print(\"Early Stopping\")\n",
    "            break\n",
    "\n",
    "        train_total_losses.append(train_total_loss)\n",
    "        train_feature_losses.append(train_feature_loss)\n",
    "        train_edge_losses.append(train_edge_loss)\n",
    "        train_position_losses.append(train_position_loss)\n",
    "\n",
    "        test_total_losses.append(test_total_loss)\n",
    "        test_feature_losses.append(test_feature_loss)\n",
    "        test_edge_losses.append(test_edge_loss)\n",
    "        test_position_losses.append(test_position_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model,\"./models/\"+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "Vp6sgGOOUuhs",
    "outputId": "8e483db8-e50c-4165-c93e-52a09d610557"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGzCAYAAADEw6Y0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACVuklEQVR4nO2deXgT1f7/30naNF1oC5QuQIGyKCB7kVJAcakUxa/WBRG9gsgFRVGRe1XwYgHRixcvXgRUXH4sekUQF1TkopVdlrLviyyFAqULlO5L2uT8/khnOjOZmSRtk0ybz+t5+jSZOXPmzEza885nOzrGGANBEARBEEQTR+/tARAEQRAEQXgCEj0EQRAEQfgEJHoIgiAIgvAJSPQQBEEQBOETkOghCIIgCMInINFDEARBEIRPQKKHIAiCIAifgEQPQRAEQRA+AYkegiAIgiB8AhI9BEEQBEH4BCR6CKKJodPpnPrZsmVLvc9VVlaGWbNmOd3Xli1bFMfz+OOP13s8cpw4cQKzZs3ChQsX3NJ/feDux7fffuvtoRCET+Dn7QEQBNGwfPnll6L3X3zxBdLS0uy2d+vWrd7nKisrw+zZswEAd9xxh9PHvfTSS7j11ltF2zp06FDv8chx4sQJzJ49G3fccYfbzkEQROOARA9BNDH+8pe/iN7v3r0baWlpdtu9yW233YZHH33U28OoF6WlpQgODvb2MAiCcAFybxGED2K1WrFgwQLccsstMJlMiIqKwrPPPosbN26I2u3btw/JycmIiIhAYGAg4uLi8MwzzwAALly4gFatWgEAZs+ezbupZs2aVe/xpaenY/jw4QgLC0NQUBCGDh2KHTt2iNpcvHgRzz//PG6++WYEBgaiZcuWGDlypMiNtXz5cowcORIAcOedd9q59pTG26FDBzz99NOifnQ6HbZu3Yrnn38ekZGRaNu2Lb//f//7H2677TYEBwejWbNmGDFiBI4fP17v+8Bx/vx5jBw5Ei1atEBQUBAGDhyIX375xa7dokWLcMsttyAoKAjNmzdH//79sXLlSn5/cXExpkyZgg4dOiAgIACRkZG45557cODAgQYbK0FoGbL0EIQP8uyzz2L58uUYN24cXnrpJWRkZGDx4sU4ePAgduzYAX9/f+Tm5mLYsGFo1aoVpk2bhvDwcFy4cAHff/89AKBVq1b4+OOPMWnSJDz00EN4+OGHAQC9evVyeP7i4mJcu3ZNtK1FixbQ6/XYtGkT7r33XsTHx2PmzJnQ6/VYtmwZ7rrrLmzfvh0DBgwAAOzduxc7d+7E448/jrZt2+LChQv4+OOPcccdd+DEiRMICgrC7bffjpdeegkLFy7EG2+8wbv06urae/7559GqVSukpqaitLQUgM2dOHbsWCQnJ+Nf//oXysrK8PHHH2PIkCE4ePBgvV1qOTk5GDRoEMrKyvDSSy+hZcuWWLFiBR544AF8++23eOihhwAAn332GV566SU8+uijePnll1FRUYEjR44gPT0dTzzxBADgueeew7fffovJkyeje/fuuH79Ov744w+cPHkS/fr1q9c4CaJRwAiCaNK88MILTPinvn37dgaAffXVV6J2GzZsEG3/4YcfGAC2d+9exb7z8vIYADZz5kynxrJ582YGQPYnIyODWa1W1qVLF5acnMysVit/XFlZGYuLi2P33HOPaJuUXbt2MQDsiy++4LetWbOGAWCbN2+2a6809vbt27OxY8fy75ctW8YAsCFDhrDq6mp+e3FxMQsPD2cTJkwQHZ+dnc3CwsLstivdjzVr1ii2mTJlCgPAtm/fLjpvXFwc69ChA7NYLIwxxh588EF2yy23qJ4vLCyMvfDCC6ptCKIpQ+4tgvAx1qxZg7CwMNxzzz24du0a/xMfH4+QkBBs3rwZABAeHg4AWLduHaqqqhp0DKmpqUhLSxP9REdH49ChQzhz5gyeeOIJXL9+nR9baWkp7r77bmzbtg1WqxUAEBgYyPdXVVWF69evo3PnzggPD3ebu2bChAkwGAz8+7S0NBQUFGD06NGie2kwGJCQkMDfy/qwfv16DBgwAEOGDOG3hYSEYOLEibhw4QJOnDgBwPa8Ll++jL179yr2FR4ejvT0dGRlZdV7XATRGCH3FkH4GGfOnEFhYSEiIyNl9+fm5gIAhg4dikceeQSzZ8/Gf/7zH9xxxx1ISUnBE088gYCAgHqNoWfPnkhKSpIdGwCMHTtW8djCwkI0b94c5eXlmDt3LpYtW4YrV66AMSZq4w7i4uJkx3vXXXfJtg8NDa33OS9evIiEhAS77ZyL7uLFi+jRowdef/11/P777xgwYAA6d+6MYcOG4YknnsDgwYP5Y+bNm4exY8ciNjYW8fHxuO+++zBmzBh07Nix3uMkiMYAiR6C8DGsVisiIyPx1Vdfye7ngpO5+jG7d+/Gzz//jF9//RXPPPMM5s+fj927dyMkJMQtYwOA9957D3369JFtw533xRdfxLJlyzBlyhQkJiYiLCyMr/fD9VNXLBaL7HahdUk43i+//BLR0dF27f38PPcvtlu3bjh9+jTWrVuHDRs24LvvvsNHH32E1NRUvqzAY489httuuw0//PADfvvtN7z33nv417/+he+//x733nuvx8ZKEN6CRA9B+BidOnXC77//jsGDB9tN4nIMHDgQAwcOxDvvvIOVK1fiySefxKpVq/DXv/4VOp2uwccG2CwkcpYgId9++y3Gjh2L+fPn89sqKipQUFAgaqc2xubNm9u1N5vNuHr1qkvjjYyMdDjeutK+fXucPn3abvupU6f4/RzBwcEYNWoURo0aBbPZjIcffhjvvPMOpk+fDpPJBACIiYnB888/j+effx65ubno168f3nnnHRI9hE9AMT0E4WM89thjsFgsmDNnjt2+6upqXgTcuHFD5DICwFtfKisrAQBBQUEAYCcc6kp8fDw6deqEf//73ygpKbHbn5eXx782GAx241u0aJGdlYarpSM3xk6dOmHbtm2ibZ9++qmipUdKcnIyQkND8c9//lM27kk43rpy3333Yc+ePdi1axe/rbS0FJ9++ik6dOiA7t27AwCuX78uOs5oNKJ79+5gjKGqqgoWi8XO7RcZGYnWrVvzz5Mgmjpk6SEIH2Po0KF49tlnMXfuXBw6dAjDhg2Dv78/zpw5gzVr1uCDDz7Ao48+ihUrVuCjjz7CQw89hE6dOqG4uBifffYZQkNDcd999wGwuXu6d++O1atX46abbkKLFi3Qo0cP9OjRo05j0+v1+Pzzz3Hvvffilltuwbhx49CmTRtcuXIFmzdvRmhoKH7++WcAwP33348vv/wSYWFh6N69O3bt2oXff/8dLVu2FPXZp08fGAwG/Otf/0JhYSECAgJw1113ITIyEn/961/x3HPP4ZFHHsE999yDw4cP49dff0VERIRT4w0NDcXHH3+Mp556Cv369cPjjz+OVq1aITMzE7/88gsGDx6MxYsXO+znu+++4y03QsaOHYtp06bh66+/xr333ouXXnoJLVq0wIoVK5CRkYHvvvsOer3tu+uwYcMQHR2NwYMHIyoqCidPnsTixYsxYsQINGvWDAUFBWjbti0effRR9O7dGyEhIfj999+xd+9ekbWMIJo03k0eIwjC3UhT1jk+/fRTFh8fzwIDA1mzZs1Yz5492WuvvcaysrIYY4wdOHCAjR49mrVr144FBASwyMhIdv/997N9+/aJ+tm5cyeLj49nRqPRYfq6MynajDF28OBB9vDDD7OWLVuygIAA1r59e/bYY4+xjRs38m1u3LjBxo0bxyIiIlhISAhLTk5mp06dsks3Z4yxzz77jHXs2JEZDAZR+rrFYmGvv/46i4iIYEFBQSw5OZmdPXtWMWVdKX1/8+bNLDk5mYWFhTGTycQ6derEnn76abt7pXQ/lH64NPVz586xRx99lIWHhzOTycQGDBjA1q1bJ+rrk08+Ybfffjt/zzp16sReffVVVlhYyBhjrLKykr366qusd+/erFmzZiw4OJj17t2bffTRR6pjJIimhI4xiX2YIAiCIAiiCUIxPQRBEARB+AQkegiCIAiC8AlI9BAEQRAE4ROQ6CEIgiAIwicg0UMQBEEQhE9AoocgCIIgCJ+AihMKsFqtyMrKQrNmzRq8vD5BEARBEO6BMYbi4mK0bt2aL9gpB4keAVlZWYiNjfX2MAiCIAiCqAOXLl1C27ZtFfeT6BHQrFkzALabFhoa6uXREARBEAThDEVFRYiNjeXncSVI9AjgXFqhoaEkegiCIAiikeEoNIUCmQmCIAiC8AlI9BAEQRAE4ROQ6CEIgiAIwiegmB6CIAhCMzDGUF1dDYvF4u2hEBrCYDDAz8+v3uVkSPQQBEEQmsBsNuPq1asoKyvz9lAIDRIUFISYmBgYjcY690GihyAIgvA6VqsVGRkZMBgMaN26NYxGIxWJJQDYrH9msxl5eXnIyMhAly5dVAsQqkGihyAIgvA6ZrMZVqsVsbGxCAoK8vZwCI0RGBgIf39/XLx4EWazGSaTqU79UCAzQRAEoRnq+g2eaPo0xGeDPl0EQRAEQfgEJHoIgiAIgvAJSPQQBEEQBOETkOghCIIgiDry9NNPQ6fT2f2cPXu2Qfpfvnw5wsPDG6SvuvL0008jJSXFq2NoKCh7iyA0wM+HsxDob0BS9yhvD4UgCBcZPnw4li1bJtrWqlUrL41GmaqqKvj7+3t7GF6FLD0E4WVyiyvw4tcH8dcv9sFqZd4eDkFoAsYYyszVXvlhzLW/w4CAAERHR4t+DAYDAODHH39Ev379YDKZ0LFjR8yePRvV1dX8se+//z569uyJ4OBgxMbG4vnnn0dJSQkAYMuWLRg3bhwKCwt5C9KsWbMA2FYTX7t2rWgc4eHhWL58OQDgwoUL0Ol0WL16NYYOHQqTyYSvvvoKAPD555+jW7duMJlM6Nq1Kz766KM6PKFatm7digEDBiAgIAAxMTGYNm2a6Bq//fZb9OzZE4GBgWjZsiWSkpJQWlrKX+OAAQMQHByM8PBwDB48GBcvXqzXeNQgSw9BeJmi8ir+NUkegrBRXmVB99RfvXLuE28lI8hY/+lx+/btGDNmDBYuXIjbbrsN586dw8SJEwEAM2fOBGBLw164cCHi4uJw/vx5PP/883jttdfw0UcfYdCgQViwYAFSU1Nx+vRpAEBISIhLY5g2bRrmz5+Pvn378sInNTUVixcvRt++fXHw4EFMmDABwcHBGDt2rMvXeOXKFdx33314+umn8cUXX+DUqVOYMGECTCYTZs2ahatXr2L06NGYN28eHnroIRQXF2P79u38ciMpKSmYMGECvv76a5jNZuzZs8etRSlJ9BAEQRBEPVi3bp1IjNx7771Ys2YNZs+ejWnTpvFiomPHjpgzZw5ee+01XvRMmTKFP65Dhw54++238dxzz+Gjjz6C0WhEWFgYdDodoqOj6zS2KVOm4OGHH+bfz5w5E/Pnz+e3xcXF4cSJE/jkk0/qJHo++ugjxMbGYvHixdDpdOjatSuysrLw+uuvIzU1FVevXkV1dTUefvhhtG/fHgDQs2dPAEB+fj4KCwtx//33o1OnTgCAbt261ek6nYVED0FoCJtZnUrvE0SgvwEn3kr22rld4c4778THH3/Mvw8ODgYAHD58GDt27MA777zD77NYLKioqEBZWRmCgoLw+++/Y+7cuTh16hSKiopQXV0t2l9f+vfvz78uLS3FuXPnMH78eEyYMIHfXl1djbCwsDr1f/LkSSQmJoqsM4MHD0ZJSQkuX76M3r174+6770bPnj2RnJyMYcOG4dFHH0Xz5s3RokULPP3000hOTsY999yDpKQkPPbYY4iJian7BTuARA9BaAhybxGEDZ1O1yAuJk8QHByMzp07220vKSnB7NmzRZYWDpPJhAsXLuD+++/HpEmT8M4776BFixb4448/MH78eJjNZlXRo9Pp7GKPqqqq7NpxAowbDwB89tlnSEhIELXjYpAaGoPBgLS0NOzcuRO//fYbFi1ahH/84x9IT09HXFwcli1bhpdeegkbNmzA6tWrMWPGDKSlpWHgwIFuGU/j+EQRhI/gYvwkQRAapl+/fjh9+rSsIAKA/fv3w2q1Yv78+fwSC998842ojdFohMVisTu2VatWuHr1Kv/+zJkzDlenj4qKQuvWrXH+/Hk8+eSTrl6OLN26dcN3330Hxhhv7dmxYweaNWuGtm3bArAJtMGDB2Pw4MFITU1F+/bt8cMPP2Dq1KkAgL59+6Jv376YPn06EhMTsXLlShI9BNF0IXcWQTRFUlNTcf/996Ndu3Z49NFHodfrcfjwYRw7dgxvv/02OnfujKqqKixatAj/93//hx07dmDJkiWiPjp06ICSkhJs3LgRvXv3RlBQEIKCgnDXXXdh8eLFSExMhMViweuvv+5UOvrs2bPx0ksvISwsDMOHD0dlZSX27duHGzdu8CJEjsLCQhw6dEi0rWXLlnj++eexYMECvPjii5g8eTJOnz6NmTNnYurUqdDr9UhPT8fGjRsxbNgwREZGIj09HXl5eejWrRsyMjLw6aef4oEHHkDr1q1x+vRpnDlzBmPGjKnT/XYKRvAUFhYyAKywsNDbQyF8iDM5Raz96+tY+9fXsYqqam8PhyC8Qnl5OTtx4gQrLy/39lBcYuzYsezBBx9U3L9hwwY2aNAgFhgYyEJDQ9mAAQPYp59+yu9///33WUxMDAsMDGTJycnsiy++YADYjRs3+DbPPfcca9myJQPAZs6cyRhj7MqVK2zYsGEsODiYdenSha1fv56FhYWxZcuWMcYYy8jIYADYwYMH7cb01VdfsT59+jCj0ciaN2/Obr/9dvb999+rXiNs3nfRz/jx4xljjG3ZsoXdeuutzGg0sujoaPb666+zqqoqxhhjJ06cYMnJyaxVq1YsICCA3XTTTWzRokWMMcays7NZSkoKi4mJYUajkbVv356lpqYyi8UiOw61z4iz87eOMTKocxQVFSEsLAyFhYUIDQ319nAIH+FsbjGS3t8GADg1ZzhMLgZREkRToKKiAhkZGYiLi4PJZPL2cAgNovYZcXb+puKEBEEQBEH4BCR6CMLr1Mb0kN2VIAjCfZDoIQivQ0qHIAjCE5DoIQgNwUgAEQRBuA0SPQThdci9RRAclFtDKNEQnw0SPQShIejfPeGrcDVmHBXYI3wX7rPhTD0iJag4IUF4HZI6BGEwGBAeHo7c3FwAQFBQkFtX2yYaD4wxlJWVITc3F+Hh4fVaMoNED0FoCDLtE74Mt5I4J3wIQkh4eHidV5vnINFDEF5HENPjxVEQhLfR6XSIiYlBZGSk7OKZhO/i7+/fIIuikughCA1Bhh6CsLm63LXqN+HbUCAzQRAEQRA+QZ1Ez4cffogOHTrAZDIhISEBe/bsUW2/Zs0adO3aFSaTCT179sT69etF+xljSE1NRUxMDAIDA5GUlIQzZ86I2jzwwANo164dTCYTYmJi8NRTTyErK0vU5siRI7jttttgMpkQGxuLefPm1eXyCMJ7kKWHIAjCbbgselavXo2pU6di5syZOHDgAHr37o3k5GTFwLOdO3di9OjRGD9+PA4ePIiUlBSkpKTg2LFjfJt58+Zh4cKFWLJkCdLT0xEcHIzk5GRUVFTwbe6880588803OH36NL777jucO3cOjz76KL+/qKgIw4YNQ/v27bF//3689957mDVrFj799FNXL5EgvAYVJyQIgnAjqmuwyzBgwAD2wgsv8O8tFgtr3bo1mzt3rmz7xx57jI0YMUK0LSEhgT377LOMMcasViuLjo5m7733Hr+/oKCABQQEsK+//lpxHD/++CPT6XTMbDYzxhj76KOPWPPmzVllZSXf5vXXX2c333yzYh8VFRWssLCQ/7l06ZJTS9MTRENyJqeYtX99HWv/+jqWX1Lp+ACCIAhCRGFhoVPzt0uWHrPZjP379yMpKYnfptfrkZSUhF27dskes2vXLlF7AEhOTubbZ2RkIDs7W9QmLCwMCQkJin3m5+fjq6++wqBBg/giRbt27cLtt98Oo9EoOs/p06dx48YN2X7mzp2LsLAw/ic2NtaJu0AQDQuVIiEIgvAMLomea9euwWKxICoqSrQ9KioK2dnZssdkZ2ertud+O9Pn66+/juDgYLRs2RKZmZn48ccfHZ5HeA4p06dPR2FhIf9z6dIl2XYE4U6EGVvk3CIIgnAfjSp769VXX8XBgwfx22+/wWAwYMyYMfUq5hYQEIDQ0FDRD0F4k/p8ngmCIAh1XKrTExERAYPBgJycHNH2nJwcxSqJ0dHRqu253zk5OYiJiRG16dOnj935IyIicNNNN6Fbt26IjY3F7t27kZiYqHge4TkIQuuQ5CEIgnAfLll6jEYj4uPjsXHjRn6b1WrFxo0bkZiYKHtMYmKiqD0ApKWl8e3j4uIQHR0talNUVIT09HTFPrnzAkBlZSV/nm3btomqeKalpeHmm29G8+bNXblMgvAaZOghCIJwHy67t6ZOnYrPPvsMK1aswMmTJzFp0iSUlpZi3LhxAIAxY8Zg+vTpfPuXX34ZGzZswPz583Hq1CnMmjUL+/btw+TJkwHYyo5PmTIFb7/9Nn766SccPXoUY8aMQevWrZGSkgIASE9Px+LFi3Ho0CFcvHgRmzZtwujRo9GpUydeGD3xxBMwGo0YP348jh8/jtWrV+ODDz7A1KlT63uPCMLNkNIhCILwBC4vQzFq1Cjk5eUhNTUV2dnZ6NOnDzZs2MAHDWdmZkKvr9VSgwYNwsqVKzFjxgy88cYb6NKlC9auXYsePXrwbV577TWUlpZi4sSJKCgowJAhQ7BhwwaYTCYAttV2v//+e8ycOROlpaWIiYnB8OHDMWPGDAQEBACwZXz99ttveOGFFxAfH4+IiAikpqZi4sSJ9bpBBOFJqE4PQRCE+9AxipzkKSoqQlhYGAoLCymomfAYZ3KKcc9/tgEA9rxxNyJDTV4eEUEQROPC2fm7UWVvEURThCm8JgiCIBoWEj0E4WXI1koQBOEZSPQQhIYgAUQQBOE+SPQQhJcRBi9TIDNBEIT7INFDEF5GtAwFaR6CIAi3QaKHIAiCIAifgEQPQXgZWnCUIAjCM5DoIQgvI4rpIf8WQRCE2yDRo2EYY7BYaRJs6lBMD0EQhGcg0aNhnvw8HXf+ewvM1VZvD4UgCIIgGj0kejTMznPXkZlfhqNXCr09FIIgCIJo9JDoIQgvQ+4tgiAIz0CihyA0BBUnJAiCcB8kegjCy4izt7w4EIIgiCYOiR6C8DIkdAiCIDwDiR6C8DJM4TVBEATRsJDoIQgNQcUJCYIg3AeJnkaATuftERDuRCh0SPIQBEG4DxI9GoW+8fsO9KQJgiA8A4kejUKaxzeh504QBOE+SPRoFJr7fAex0KEnTxAE4S5I9GgUcm/5ElSnhyAIwhOQ6CEIgiAIwicg0aNR6Au/7yBae8t7wyAIgmjykOjRKOTm8B1ExQnpuRMEQbgNEj0ahRae9B3Elh567gRBEO6CRI9GoW/8BEEQBNGwkOghCC8jqshMYpcgCMJtkOjRKDT5+Q4U00MQBOEZSPRoFIrt8E3ouRMEQbgPEj0aRfiNn9YbbdqIAplJ8xAEQbgNEj0aheY+34GsOwRBEJ6BRI9GoWUofAh61ARBEB6BRI9GoXnQNyGtSxAE4T5I9GgUWprAdxBlb9HTJgiCcBskegjCy5B1hyAIwjOQ6NEqlL3lk5AAIgiCcB8kejQKuTl8B+GzpqdOEAThPkj0aBT6xu87iOv00IMnCIJwFyR6NApNfb4DPWuCIAjPQKJHo9A3ft+EnjpBEIT7qJPo+fDDD9GhQweYTCYkJCRgz549qu3XrFmDrl27wmQyoWfPnli/fr1oP2MMqampiImJQWBgIJKSknDmzBl+/4ULFzB+/HjExcUhMDAQnTp1wsyZM2E2m0VtdDqd3c/u3bvrcolehyY/34FWWScIgvAMLoue1atXY+rUqZg5cyYOHDiA3r17Izk5Gbm5ubLtd+7cidGjR2P8+PE4ePAgUlJSkJKSgmPHjvFt5s2bh4ULF2LJkiVIT09HcHAwkpOTUVFRAQA4deoUrFYrPvnkExw/fhz/+c9/sGTJErzxxht25/v9999x9epV/ic+Pt7VS9QEVKfHd2Aq7wiCIIiGQ8dc9KMkJCTg1ltvxeLFiwEAVqsVsbGxePHFFzFt2jS79qNGjUJpaSnWrVvHbxs4cCD69OmDJUuWgDGG1q1b429/+xv+/ve/AwAKCwsRFRWF5cuX4/HHH5cdx3vvvYePP/4Y58+fB2Cz9MTFxeHgwYPo06ePK5fEU1RUhLCwMBQWFiI0NLROfTQUucUVGPDORgDAd5MGIb59c6+Oh3Afm0/nYtyyvQCA7yYlIr59Cy+PiCAIonHh7PztkqXHbDZj//79SEpKqu1Ar0dSUhJ27dole8yuXbtE7QEgOTmZb5+RkYHs7GxRm7CwMCQkJCj2CdiEUYsW9pPDAw88gMjISAwZMgQ//fST6vVUVlaiqKhI9KMZmOIboqlBq6wTBEF4BJdEz7Vr12CxWBAVFSXaHhUVhezsbNljsrOzVdtzv13p8+zZs1i0aBGeffZZfltISAjmz5+PNWvW4JdffsGQIUOQkpKiKnzmzp2LsLAw/ic2NlaxracRLU1AE2GThur0EARBeAY/bw/AVa5cuYLhw4dj5MiRmDBhAr89IiICU6dO5d/feuutyMrKwnvvvYcHHnhAtq/p06eLjikqKtKM8KGYHt+BkaWHIAjCI7hk6YmIiIDBYEBOTo5oe05ODqKjo2WPiY6OVm3P/Xamz6ysLNx5550YNGgQPv30U4fjTUhIwNmzZxX3BwQEIDQ0VPSjFUTf/mki9BmoVAFBEIT7cEn0GI1GxMfHY+PGjfw2q9WKjRs3IjExUfaYxMREUXsASEtL49vHxcUhOjpa1KaoqAjp6emiPq9cuYI77rgD8fHxWLZsGfR6x0M/dOgQYmJiXLlEgvA4pHMIgiA8g8vuralTp2Ls2LHo378/BgwYgAULFqC0tBTjxo0DAIwZMwZt2rTB3LlzAQAvv/wyhg4divnz52PEiBFYtWoV9u3bx1tqdDodpkyZgrfffhtdunRBXFwc3nzzTbRu3RopKSkAagVP+/bt8e9//xt5eXn8eDhr0IoVK2A0GtG3b18AwPfff4+lS5fi888/r/vd8SK0NIHvwBReEwRBEA2Ly6Jn1KhRyMvLQ2pqKrKzs9GnTx9s2LCBD0TOzMwUWWEGDRqElStXYsaMGXjjjTfQpUsXrF27Fj169ODbvPbaaygtLcXEiRNRUFCAIUOGYMOGDTCZTABslqGzZ8/i7NmzaNu2rWg8QkEwZ84cXLx4EX5+fujatStWr16NRx991NVL1AQ0EfompG8JgiDch8t1epoyWqrTc/lGGYb8azMA4OsJA5HYqaVXx0O4j9+OZ2Pil/sBACsnJGBQpwgvj4ggCKJx4ZY6PYTnEGdvkS5tytDTJQiC8AwkehoDNCv6DvSsCYIg3AaJHo1CTkffgWoyEQRBeAYSPRqFqvT6ElSTiSAIwhOQ6NEoVKXXd6DnSxAE4RlI9GgUcco6zYq+Aj1rgiAI90GiR6MIKwmQJaBpQ4vLEgRBeAYSPRqFihP6DhTITBAE4RlI9GgUWoaCIAiCIBoWEj0E4WVEmXokcAmCINwGiR7NQinrvgK5twiCIDwDiR6Nwiiox2dgim8IgiCIhoREj0ahlHXfhJ41QRCE+yDRo1GoOKHvQHE8BEEQnoFEj0ZhtDSBT0LPmiAIwn2Q6NEoNPn5JvTcCYIg3AeJHo1CGT2+Az1rgiAIz0CiR6NQ7RbfgYKXCYIgPAOJHo1C3/59B6q+TRAE4RlI9DQCaB70HdzxqK1WhjM5xSSoCILweUj0aBRGFet8BneXJ0j96Rju+c82LN50tuE7JwiCaESQ6CEIL+NuSfvf3ZkAgPlpf7r5TARBENqGRI9GoTo9vgo9bIIgCHdBokejUCCz7yCMtSGBSxAE4T5I9GgU0dpbNBE2aWhtWYIgCM9AokejiL7901TYtKHHSxAE4RFI9GgUsvT4JvSsCYIg3AeJHo1CMT2+gyhonZ42QRCE2yDRo1lo8vMV3F2nhyAIgrBBokej0NIEvgk9aYIgCPdBokej0OTnO9CzJgiC8AwkejQKuTx8B7LqEQRBeAYSPRqFUtZ9B3q+BEEQnoFEj0ahlHXfhJ41QRCE+yDRQxBehoQOQRCEZyDRo1Eopsd3EC9DQQ+bIAjCXZDo0SjignWEr0AClyAIwn2Q6NEqlNHjO9Aq6wRBEB6BRI9GoZW3fQd6vgRBEJ6BRI9GYaR6fBJ61ARBEO6DRI9GoYBW34GKExIEQXiGOomeDz/8EB06dIDJZEJCQgL27Nmj2n7NmjXo2rUrTCYTevbsifXr14v2M8aQmpqKmJgYBAYGIikpCWfOnOH3X7hwAePHj0dcXBwCAwPRqVMnzJw5E2azWdTPkSNHcNttt8FkMiE2Nhbz5s2ry+VpAvEq6zQRNmXEhSgJgiAId+Gy6Fm9ejWmTp2KmTNn4sCBA+jduzeSk5ORm5sr237nzp0YPXo0xo8fj4MHDyIlJQUpKSk4duwY32bevHlYuHAhlixZgvT0dAQHByM5ORkVFRUAgFOnTsFqteKTTz7B8ePH8Z///AdLlizBG2+8wfdRVFSEYcOGoX379ti/fz/ee+89zJo1C59++qmrl6gJqDih70CPlyAIwjO4LHref/99TJgwAePGjUP37t2xZMkSBAUFYenSpbLtP/jgAwwfPhyvvvoqunXrhjlz5qBfv35YvHgxANu33AULFmDGjBl48MEH0atXL3zxxRfIysrC2rVrAQDDhw/HsmXLMGzYMHTs2BEPPPAA/v73v+P777/nz/PVV1/BbDZj6dKluOWWW/D444/jpZdewvvvv1+H2+J96Nu/j0IPmyAIwm24JHrMZjP279+PpKSk2g70eiQlJWHXrl2yx+zatUvUHgCSk5P59hkZGcjOzha1CQsLQ0JCgmKfAFBYWIgWLVqIznP77bfDaDSKznP69GncuHFDto/KykoUFRWJfrQCWXp8B3JlEgRBeAaXRM+1a9dgsVgQFRUl2h4VFYXs7GzZY7Kzs1Xbc79d6fPs2bNYtGgRnn32WYfnEZ5Dyty5cxEWFsb/xMbGyrbzCjQR+gwkcAmCIDxDo8veunLlCoYPH46RI0diwoQJ9epr+vTpKCws5H8uXbrUQKOsP6KKzDQR+gz0qAmCINyHS6InIiICBoMBOTk5ou05OTmIjo6WPSY6Olq1PffbmT6zsrJw5513YtCgQXYBykrnEZ5DSkBAAEJDQ0U/BOFpKE2dIAjCM7gkeoxGI+Lj47Fx40Z+m9VqxcaNG5GYmCh7TGJioqg9AKSlpfHt4+LiEB0dLWpTVFSE9PR0UZ9XrlzBHXfcgfj4eCxbtgx6vXjoiYmJ2LZtG6qqqkTnufnmm9G8eXNXLlMTiOM8CF+B9A9BEIT7cNm9NXXqVHz22WdYsWIFTp48iUmTJqG0tBTjxo0DAIwZMwbTp0/n27/88svYsGED5s+fj1OnTmHWrFnYt28fJk+eDADQ6XSYMmUK3n77bfz00084evQoxowZg9atWyMlJQVAreBp164d/v3vfyMvLw/Z2dmiWJ0nnngCRqMR48ePx/Hjx7F69Wp88MEHmDp1an3uj9dgFOjhM1AgM0EQhGfwc/WAUaNGIS8vD6mpqcjOzkafPn2wYcMGPmg4MzNTZIUZNGgQVq5ciRkzZuCNN95Aly5dsHbtWvTo0YNv89prr6G0tBQTJ05EQUEBhgwZgg0bNsBkMgGwWWzOnj2Ls2fPom3btqLxcK6BsLAw/Pbbb3jhhRcQHx+PiIgIpKamYuLEia7fFQ1Aq1D4JqRvCYIg3IeOUUABT1FREcLCwlBYWOj1+J7fjmdj4pf7AQCzH7gFYwd18Op4CPfx6bZz+Of6UwCAt1N64C8D2zdo/x2m/cK/vvDuiAbtmyAIQgs4O383uuwtX0Hs3SJd2pSh+C2CIAjPQKJHo5DO8VHowRMEQbgNEj2ahZah8BUofosgCMIzkOjRKCKXB82ETRp6vgRBEJ6BRI9GoW//vgNV3yYIgvAMJHo0itjSQzOhr0DPmiAIwn2Q6NEoVKTOd6DsLYIgCM9AoqcRQF/+CYIgCKL+kOjRKCR0fBN67gRBEO6DRI9GEQcya2cmPJNTjD/OXPP2MJoUwjge7TxpgiCIpofLa28RnkE0EWpoJrznP9sAAL9PHYrOkSFeHk3TgILWCYIgPANZehoBWpwGz+aWeHsITQYtPl+CIIimCIkejaLF4oRkhSAIgiAaMyR6NIqoYJ1GbAFVltpx6HReHEgTQ4sClyAIoilCokejaHHyq6i2eHsITRItClyCIIimCIkejaLFb/+VVVb+tVbG1NSg+0oQBOE+SPRoFC3OfRVVtZYes8Wq0pJwBRI6BEEQnoFEj0YRp6xrY1asrK4VOpVV5OpqKGhxWYIgCM9AokejiCZCjcyEQktPRTVZetyBVp41QRBEU4REj1bR4CKUZOlxE4wCmQmCIDwBiR7CaYRCp1Jjlp6rheWNtmAiyRyCIAjPQMtQaBRRGrNGZkVhyrrWRE/i3E0AgP0zktAyJMDLo3ENLWbqEQRBNEXI0qNRRBOhRmwBwpT1So3W7LlwvdTbQyAIgiA0CokejaLJQGahpadKW5aexozYqqeRh00QBNEEIdGjUZgWA5lFlh4SPQ0F6RyCIAjPQKJHo4hcWhqZFStEgczadG9p5FbVmcY+foIgCC1DokejaNHSI6zNQ5aehoOKExIEQXgGEj0aRYuTn8i9paGYnsYeB6Pl7K3cogoUlld5exgEQRANAqWsaxWm9ZR17bi3tGgVcwWtZOdJuVFqxoB/bgQAXHh3hJdHQxAEUX/I0qNRxC4PbUyKWg1k1sbdaRi08qwB4GR2kbeHQBAE0aCQ6NEoWnR5aLU4oVUrN6iuaPBZA4AOOm8PgSAIokEh0aNRRKuse3EcQkTZWxpae0uLAtEVtBrIrCPNQxBEE4NEj0bRYnHCSo1mb2nJJVRvtPKwCYIgmiAkeginqWwElp7GiFazz4SGHq2OkSAIwhVI9GgUTa69pVVLj8i9pY175QpazT7TCfxbVi0NjCAIoo6Q6NEoTPGN9xBXZNaQ6NHKDaojWnRlSmn0weIEQRAg0aNZtBnIrM1V1puSFUKrAs7SlG4yQRA+C4meRoBWXDZmgXWnysI0MxFqUSC6gkYerx3C7C2tjpEgCMIVSPRoFC2mYUtdHGaNuLg0cnvqjNC6o5VnDYgDmcm9RRBEU4BEj0bRoptDs6JHG8NoELT01IWWHguJHoIgmgAkejSKFjN6pPOeVr79a1EguoIWrXpSmpKwJAjCd6mT6Pnwww/RoUMHmEwmJCQkYM+ePart16xZg65du8JkMqFnz55Yv369aD9jDKmpqYiJiUFgYCCSkpJw5swZUZt33nkHgwYNQlBQEMLDw2XPo9Pp7H5WrVpVl0v0OlrM6JGKHK2IHmsjEA2NE2HKOt1YgiAaPy6LntWrV2Pq1KmYOXMmDhw4gN69eyM5ORm5ubmy7Xfu3InRo0dj/PjxOHjwIFJSUpCSkoJjx47xbebNm4eFCxdiyZIlSE9PR3BwMJKTk1FRUcG3MZvNGDlyJCZNmqQ6vmXLluHq1av8T0pKiquXqAm0WKdHOgptjMr1QO/VezOx6VSOm0bjOuJAbK3cVTHk3iIIoingsuh5//33MWHCBIwbNw7du3fHkiVLEBQUhKVLl8q2/+CDDzB8+HC8+uqr6NatG+bMmYN+/fph8eLFAGz/8BcsWIAZM2bgwQcfRK9evfDFF18gKysLa9eu5fuZPXs2XnnlFfTs2VN1fOHh4YiOjuZ/TCaTq5eoCbQY3KpVS48rK9KfzS3B698dxTPL97l3UHVFG7e0htrBaOVZEwRB1AeXRI/ZbMb+/fuRlJRU24Fej6SkJOzatUv2mF27donaA0BycjLfPiMjA9nZ2aI2YWFhSEhIUOxTjRdeeAEREREYMGAAli5dqmoFqKysRFFRkehHK2hxjrFK4jq0MkbhhOxoTLnFFeoNvIBWFxwV3kvpsycIgmiMuCR6rl27BovFgqioKNH2qKgoZGdnyx6TnZ2t2p777UqfSrz11lv45ptvkJaWhkceeQTPP/88Fi1apNh+7ty5CAsL439iY2NdOp+n0EqdHily3/6PZxXi//2R4dkaPsLJWaP3Sg2tDtnayO8rQRCEFD9vD6AhefPNN/nXffv2RWlpKd577z289NJLsu2nT5+OqVOn8u+Lioo0K3y0gHTik5sHRyz8AwBg8tfjyYT2nhiWyDriSGvpRNVntIeWBK7weZPoIQiiKeCSpSciIgIGgwE5OeIg0JycHERHR8seEx0drdqe++1Kn86SkJCAy5cvo7KyUnZ/QEAAQkNDRT9aQYtVhl2J6TmR5TlXodi9pX63tBgorMX4LUAiesi9RRBEE8Al0WM0GhEfH4+NGzfy26xWKzZu3IjExETZYxITE0XtASAtLY1vHxcXh+joaFGboqIipKenK/bpLIcOHULz5s0REBBQr368gRZrt0jHocVxaWVMrqDFmkwAGr3bkCAIQorL7q2pU6di7Nix6N+/PwYMGIAFCxagtLQU48aNAwCMGTMGbdq0wdy5cwEAL7/8MoYOHYr58+djxIgRWLVqFfbt24dPP/0UgK22zpQpU/D222+jS5cuiIuLw5tvvonWrVuL0s0zMzORn5+PzMxMWCwWHDp0CADQuXNnhISE4Oeff0ZOTg4GDhwIk8mEtLQ0/POf/8Tf//73et4i7+BKRpKnkLqOtDIRit1b6mPSvnvL2yOohWJ6CIJoargsekaNGoW8vDykpqYiOzsbffr0wYYNG/hA5MzMTOj1tQakQYMGYeXKlZgxYwbeeOMNdOnSBWvXrkWPHj34Nq+99hpKS0sxceJEFBQUYMiQIdiwYYMo3Tw1NRUrVqzg3/ft2xcAsHnzZtxxxx3w9/fHhx9+iFdeeQWMMXTu3JlPr2+MaNF6IXUdaWS9UVitdXMPMcag03lfBGnkNtpBMT0EQTQ16hTIPHnyZEyePFl235YtW+y2jRw5EiNHjlTsT6fT4a233sJbb72l2Gb58uVYvny54v7hw4dj+PDhivsbG6I4Dy+OQ4h9ILNWRlaLK5MzY+L1pbyFFgtRAq4FiBMEQTQGaO0tjaJBPWE3HWtlIhTVk3FhTNqxXjSCQGYtDYwgCKKOkOjRKJpce8uqTUuPeEJ2fkxaEW1aRfh8PVp3iSAIwk2Q6NEqdZzI3Yn9KuveGYeUurphtGK90Mgw7NBiXBlBEER9INGjUbRo6bF3b2ljYKyRu2HE4kI746fsLYIgmhokejSKFr9lO1OR2RtYXbhXwsBlLU7kWhqRldxbBEE0MUj0aBRx9pY2JhytrrJe19XAPTmPF5ZX4an/l47vD1y226fVisxiC5oXB0IQBNFAkOghnEY68Wllgq6rVcyTrqQPN5/F9jPXMPWbwzLj8NgwXEKrbjeCIIi6QqJHo2jRvcUZJAx6m49IK5aeusaeeNJ6UVBmVtynxerbgPj+kHuLIIimAIkejaK93K1aQWHQaUv01NU9pEXrhZaGZCX3FkEQTQwSPRpFi5YebhLkVhnRyLAkxQm1aelRQ6sLjoozCLU0MoIgiLpBokejaDGQmRuFX43q0cpEKBQ6jdHSo5XnK0VUnFAj94ogCKI+kOjRKhrzbzHGeEFRG9PjxQEJcGXtqrouWeEptKQtyL1FEERTg0SPRtGY5hFNxrzo0chM6IqQYSKrkDbGL37AGhkTAKtV8For94ogCKIekOjRKJqZkGsQjkav05ilx4U6PVoTk4A2q28DkuU9tPKwCYIg6gGJHo2itRopQjHhV2Pp0UosiitB31pcOZzVMSbJ3ZB7iyCIpgaJHo3irEWCMeaRGirCCZBzb2llgra64LLSekyPlmjsa5oRBEFIIdGjUZy1Xvx1xT4M+dcmVFRZPDYerRUnFLlhXLH0eFD16KBT3KfV4oQigUgKkSCIJgCJHo0iTllXZuOpXFwtrMDOc9fcOx5Z0ePWUzqNK65Ajeg0EVqsyQRIK117bxwEQRANBYkejaLlmB7NWXpciD1xJejZG2hpRFqMfyIIgqgPJHoIpxCJnprsLa3M0GL3lvqgxGnY7hmPq2hkGHa4cl8JgiAaAyR6GgGenG7WH72KX49nq45Be5YeF9qKjtPK+LWZvUWBzARBNDX8vD0AQh7RhOzEfNMQc1JheRWe/+oAAODUnOEw+Rtq+xdYSPwM2orpccUNo8U0bK0GMguDl4UWMoIgiMYKWXo0ijcmwtLKav51ZbV4lhOKBb3WVll3qSKz8LU2xi9CQ0MS3ktae4sgiKYAiR6N4u2MHp0kw1rOvaUV0eBSRWYNWnq0JHSEaNEVSBAEUR9I9GgUUcq6E/ONVKQ0NHKBzFqZB12ryCxoqxG14Wx5gjr1XY+HpEmBSBAEUQ9I9GgUV1YOl7Zv6PMDtaJHr6sVWFqZCF2q0yO0CmkwTqWhLSr16U4odD1R9ZsgCMLdkOjRKM5MMW51OUi65k6l0+mciuk5llWEXeeuu2t0IsTuLfW24oJ72pjIXYxZd63v+hyr9fgngiAIFyHRo1Gccdm4cx6SCgLurdjSozyAw5cKMPqz3cgtqnDXEHmsTtyr2v3am7zdql3r0bkokJksPQRBNAFI9GgWx3EeDW2pEMYFSfvm3gstPc6Q7QHR40o9GaZBS4+QBndT1uNYLab3EwRB1AcSPRrFGUtPQ09EaqnfvOiBc5YeT+JKlpErrjBP4d5A5obpRyvPmiAIoj6Q6NEo4jlGfsJp6Owj4cQmFQ+17i1BTI8kENhbriNRRWMHbcXLUGhjIndn7Ex9PiOi4oQauVcEQRD1gURPI8BTMT1qlh5hTI9ewdLjrXnRFZeVWNi5a0SuwRReN0jf9crekn9NEATRWCHRo1Gc+Ybe0N++RYJAcn5hTI9OoU6P3Hg8ISxcmZy9VXDP3XWU3AGtsk4QRFODRI9GcSaN2ZWsJVfPqRjTI7D0SIWRt6ZFVxbs1GLBPeZGU4/0frgi9IQtrVq5WQRBEPWARI9GccYi0dCWCtE3e6u8oNELLD1KwsjTuBTIrMnaM8oWtvr3XHcXpBYFIkEQRH0g0aNRXLX0NARqliNuAtRmTI/zbhgtxKmoiS13V9Z2pXtybxEE0dQg0aNRnFl7Szh5NkTMiJp44ASCuCKz9HiZPus/LIe4tMq66L56ZyJ35r41FNKuXXJvCe8rmXoIgmgCkOjRKl6I6VFbokGuIrNdWrvMSD0hLMTuLdsEvfl0Lq6XVNq1tTpxX92N3b0Vvm5wS0/d4660YBUjCIJoSEj0aBRn5hhX6tM44nR2MX45ksW/Vw5kVsvequcg6ojUDbNq7yWMW7YXwz/Ybt9YAy4be0Hpzpgeyfs6x/SQ6iEIovHj5+0BEPKIM5LkJxyxpad+k1Lygm2K57edq0b0AIoLjnqvOKF4DBuOZwMA8orVLT3ei+mp276GOJcr4kW0yjqJHoIgmgBk6dEorlp63BnUbDuX7betIrN8G7kxeCSmx4XzaSE4V8291eDUo3NnlkIhCIJoTNRJ9Hz44Yfo0KEDTCYTEhISsGfPHtX2a9asQdeuXWEymdCzZ0+sX79etJ8xhtTUVMTExCAwMBBJSUk4c+aMqM0777yDQYMGISgoCOHh4bLnyczMxIgRIxAUFITIyEi8+uqrqK6urssleh1X195y9/IF4orMnHvLcWqQJyZLqRtGLabbnTVxnEUtkLmhh1SflHWRVYyCegiCaAK4LHpWr16NqVOnYubMmThw4AB69+6N5ORk5ObmyrbfuXMnRo8ejfHjx+PgwYNISUlBSkoKjh07xreZN28eFi5ciCVLliA9PR3BwcFITk5GRUXtCt1msxkjR47EpEmTZM9jsVgwYsQImM1m7Ny5EytWrMDy5cuRmprq6iVqAvHcLD/huHPxTOm6WqKYHsk2aRshHglkdsFlpUVLjxD3p6yTe4sgCN/FZdHz/vvvY8KECRg3bhy6d++OJUuWICgoCEuXLpVt/8EHH2D48OF49dVX0a1bN8yZMwf9+vXD4sWLAdgmxQULFmDGjBl48MEH0atXL3zxxRfIysrC2rVr+X5mz56NV155BT179pQ9z2+//YYTJ07gv//9L/r06YN7770Xc+bMwYcffgiz2ezqZXodZ6oMizORGnZSUhI0Oh0UA5nlRmDxgIVAmt7v7Bm9FtMjXahV5V29zyV9X8fuSfMQBNEUcEn0mM1m7N+/H0lJSbUd6PVISkrCrl27ZI/ZtWuXqD0AJCcn8+0zMjKQnZ0tahMWFoaEhATFPpXO07NnT0RFRYnOU1RUhOPHj8seU1lZiaKiItGPFlEUPaJVsN17Tu6tekyP/SA8ISyEVilHliW1leQ9hScDwOuXsu59qxhBEERD4pLouXbtGiwWi0hYAEBUVBSys7Nlj8nOzlZtz/12pU9XziM8h5S5c+ciLCyM/4mNjXX6fO7GuUBm4Wv3WnrEFZmVsrfkxugJS08tjiZnV1xhDYn4vB50b9n1X0f3FsX0EATRBPDp7K3p06ejsLCQ/7l06ZK3h1SLE64rd34TV6vIrFic0AVLT0OKIakrUC2Q2Z3B32o4G3/V4IHMTrggnTmWNA9BEE0Bl0RPREQEDAYDcnJyRNtzcnIQHR0te0x0dLRqe+63K326ch7hOaQEBAQgNDRU9KMVnFqGQvBaGnhcX5QyjIQxPXZtZPqRC4D9eMs5DJy7EZfyyxpgpPaTs9r8LBaKDXJ6p1CzyrnTYtdQ2VvaWZyVIAii7rgkeoxGI+Lj47Fx40Z+m9VqxcaNG5GYmCh7TGJioqg9AKSlpfHt4+LiEB0dLWpTVFSE9PR0xT6VznP06FFRFllaWhpCQ0PRvXt3p/vRCs6kMbvT0qNUnFAY0+NM4Tu5bf/acAo5RZWY9+vphhlrHdfTaujgbzXUiiKKxt/QJ7bzb7lwKLm3CIJoYrhckXnq1KkYO3Ys+vfvjwEDBmDBggUoLS3FuHHjAABjxoxBmzZtMHfuXADAyy+/jKFDh2L+/PkYMWIEVq1ahX379uHTTz8FYLMaTJkyBW+//Ta6dOmCuLg4vPnmm2jdujVSUlL482ZmZiI/Px+ZmZmwWCw4dOgQAKBz584ICQnBsGHD0L17dzz11FOYN28esrOzMWPGDLzwwgsICAio523yPM7Uk2nIZSikcHNcudmCQKPByYrM6mO0P0fDjNrZeBnAvcHfanhrSQfpmepakZk0D0EQTQGXRc+oUaOQl5eH1NRUZGdno0+fPtiwYQMfNJyZmQm9vtaANGjQIKxcuRIzZszAG2+8gS5dumDt2rXo0aMH3+a1115DaWkpJk6ciIKCAgwZMgQbNmyAyWTi26SmpmLFihX8+759+wIANm/ejDvuuAMGgwHr1q3DpEmTkJiYiODgYIwdOxZvvfWW63dFA4i//SvF9AjaK0xmezLysePsNbx4V2f4GZw37DFmW7Rz3LK9mHrPTejfvjkAqaVH3hok2tbAbjc5XFlEVKQlPSg+1Kxy7qx83FAxPeTeIgiiKVCntbcmT56MyZMny+7bsmWL3baRI0di5MiRiv3pdDq89dZbqgJl+fLlWL58ueq42rdvb1ftubHizBzjTKDpY5/Y0v4jmgXgqYHtnT6/lQEzfrAVkHw/7U/8d3wCAAcxPTJjUCtqpxZw7AquFGkUp6w30ACcwKoibDxbkdkVS0/taypOSBBEU8Cns7e0jNgiId/GlZie83klrp1fJaZHpxNvUxun5ysyq5/PlbYNiaqlp44xSc5QP0sPubcIgmhakOjRKK4HMjvfnzNYGXhxIzyXTrj2lvQcMiNVG5dO59jW89bPJ5Dy4Q5UVlsU2zAXTCXemsi9Vh9IZRyuHEvFCQmCaAqQ6NEsjr/9e7Q4Yc1vcUVmqTXIcT+usnRHBg5dKsCvx3MU27gyOYuzqDRi6XHjMOwrMtcxkJlMPQRBNAFI9GgUZ4wXDRUAK19UkIksPXIVme1jU+z7UUt1diWmp6JK2dIjzshiqgJQNOl7NKZHWcQ648qsK3b9udC/twQiQRCEuyDRo1EaOqZHVQjIxuIAOoEs4bOwdDperUi//cvpm4aaK6stakLG+fN5z9Ij/1qKu2sHUUwPQRC+DImeRoxLMT0q++Qyc5TdW8oxPXJbGkpYVKvkvkvjZdRihbwWW6MmUN3q3lJ/7+yx5N4iCKIpQKJHozhTeNCVZQLUdiutji4XyOx6TI/yeZ2IY+apUrH0uLJyuvi+esnSI9Fvziw5Ulek11j34oQkegiCaPyQ6NEooilGccJpmElJKdVcJ3kPiCsyO2NFaCgLQbXFuSqHDA5ceYLXnjReOCsgtFSckCoyEwTR1CDRo1GcS1mXfy3bn8p0p2zp0YneA1ydHvllKJxde6suVKmIHldq7whFmGcrMte+Vi9O2LBjsotjduGavVXTiCAIwl2Q6NEoTgUyiyZwB/2purfk2ktiemreCuKYnUq9VnVvKe+yw1n3luOKzILXHjRfqMX0uHMUaiu6O4KytwiCaGqQ6NEozsSeuDIpqQYyy0z+ViYWJeKYHnn3VkNbeoT3QDWQWeEY+baOY6XcgZrVRPSsGzympx7Hiur01H8sBEEQ3oZETyNAaSJsqOULlOr0QLEiM7fNcd/1ET3C/tUsPdJ6RVrM3nLWGtXQQ6pX9pbgNa29RRBEU6BOC44S7seZOcaVCdxV95aSWNHrdNDrOUuPEzE9asUJHaRvCftTi+mRBgnr1ESFC5leDYmzxQkb3vwkPZfzJ3AlK44gCKIxQJYejeJMGrNrKcWuBTJLDD0iS48rC47Wx5oidLupFScUn89BILNKQLE7UQs6d2sgcz0sPaJV1il9iyCIJgCJHo3S4NlbapYe2ZgeJs7eqjG06HQ6vlKz9LCGjukRHqtenNCFgO4GSvN3FdXihO48r4P3qsdSyjpBEE0MEj0aRRynIj/jiFcXdxDA67J7S2zp4ZroBTE9ztSAUZvgHWVvORvT44r1xhWh2JCoBZ2LA7Eb9rz2lh7nT+DMZ5AgCKIxQaJHozjj5qhLUG5JZTXGLt2Db/ZeEhwr595iKhWZ5WN65AOi7ft1FqFLpaHq9HjL4mJVs0aJMvUaFvuKzOL9hWVViq4r4ZgpkJkgiKYAiZ5GQEPE9HCT32fbzmPrn3l47bsjqsfaYnp0gvec6HE1pkd90lXD6mRMjytp6N6au5239Lg3pkd4tvN5Jej91m8Y/dlu2WNFny9KWScIoglAokejODP31cVVU1he5dS5lMVKraXHPqbHvh9p3yKrggP/lvPZW/LH2M4vvQ7hRO6tmB6PnVY1kPnb/ZcBAHsy8h0eS8UJCYJoCpDo0Siib/8K9gtX0q/VdisWJxSIEu54dUuPfT/Svl2ZPIUuFbPa2lsqgkJt0tfK2lvOBK3XFelnx7VA5trXJHoIgmgKkOjRKk4E5zqqyCxapqLmt1xpHGeyrmRjelTGo9SPK6nPQpeKudq5iszSm6XmXnMmbupqYTlGfbIL/zt61WFbNYTXYl+nRyXep56oiT5Hp6IFRwmCaGqQ6NEocnEqf+YU44HFf2DzqVzbdgeTklzwrLO1dJSClHWi7C3lyVupb6H1RufAvyUcf6WK6FGbnO0sP3BtIp/103GkZ+Rj0lcHHDdWwdn4GLkhXbhWio0nc+p1/tr+nRdYwt1k6SEIoilAokejyKULv7L6EI5cLsS45XsBOE7VdjbjRinrSlinh2shWmVdMnnLnc4upsYFk4HQKlRZbVFsp+aGUXUlOXF/8kvNDts4g9oYHQ3jjn9vwfgV+5B+/nq9zit9r2bp2vZnHvZfvMG/92T8E0EQhLsg0aNRmMzrkspqURtH2VvOTnBy4sjKmLgis7XW0uNK9pbUneWSe0to6alydsFR5T5s+9XvmbtQs0YxtQsQcPhygcvntYvpcfKSxyzdI3pPKesEQTQFSPRoFHHhQdsvk59B3EapfQ0Wq30fsjE9MnpCGshs5Y9Xy95yzb3lKKZGeKzz7i3lGB7pe0/O486uvSUdkrCtv8H1P1c7Sw/sPxPOQCnrBEE0BUj0aBS5+chklIgeV2J6VM6lVJxQro2wIrO0V7lz2Lu3hK/VZ11n3VtqQd9q7i5njE6O4o6cxdmsMen4y8y1110n0eOgf2ehtbcIgmgKkOjRKHJZNiY/8eNy5N5y9tu5fCyO2NJTbeVEjyCmxylLj8S95YLoqFsgs0SISeOOhK+dUABq1qizuSU4n1fisA/peZ1J9ecQ1lWqi+ywD0ivQyeoff4EQRCNGT9vD4CQR25yNvmLLT0iq4kjSw+XfSVjuVCO6altW11TJ8eWvaXj2ygOmutbIjqE1h1HcSLC/lVT1lU8NmoCoz7TeLnZgqT3twIA/nz7Xhj91L8/OFs9WyqyhKKn3Fwtbe4QO0uPC9WrhVD2FkEQTQGy9GgVmcnZ5C9+XI6cS3JWFfm0cvlYHKGlh1vwUyeQQnWy9AgOcs295Vwgs5plCZC4mZywXii5twrKa7O6KtRcbzLjUtMP0n1C0SN0dTmLUvaW1coUr1/O8lStVhzSTey7kI/B727C7ycaJl2fIAiCRI9GEVt6bL8DBZYexpjD2i/OLhgpn7Iu3lZdcwK9DtDr5Y9zJmXd4qTFAxBfk8XKFCdeqaBQD2x2LaZHCXHqu+P2Yquc8n2T9lVQVj/RIyeNrVaG+xZux+d/ZMiPVdZqWIdT15On/t8eXCkox1+/2Of5kxME0SQh0dMI4KwzQvdWRZXVYfq1s0HDSsUJhTYOztIjXmVd2o+8xUg8JoEQc2A8kPanZO2R1t4RVz9WbutIdGVcK5VdqwyQWJecUARqQedqLqcikaWnDu4tu+tnuFJQjlPZxYrHVMsoaLlt7qa8qi4ijyAIQhmK6dEocvNxgCBupKSy2uGCoyJLD1dnR8ZdIzdpSzdxq5zb6vTIx/TITf1SC5Mrlh7psZXVVgQHqB4Cq0NLj/rxHJnXy3Dnv7con0e4ArwTnaoviqp8XL3dWw7eyyFrNaSUdYIgmgBk6dEocssFCCfOMnO1w+rCovgZlZlVKZBZeD7um76tTo9t285z17HuSJbqGOzcW06OCbAXY0orrUtFjnohQOfOv+eC/MrjcmNxJp1brU6P0vgAieipbJiYHrlaTcLzyll1qDghQRBNARI9GkUuzkM48dgsPeoTuHCT7ErqNdvk5jOpxYSb5PU6sbVo8sqDsuerPYfye0diQbpbSfRI75XIqiLpROSWqsdEXm1VFwlS1KxyaqMQiZ46uHvsBRYTLS/CIQ4wt+/HYmVOpfgTBEFoGRI9GkVeQNRuLDNbHKZfW0Tf3mUsQTX7lYoTCidCcUyP/JidWmXdFfeWnaVHvr3YKia19EjdW/YWtLogFGDVCuPKLqzAqewiflxKY2IqYypo6JR1Ju/OFD4XJasOleohCKKxQzE9GkU4v3CTolAEuBrTIycwLFYGf4NSILP4GGGdHjlLgW3M6pOp9BocW3qcdW+JX6taVRzcM2cRCh2lmJ6BczcCAP54/c46Z40JLT2lDeDesjIlq1/tayXLVbXVCoPeILuPIAiiMUCWHo0iZ8URCojSymqH8SnC/XITHbdNPpBZYukRVGR2xdKjluHlSkVmwEn3FsT1Z9QtPQ3j3pK7t8K+z+SUSNb8Una5SYVjhSB4uS7ZTPYLjjJVqx+gHLRMwcwEQTR2SPQ0IkTurUqL6kQKiFPCZeM0VNxbViYWE1XV9hWZpThT76euxQkBZfeWUDZIY5HUhI2ae83RilvCmkFylhFhen2Q0SCpqaQc1CMdkrDv0krX3VtS4xuDugCWnlNpLARBEI0REj0aRS6QWfgN3S6QuQ7FCS0WTvTInZ+J4zwEKe8KmkcxIFr03oVlKKS7Fd1boro8TNW91VAxPY4sPUUVtW6pAH+D8wuOSt4L+y5viJR1RfeWtiw9dblWgiAIR5Do0SjignX2FhlpyrpSzA6Hq4HMyu4tFUuP3BIXkvO6suCovaVHwb0lSe9Xc+s5Wq+stk91RIHMcqKnvNYqY59Gr+zekiLsu6zKImu5EgosKXYp62CyoqfaCTHqKUvP2dxidEvd4JFzEQThW5Do0SiyKesiS4/F4eKRIlFktRc4tSnrzru39HplS48ja5P0Ghy6t+xieuTbS8WfWi0gaaZXXREGMjuy9FisTNXCJM7eUr5fFiuzq0q94Pc/0WvWb6J6SaK+ZfxbSnWZas8jL248Vavn023nPXIegiB8jzqJng8//BAdOnSAyWRCQkIC9uzZo9p+zZo16Nq1K0wmE3r27In169eL9jPGkJqaipiYGAQGBiIpKQlnzpwRtcnPz8eTTz6J0NBQhIeHY/z48SgpKeH3X7hwATqdzu5n9+7ddblEr8NkXgsNHUUVVY5jemQsHhaZb/RyBhSpeOCLE0LN0iPfj9J7R9lb0muqUliGwj57S1lgiO6ZyrkdxvQIhIFcynpxRbVov5pVTu5Z155HvEXq9lnwu+3vZMbaY7LjtLf0yIsasbiS7cqpIowNgdLniyAIor64LHpWr16NqVOnYubMmThw4AB69+6N5ORk5ObmyrbfuXMnRo8ejfHjx+PgwYNISUlBSkoKjh2r/Sc9b948LFy4EEuWLEF6ejqCg4ORnJyMiooKvs2TTz6J48ePIy0tDevWrcO2bdswceJEu/P9/vvvuHr1Kv8THx/v6iVqArnaLcLJsqi8ymEmlJxLRVS7h4/psT+YSSwC/CrrgrW3+L5lrEgc0glUFFztsE6P+L2Se0VozbAydYEBtX0uUOXI0lMutvQ4nSov2Sftu9TFWj3yMT327ZwJZPaU6FEqiUAQBFFfXBY977//PiZMmIBx48ahe/fuWLJkCYKCgrB06VLZ9h988AGGDx+OV199Fd26dcOcOXPQr18/LF68GIBtcl+wYAFmzJiBBx98EL169cIXX3yBrKwsrF27FgBw8uRJbNiwAZ9//jkSEhIwZMgQLFq0CKtWrUJWltis37JlS0RHR/M//v7+rl6iBrG30hSWVzmM6bFa7Sdmi8VeCCnF9FhlJkK9zn4ZA94aITMn1mcZCqk7xayUvSUxlaiJwfqssq60VIOcSBC6t6qtVvWYHpVxSPtWWnRVCfv0eCY7XkdB8UDDiZ4KB6n3pHkIgnAXLokes9mM/fv3IykpqbYDvR5JSUnYtWuX7DG7du0StQeA5ORkvn1GRgays7NFbcLCwpCQkMC32bVrF8LDw9G/f3++TVJSEvR6PdLT00V9P/DAA4iMjMSQIUPw008/qV5PZWUlioqKRD9awZGrqKhCWqdHrn3ta170yLiX5CZdJhEPVdW213qdfUyPRcXS4xn3llhQqFV9Fr5TE12OAsOFlh5H7i37mB57ISI3PkAsUpXOZetTdrNdf0rFCT1l6TmeVYiub25A6o/y7jgAinWgCIIg6otLoufatWuwWCyIiooSbY+KikJ2drbsMdnZ2artud+O2kRGRor2+/n5oUWLFnybkJAQzJ8/H2vWrMEvv/yCIUOGICUlRVX4zJ07F2FhYfxPbGyso1vgOUTxOrbfwknH5t4StlGfyPhMLRlLi2wKs132lnKdHq5veaGmPCZH3iXpuJTdW+LziTK0pNlboghx5XPLiR7RelsOKjJL3VuOqmfzQ2LSa5YIP6WAG8UO7ftXet5yr4U0hOjhYpC+2HVRsY3OYUQVQRBE3Wgyy1BERERg6tSp/Ptbb70VWVlZeO+99/DAAw/IHjN9+nTRMUVFRZoRPkzmtb3oURcQcqnbcutxKRUnFM5x1SoxPRaV2CBVS4/DmB7n3Fvi4GSmagETiw/l88sJGdGyHAJl5Sh7S9qXmnvLztJjJ/xcEx52FZkhnzUn1FKKgcweyt4i9xZBEO7CJUtPREQEDAYDcnJyRNtzcnIQHR0te0x0dLRqe+63ozbSQOnq6mrk5+crnhcAEhIScPbsWcX9AQEBCA0NFf1oBbk0ZuFkWSix9Mi6Y2TS0+XWvlISTHJrb9nq9IjbcgJArh+1lHWLleFSfhku5ZfZHyjTn5J7SypyVO+LExYN6Tg5hIJD5N6Si+kR1OmRWmfsCjLLWPXkzgmIK0E7g90l1sO9peRacwVn9AxlbxEE4S5cEj1GoxHx8fHYuHEjv81qtWLjxo1ITEyUPSYxMVHUHgDS0tL49nFxcYiOjha1KSoqQnp6Ot8mMTERBQUF2L9/P99m06ZNsFqtSEhIUBzvoUOHEBMT48olagZHlp5qK0NZpbgAnhSRpUa2To/asfLFCeUqMv+/PzJwKb9Mvt6PXfZWbZvSymrcNm8zbpu3WdZtI7UsOOPeklaStrc0CdvKdmc7l8wELw4MV7f0FAssPWaJWHOlPhDXt7/BdtOVl+KQxz55zQn3llJF5gaw9HjGVkQQBCGPy+6tqVOnYuzYsejfvz8GDBiABQsWoLS0FOPGjQMAjBkzBm3atMHcuXMBAC+//DKGDh2K+fPnY8SIEVi1ahX27duHTz/9FIDNXTJlyhS8/fbb6NKlC+Li4vDmm2+idevWSElJAQB069YNw4cPx4QJE7BkyRJUVVVh8uTJePzxx9G6dWsAwIoVK2A0GtG3b18AwPfff4+lS5fi888/r/dN8gZy3/6l892NstqJVTaQ2UH8DicilIKglSw90pTij7acw7IdFzD9vq4y/Si7doTjL6+ywN8g1uDOrr0lTe+XS/fn30vW6VLCpUBmWfdWtWxbpb7lxmfr23bfTX4GVFmqXa6KbGfoYQpLklgZNp7MwcKNZ/BAnzaifTqd7ThXXWt1hSw9BEG4C5dFz6hRo5CXl4fU1FRkZ2ejT58+2LBhAx+InJmZCb2+dvIaNGgQVq5ciRkzZuCNN95Aly5dsHbtWvTo0YNv89prr6G0tBQTJ05EQUEBhgwZgg0bNsBkMvFtvvrqK0yePBl333039Ho9HnnkESxcuFA0tjlz5uDixYvw8/ND165dsXr1ajz66KMu3xQtILekg7SoXGG5uba9g3gaueKEcrV7hPvkYnr0evuYHsAmWpRWa6+2WJF2IgfxHZorxovIWVak1yS1mNS2Ux632jIUahYXuQl+ydZzeP6OzmgebHRYkbmkwhX3lrJI4/oO8DeguLJa0cVUXFGFE1lF6N5a7KK1yxRTcm8xhvEr9gEADl8uFO3z1+thtlgdVtB2BmfkDGkegiDcRZ0CmSdPnozJkyfL7tuyZYvdtpEjR2LkyJGK/el0Orz11lt46623FNu0aNECK1euVNw/duxYjB07VnnQjQyxpYcTLOI2BQ4sPXLxO3KVd+Umf+nkaBacXCmlWG5KtDLgq/RMzPzpOCKbBeDFu7vIHisXq6KWvXX5Rhm+2XsJYwZ1sCv85+w6V67G9Hy2PQN/5pRgxTMDJHV67NsK75e96FEek1JMj8lfL9tXbZ/AfQu3Y81zibi1QwvZvrn3jlx3UvwMOpgtDZO95UwPlLJOEIS7aDLZW00NuYwe6cRUIEiLVlo/S/paON/x9XUcBLYCtZOvXiZ7S+58tdsYfj9pC1LPLa5UnFzNsjE94vdCN9ETn6UjM78M+zNvINgo/hirpcWLrCqyI7GhZFHZ+mee3VgsMmMXWqWk1+ZsaIzVWlvJOdDfAABYvPksKqut+L/erWWP+eXIVbHokbl+OcuemuvKr0aF0DIUBEE0dmjB0cYAL1jEQa2OLD1yFYTlqjTLHfvTYXGlawsvepSHKVdp18pqJ01hP1JcdW9l1mR87Th7XTXNWy2mSG0Od5SeXe1glXWh0JFem1T4KZ1K2K+pRvQcuVyIF78+qDgu+2dgb1WSDWRWuRlGP9u/CU+lrFOZHoIg3AWJHo0idGNILT3Ng4wAgGsllbVtHKas12yTK1jowmSmZukRjqf2vAwGQYyX0rnkAnSdLk4o6bJMsCinenq4mntLOWD42/2X8fkfGYJx2fdTperekoxJYeV3i0j0OPenKl2mQtbSoxDTo4RfzfPzVCCzO1K88kvNLmXNEQTRNCHRo1GElgI+pqfm983RzezaK2VgcVgkfQBQXShUCZ0O0Ct8aq6VmO22WRlzytIjl5klnYi5pTCkqE1mapYe1ZR1lQn+72sOi97LXVOVinvL2eKEQpHHWXocIbX02MX0MPnxqrmu/Gosi2rWoNyiCtw1fwsWbTzj1DjVaGhxtf1MHvrNScOcdScbtF+CIBofJHo0ilymEjcxxbdvbrfP2QVHnXVvKSFXkZkjr7hCZlyAwVDbXmlCkwvQtStOKNNGp6ud2EfGt7U/v9SVJHj9x9lrstYpwH7NKzXkXHNqa3M5a3EQCpEAP4PiPiEOLT0Kx6oJX66UgJoYmb3uBM7nlWJ+2p+KbaQo3YeGjh1asvUcAGDpjgwHLQmCaOqQ6NEoQtEjdW/1aycneuz7sLNyWJl4/ag6WHr0OuWQCzlLD5NYeoQLcQqRtfRI6/QoTIbc5BkTHmi3T829BQDDF2yT7dOV+BWpK4wx5iB7SzImhfEJ70mAxL2llMVlb+mxtyrJiQqzghUNqI3JUrP07MnIV9ynRP+3f8fGkzl2211eX8wBnVqF8K8drfBOEETThkSPBpGKk9rihLYXLYKNiIsIFh3jaMFRwCZy5NK5XQl10MG+OCFHXrG91US62KawtpBobE6krMstQ6FDrYiQi3uxdyWJ38sJNblzq2G/KKj0vSvuLXtLnJ9eB39JBLkzosdcbZWvyCzzwEsq5cUoABhqzq1k6WGMyT57R1wvNfO1gYQ0tKUnIiSAf33ialGD9k0QROOCUtY1iF2Kc81EyG026HVoEx6IjGultW1k5gnpNunSEnK1exxhK04ov69QkEIvPGe5ILBYmHEmRG5C5QSKyV+Piiqr4kTPHSl1AXHnF7+X7cKp8ShhXzlaPE6pFUWta+FwuZgeg15nV61aKaWec29lXi/D3e9vQZAknV/J0lMk8+ykKFkErxSU869bBBsd9uMIpc+Ckth22J/geRy9XChrKSUIwjcgS48GUYrL4CYdg17HpxFzOFpwFLBNdnKix7VAZp1LyTWMia0PcsIIUKrTYzsTJ2bk2uh0Ol4cBfjZf5zVlqFQw6WYHgeiR5p1Zm+VU49t8dPr4Gdwzb21ZNs5VFmY3f1mkBdMwlXhpYSa/AGF4wDgusBaZmiAyoKuBlo7wiwYt/CLAkEQvgeJHg1SWS2fgVO7/pWOr9XDobRoqBALE7u36hLIrNe5ttq2lTGUmWtdJzeULD1yVYJrNnFiJruwQjYmg0naSc8veu9kuIhrMT3itlJx5pp7qxZOTNksPRL3lsJDq6hSv0Cl4oRysVadI0Pw8+QhCDHZrEVK90T4TBoiHkfO0lOfjC6hpUf6t0UQhG9BokeD2GVu8ZYe2285d4fcfCQNPLVKLT18TI8Llh7oXJrYLIyhXDARF5Y5H9PDjZ9L1z6TW4IHF++QjKfWeiO1fgH2gqQumVOOkFpypM/PkXtLKZCZt/QY9HytHP6cCs+AsxKqXaZcDSI591avNmHo2TaMz9azWBlulJrx3f7LIiErtEzKxV25itz46rPCu/DzWulAFBIE0bShmB4NorSwJjcJGnQ6GA2O3VvSybVaElTMiQqXYnp08m4mJaxWoFwwQSq5t+QsF/ximwIxczqn2K4dd+lyMR9yKdvOUL+YHtcCmcXU7uOsX7KWHoUFQCsdZCfZYnrst8u5t/Q1rirhMhQTvtiHfRdvYN/FG5j7cE8AUkuP+n1zRrvIWf3qY+kRfrakrmOCIHwLsvRoEMVA5poZQ6+HnaVHbk6wX2FcbOmpTVl3fmzVVoabo+yLIyrBGEO5YFIsNctPynIWAt695aAaMScidBAveSHcp/ReCbWKzFIciRzpe7X1wISTsjimRyp6mKwQKK+yOCzWKHdtvx63Tx031IhIg0D07Lt4AwDw7f5LsmM2W6yq53fG0iYb0+OCS1WK8LNF7i2C8G1I9GgQztLDzd98IDM/CertXDlyAbpyMT1y61K54t4qLK9CcIAfjs4ahv4yRRLtxwBR9pYScktMcOOTZmVJx1tr6bEPpHVUpweof+CsXUxPtbroUVtlXSgghNlbUvdWlcUqO8ZqK1ON61Gy9MjBFZU0yCw4KhR60jgrNauMUiySo+Prs+6XyL1Flh6C8GlI9GgQbtLkJnvu372qpcdqWwH84vXa7BQ70VPH7C2he4lzTzUz+SPQ6HhpBIvE0qOEWnFCaYCyXXZbzW9bgLe6209uzlWrfu0M0klaaqkzSxccVenaVltH7Hb0k8nWq7IwVClYo4orlTOxGJy3YslZeuSQPg+1QHe5WCTptobO3hK5tyimhyB8GhI9GoQXPTVuHcZYzY9tv0Gng7+f2KJxpaAcY5fuwdD3tvDbpPOExSrO3Kmt06M+nuOzk/nXhYLsK2fSk83VVodxHoBCIDNfp0csroSWBZ2u1vKjA+zcQPaCTiYORsbl4VpMj8SyI7X0VDuw9EhOxYkIYfaW1G1XbbEqunxsmVjy+xiTd4vJwT1fPpDZiewtQD3mS+7cpZVSS1H9RKgU4f2vIPcWQfg0JHo0CDfpmQSWHuE/fYPePpBZDulEYbEyhbW31CcUYY2YEkFQsnQilsMZ1xYgb+mpdW+Jr1VqORIGMkvdQHYZbDKXKufycMnSYxfTI37vqE6P9D1njai19Ohl6vQoixe1e87gfFyTQSaQWQ7p/VPL7pMTt1LLlJylSHhuc7V8ELfiOcnSQxBEDSR6NAg3iQhdGsJv2XqZlHU5pJOpVVKjxZWU9an33IRmJj+8ktSF3+aUpcfJABI5V42Se0sYs6KDrjaQWScXyAzJexlLj8xEWJ+YHvtAZnvxqQZnjVCv02OVtYgANsuL4iNlyu6nqNAA0Xve0tOQokemD+kSGLIxPVaGI5cL8O3+y0hesA0jFv3htPCpojo9BEHUQCnrGoQTCtxkz5i4qJ5BJnZFiNXKoNfr7NxWFqt44rLylh7HY3rp7i544c7OIqEjtarUB7XihFL3VqlkkuSOdMa9JScGzJb6ubekbaUiwL5uj3xMEn88b+mx/fYzyAQyV1sVxYtqILPC2lsA8NTA9vj3b7WrpDtt6ZFY3qpUFi+VG3OJpDCiUoD2A5IaTadzitEtJlTxXBxmUfYWWXoIwpchS48Gkcb0AEBBubjUv1whPo6ymklIOuFXW60S9xZk2ykhtew0xJID/NhUihNKRYWoerCuVsjIBTLLrT8mRU4kNKylR/zeLrBbcire0iOo0yMVc9/su6y4pEJFlUXxmSqtvQXYxKXQbSoNZP4q/aKoPfd87ESeqqVHzr3l2NJztbDcblv6+euK51Hqj0QPQfg2JHo0iDR7CwAS527iX+t1OhgNyoKjrGYSkbqtSistogmAsyTUtdptQ4oe2eKENeNq3yJItL1YUkiPqbq3JP06GdPjmqVHXeRI+5KKLGVLT232ltS99fvJHIxZukd2PBXVFkUrkDQ+TIjJ3yByJXLPl/stXZGeE5/SQGb1mB5nLD32xx/KLLDblp6Rr3gepfE4Kt5IEETThkSPBjHXfNOXW0sKkF+GQggXIyF1YxSVV4nX3qp57UIdPrtxNBRqxQmDA/xw8M170CUyBABQJJgkzdVWnM0tASBfp0d6D2RjemTiPFwKlHVQnFDqzuJEwo6z1zBn3QneMsINXS6mxxVXYkWVFZUKwsMqqdUkJMBPL7IuSkWPFK58gVQ0ns4uxvTvj+JSfpndMXWN6Tl0qcBu20EZISSHMKaKLD0E4dtQTI8G4SZBaSwLh15nX6dHSJmZc2+JtxdVVEnq9KCmXd0sPc5kbzmL3ERnFUz6zYONaBlixJlc+3WiuCrPOifcW3JXWn9LT23bzady8fp3R0X7pZM6d775v53GAcHEbfI3oMxskc3eciZwnaOiyqK4lIkj95bQuuis6JFaeqasPgQAOHqlAOtevE20TzZ7S2K5kxvf4csFdtvyFdZxkyIUodVWhmqL1S4bjiAI34D+8jUIN+nJpaUb9Drb5K4S08MF+kqtFTZLT+37WvdW3cbpiqUn2EEhQzmXCDf5cacJrBGBcutEAQqBzHYp67b3wpgo+ewtxxYBuQDfccv38q+lcVfc8+REgnRlc07kcvvVsrfUUBM9ldXylZyBGkuPnHtLZk0zoPY5KFlPjl0pstsm58Ysk6TYy7nApK41wGZBkwouOaSfLbL2EITvQqJHg3CWnhCTvSGOm4DUYnpKa2rpSC04BeXSb9SQbecsroie5sFG1f3y2Vs1oqfmPFwF6KLyaru2QI2lR1qnxy6Q2fZ789/vwKBOLQHUurcOZt7Ax1vOwWJ1XMDvvp7RWDbuVtvYFdoGSix1ESG2e8BN1NLJ3lQjOLhJmc/e0utcskxUVlsVRU+5uVpxvCZ/g0ioSQOZpShZetSQE1zS++BKELmSABYi/Ww1FtGTca3UzkpIEET9IPeWBuEmrLBA/5qKw7X7uC/datlbXIVbqfGkoEw8QXCiwhOip0WwEZdv2GfgcMhZerhxcZOvyYGlRy+79pa8f0uvq42Z4ibBhz7aCcB23x3F9Pgb9ILlGeQn0UB/g2hV+YhmAcgqrOCzt6RiQdXS48K9rqiyKGZQlZmVM7tsMT3Ou7eul9qsL0oiQs5AJPecpSUIXHEtFpVXI9LB+rfSe9EYavWcyCrCfQu3I7ZFILa/dpe3h0MQTQay9GiQSj57S49go1iXchOCWowH796STG43JDEQtRWZ6zZOYUyPggeEJzxI3tLD9XHheikGv7sJn2w9Zzc+bhkE3r1VruTesk/tlivQyLXl4lekk/ahSzccTrxGg54PLlZqG2SUWnpsxf8qqqx2q88DtaKnstqKc3kl+McPxwDU1OlpoJieMrNyZpej7C0pOYUV/PnkkHOLyZ3b3tLjvCWmqKIKVwrKMW/DKWTXjMf+nBLR0wiqMm84dhUAcClf+YsCQRCuQ6JHg3DfTI1+eoQEiEWPxRnRwwcy29qGB/kDAPJLxaKn2lo/S49eMBlKxymlRc0YpHBC5kBmAa4UlGPu/07x+zgtwbu3HMX0yAR4S7O3uHd6XW0dJGkac5nZ4tDFYvQTWnoULCcS91arkNqKx5XVVhnRw1meLHj80938doNebyfm1KioUnNvWRSLEwb469FM8Bz1DkRPVk3tHE40SjWOXkb0yN0rO0uPE2u1cRSWV2H88r34aMs5vLDygGwbaUVsNffWoUsFeGb5XpzNLXZ6DO7AFWuXtzmbW4Kv92TWa300gvAU5N7SIMI6PcEB8gHArlh6wgP9UVBWZe/eqvkn5cwyFLIIDgsJ8LMLzBWiFNMTaDTYFac7nlWIm6Ka1bq39LVtAbWYHjn3FiTvazbIuLc4KqosDicdf4Oet1IpTdKB/uJnFNGs9h4UlVfZZZbVuresyCuu5Lf76e1jldRQdW9VKQs6k58BYQJxyl2fUpbe1QKxpUf6GZAbstxyI3aBzC65t6pwKtsmUPZfvCHbxj6QWdm9lfKhrerzlRvl+PWV2/HZtvO4UWbGa8O7Oj2mhqAxiZ6k97cCsH2RGHVrOy+PhiDUIUuPBuFEj5ylh0NtwVEukJn7X8+5loRVnYFaK0hdv6EJLUTBDi098qJH6gICgBEL/8D/LfqDt0zpnYzp0cE+y0lpGQq9rta9tfFkDh5c/AffJj0jXyQ65AgQWHquFJTjv7sv2rUJlFxb8yAjf8yNMvtrqHVviSdlg14Hfz8XLD0OApm55/3+Y70x+c7O/L4Afz3CA2ufE+eekrPYALVVkjnRGGoSW/Okx1msTHYZkFKz42UolChSEdocnOjhMgidCWS+cL0Uu85dxzvrT+KjLedw+YZ9zSF3IhRqSs9SayiJToLQEiR6NAg36Rn99IpiQm0SLJVUZObcWwWl8paeun6ptEosPWqEKbi37rg5Unb7qexiHM+ypTw7HdOjs7mChAgnWaFFS4daS8+BzAIcvlzI71OzWHEY/cQupxlrj9mtbi7N3goJ8OMztLhaNkI495bU3ePncnFC9UBmTlQ0DzKKLIYBfgb+swLUureUXGtXCyvAGOPdg9LPgDSmR2mB1LKawPv8UjPyiiv5dmtfGIx+7cJlj+FQ+ixwWKyM/5xy2ZDOxPSY/A3414ZaV6vUSupuhNbDMnPjyODSoeHqdhGEuyD3lgbh3VuGull6yvjsrdrJDVBe46iu7i3mgugJkgRk755+N64UlCO7sALLd15QPZazjvDuLQVRotfZZzkJs7CEIk2v04mqD7uKv0FvN6n/diJb9F4aSxIc4AeTvwGlZgtOXrWvYWOqsTydzxOvqdUQdXqCjLbCh6XmWtedXq8TCRGTvx7NZdxbOsl1juofi9X7LqGy2oobZVWoqDlXM0mJBb3kWSi5AUvN1bBaGfrNSRNtb9ciyGEAt6OUdaHFJCTADzmodCrFvrC8SlQF2pG4amiE1q9SswXhQSqNCYJwGrL0aBC1QGYO9UBmLqbH9j4sUN7KknGtFNUWa50tPUwQ1GNyICCkxQmjw0yIb9/cqQBdaXFCJXQ6uVXWBeMVqDShe6suGP30aNcyiF8aAwC+O3BF1Ebqpgox+SlW2QZqA5//lATRulynRyaQmROd5TUCg+tXKMwC/AwIE7ghOdEiXCLkv+MTMCelB19zKKugnD+XtK6U1CumJHrKzBZZ8WJbfkP+88FZpJTiuzikogdQdm+prRlW6GHRIxRZUsuflhC6Ih1lcBKEFiDRo0GEMT1K7i1n6vRw8SzNFeJpjl4pxCfbzivGUIzoGYNVEwcqnkdo6ZFmKkkJqoPFikMa06OGVBwIY3pEl6lTXtvMGYwGPQL8DEibOhSfjekPADiRVShqI51cmwX4qVqXOFEnTVM26PWu1emptndvcQHxZWYLb93R63SidG6DXofwQHtLT4VAvA3u3BJGPz2iw0wAgEzB+lrNJDE9UuGl5N4qrayWFRV+ep1i5lh0qO38jiwwQqHFu7cUApmvlSjHcTlTBFEKYwy5xfJp9FI2ncrB1G8O8QKnsJGIHuFisd4UPaWV1Xjjh6PYee6a9wZBNApI9GiAI5cLRP/kuGyWQKNBOaZHRSwcvlyA0spqfsIPDjAoiqT3fj2tmLI+95GeGNixpVPX4EhAyAUsA8rxIkK4iS9UpkK1kHKzRXWVdeFrXT1Fj3AZkBbBtsleulSCNHYkxORnZ62KbREoGpMcfgblyV+OI5cL7YRsMG/psfDiz8+gs7NuCAUyJzaFsUqcq6tFsC39/vmvatPEpVbJ8iqLyLqmlJFUWW3lCx0KMaiInsga0ZNTJBYV3PVUWayotlj593odEOivbunJLbIXPTE14q4ulp5Ptp3HgHc24pcjVx22fWb5Pnx/4Ao+3nLO7nzS7DZvUFFlkXULCsWgNytdL9p0FivTM/HEZ+lOH5Nfasavx7Nl14Mjmi4kerzMznPX8MDiHXjk4538Ni5rqUWQESGKKevKk2BxRTW+3X+Zn/gMeh1a1/zzltIi2CibUQM4tsIIRYScqBHWfFEUPU4E6HKTb6tmAartiiuq7foTjpGrCB3ob0CI0Q8dW4WgrgQI7o2SJa1rjLhUcEiAvXurVUgAHurbBokdW6JzpPx4nK1boyaMlCw90rWwhIHMXH/SAG3Avu5Sm/BAu2fMWO1EaK624qWvDyqOj0t/F+Kn14nipoSCNqrms3BJklVVWG5bVHfEwu2494PtqKgRnv4GvWJdJouV4YtdF7D1zzy7MdwUZXuGjtxocrxbU3PqpVXi6z52pRBZBfJFBzOul9qdz9tLUVisDA8u3oGk97faWcmEQf8lKgkAxRVVOJB5o+7lMRzwZ47rdZX+8nk6nv1yP1bsss+8JJouJHq8zM+Hbd8Cz+aWALCZxHnRE2xUDmRWsFKMHhALAPj+wGVRenZMWKCo3U1Rtgk2v9SMP87Km4Qdrewt/P8VEWIvSEIFrhJpZenaczgR06N3TvSUmqtlUtZrX3P/GG+KCoFer8OtHVrIjsfReQDx/W8hU4PolaSb8PwdnUTbmgX42wnJQKMB/xnVB19PHCiyAvVqG8a/Lq+qFt1LJYJU3H98TE9VbUVmP71OFK8DiLPsuG/A0iKKQK2lhyNt6u2ynxdOMP1yNAvpGfl2+zkhw6W/C5FaeoT3ObaFLbI3R2KdKSirQk5RBf7MKcGZ3BKcu2b7u7K5I/U11yO+5lV7M5H643G8n/an3Ri4v5O6uLc4hFa3PRn5uH/RH3hGsDCtUAhw8VZiS493Rc+xK4U4nVOMyzfKkXldLDKLBfdFTZyNXboHD3+0E7+dyHHLGOtSYPVETTLB9wcuN/RwCA1DokdDMMZQZrbw345bBBuV3VsKFpKH+raFTgccvlyIyzXfJvV6HVqH14qelsFG/PbKUD4YVQlHLhVhIHNkM3tLklCwBdWhyKK0n7BAf0WRFB1qwvAe0egTGy4eY80/wyqLFbvPXwcA3Bxt+/YuraMDALd3aYXxQ+Lstt8cJbbaCMcdavKH8Fb1bReOl5O62D274ACD3TdlodARutse7tuGf11aaYG/QY/DqcMwY0Q3u7FxmFRWshcWueQmJ4NeZ+dyElrnuGw/uWfEufQAW5ZVkNFPdhFcTjDtOHtddlycdShLYukx6HXQ6ZRFz02S58FRWF6FbIHL62yOTfT4GXS8MJfWYPpS5Zt+VKjr7i3GmN3abf87ehXzfzvNp8Gfyi7mXW/CrEqLlcEsqdbNxeh5ix2COJmrkqU+RJYeFdFzILMAAPDN3ksNO7gahLdbLSBdDjcZnwiNQqJHQxRXVvNWngA/PYKMBkVRIE0H5mjbPBDx7ZoDAA7XpNzqdUCb8FpRwh3rTD0aNYT/aCJlrCNCa4g0ZZ3DmZie3jVWD51OJ2tRigoNwM5pdyHU5I/hPaLx3qO98EDv1gBqv2VP+u9+fFEzuQknzDfuE1faNfrpZbPdfn3ldtzfK4Z/P7BjrZVIr9eJ1hbjrFrCCbuZyQ9+Br39yuoC0SOMibi/ZvxA7Tf9sCB/xUw8QD27TXgeoeiRBjwL09O5z8cLd3ZGr7ZheDulB79PWGGbE89yGWblNenzm07lyo6LE4ZSd4/cul8tBSI9Jswk6zItLDfza4IBtdY9f4Oej8+5WliOwvIq/HY8G78cucpXdJbib9DxBReLyqtQWW1x6J45k1OMnrN+w8uSOkyTvjqARZvOigr4cWuFXROIsOIK+6BubwUyH8i8gX9tOIWNJ2ufndQiV1zpnKXH3QjjcjaezMEzy/fyn6nPtp3Hh5vPitoLnyNpHt+CRI+H+P1EDoYv2IZT2eL6LMJ/FHnFlSLXlk6nczkjwuRvwJ1dxQX/DDqxpaddjWvgjptbuda5BOE/jshQezEinLCUJmRHlh5OLHDIuZ78DXpeyOl0OozsH4tuMaEAbMKsosqC3wX/uLtGh/KvJ9zWERum3Ma/t1iZorD4620d8fitsdj89zvQUiK+hLEw3GQsjC/i4nWkriJhnMqQLhGICAnAUwPbi8Sd8Ju+WrViNdFj0On4sgLcY/PT61SDONvUfGZaNQvAT5OH4C8D2/P7hBW2ubEqubdW77tkt+4bP+aaeyWdTP1kRI/QpabT1X6OhRSUVYmsEacFoof7G8gqKMeoT3Zh4pf7+fW62oQH4t4e0Vj29K21Y/M3IDTQJsp2nb+OW9/+HX9bc5jfn3GtFD8euiJ6Jm//chIlldX4+XCW7PUKuVIzKQsD4HOKK+yyyErtFmRlbq/SfPhSAR7+aCc+3nJOJNQ4i9yxK4WoqLI4FdMjFxNWVy5eL8WHm8/aBVULP1/P/fcANp3KxfTvjyLjWineWX8S7/16GpdqMg0ZY6JaX+6KM/IWN0rNFJytAhUn9ACMMfz1i30AgHd+OYkvxycg83oZqqxW5AlSWvOKK/lJkTPlKy0BoESAn97OFaPX6fgUYwC4s0bszPy/W9A5MgTNg4zYfuYaH8g5IK4FRvWPdeK6al/LubeEE7qSq0w4YbRtHsgHGz89qAOW77yAhY/3FbVvJWPpkQu45k5nsTLedw/YrEK9Y2vjZXQ6nUgEVVuZKG37/43tzwuoPrHhdu4zjhZBRpyHLQiVs14Ir7lzTdC0dAIQ1smJCAnA3n/cbde3MKZDGngsRM29pdPZrG0VVbWTg14hO+q7SYNwMPMGhnWPUuxPaOnhhKic67G8yoIlNRlJcnBWsaxCe/eW8DcAUeFEg16H2BZBdlaaq4UVojT209mc6NGhdU1cm7D6NsetHZpjgeSzFmT042OpKqqsqKiy4vsDVxAVakKrkAC8te4EANvf3PAeMai2WHHkcoHitUq5coMTPbUiJ6+o0i4oV2rpeXrZHhy9UojoUBO6RDXDotHicTcEn20/L7v9amE5Np3KwTPL9+HBPq1FVlMlS4/Q3ShdcoRvU1iBqNAAu0KYUiZ8sQ9/5pQg83oZ/vVoL367XLmBzPwyrBOIz1PZxbheasajH+/Eg31q3ceersHkTvZfzMfIJbswfkgc/jGiu1fH8sNBW1zpw/3aenUcUsjS4wGOXqn9J3u9xIyKKgvufn8L7p6/FWdza6vv5hVXIr+k1tID1AZsOkuAn94u3iE6zMSb9gHwlqDW4YF4Nbkr/npbR6x4ZgC//2/33IRH4h1/UMWBzPbxQXERwQ77uDmqGYZ1j8JzQzuJ3GHT7+uKndPusrNatZQ5j5yFgbMCbD+Th/TztgDaO25uhR2v32VXT0ZItZWJ7vldXSNFVjIlhCKg1tIjED0Klh4595L0H79Q5lgUvsH56XWY8+AtiuPTQWdnCfLT6/D68K5oEx6I1Ptr/0HGt2+Ov97WUdGFCojja9QsPVNWHcKVgnKbMLgl2m4/d6+kcTZcX8LsrUCjAWMS2+Oe7lHoHhPKW6KA2oDj3eeviyZZzmXoZ9AjJlw+gxEA4iLsM+eCjAa79cQA4OMt53jBA9SuObXv4g3ZNdWU+O7AZcTPScM/15/ktxVXVuNgTfwLByd692Tk4+VVB7H9zDUUlNkWWv35cJZd2r4aVivD8axCh9aNEzIVwwGbqNx8yvbl6OfDWSKBJlziREi2QNCeyCriLS55xZUoM1djzb5LGDh3o8PK7ADwZ02M1up9tbFBFiuTtSQG+OmxTlAu4NTVIsz++TiqrQzfCYKX84or7WKwGprfjmdjyL824Xc3BXJzvPXzCVgZ8Nn2DLeeB6hZ4kXhvuUVV+KV1Ycx9ZvDLn0+PUGdRM+HH36IDh06wGQyISEhAXv27FFtv2bNGnTt2hUmkwk9e/bE+vXrRfsZY0hNTUVMTAwCAwORlJSEM2fOiNrk5+fjySefRGhoKMLDwzF+/HiUlJSI2hw5cgS33XYbTCYTYmNjMW/evLpcXoPzvaBS76X8Mhy4eIP/hi/8hpJbXIkbZWLR0yc2XBRLIQdXqA2w/XNv21w8Sffv0BwdIoLRq20YBnVqie4xodIuRDj75x8VJj6vlL7tmuNfj/RULXCo1+vw6Zj+mHZvV3GxQz+DrNgQmvqTutkE0bNDO9q1S+oehZgwE66VmPng0fh2zR1WNrZYrYhtEYT3Hu2FJX/p5/CbJ4fQCsGlsBtkRI80yFLNTfHeo70QFRqAfz7Uk98mDDzu1y4crZoFYMUzA3DireHo1TYcc1J64I37uuLtlB6iGCSbpUcsevQ6Hdq3DMaOaXfhGZngbTWEafqcEM24Vivgb2lt+4xxLpz49s0xuEuEXT/dW8t/FjkLpzDmK8jfD2892AOfjekPnU4nCpSf92hvAMDeC/m4KMkwAmwiqmWwUSSshcd3iKgVupzbd/xtcaoxVBzcl5odkixIf4MOU5K62LXnzrvz3HVcLzXz1k2OLadtrtiONV8atpzOw/AF2/DYJ7vw4yF7t1nCPzfi72sOI7uwAhYrU1wctbCsCpO+2o8RC/9A4txNeHrZHqTJTMK5RRWiZwnUfoHJKijHgUybyLMy2I2n1FyNcrMF7/xygu9bOOkVVVTjnv9sxZbTubht3iaMW7YXr357BAAw++daIbnvQj6feMCPX2KRWbL1HKxWhkv5ZbJV5U9lF/PuTQD4ek8mnyUrpNrKcPhygctp7zvPXcMNBbetlHm/nsblG+X46xf7eNFXH8zVVliszC6zT/j/Ua3YJgCcyi5yOuj7eFYhVu3J5BMx8kvNGPTuRoz8ZJcogw8AUn88hlvf+Z1/v0cma9ObuOzeWr16NaZOnYolS5YgISEBCxYsQHJyMk6fPo3ISPvFI3fu3InRo0dj7ty5uP/++7Fy5UqkpKTgwIED6NHDNpnPmzcPCxcuxIoVKxAXF4c333wTycnJOHHiBEwm28T65JNP4urVq0hLS0NVVRXGjRuHiRMnYuXKlQCAoqIiDBs2DElJSViyZAmOHj2KZ555BuHh4Zg4cWJ97lG9ubtbJK4UlCPtRA6KK6vxtUIGw5x1J/h/LsJv0n8Z2B4/Hc5S/PAkdY/Ef3dn8hOv9Bs6F0T80+Qh9b4WIc8N7YjL+WW4t2eM7H6dDhh1azun++sTG273z1aKcBL6+C/xuHi9DJ1a2VuU/A16TLy9o+gfqdLipkK4dO6RTrj3hAgXWxzeI5ofA0fPNjaX2sdPxuO5/+7nLRBq/3RG9o+1G4dQ9Hz//GC7Y54SxN20aR7If9MtrqgWrY3VzOTnVGq+EuGiNbps1znsligs33kBSd0i7VxI/Tu0wBMD2iGroBxhgf5Ys+8S/jbsZrQOD8SyHRfs+uf+YXcTCHTpUidPJbbH9jN5eCqxA3q3DUNESACulVTya2YZ/fS11c0NNguaUGS+fHcXvFNjZekosPR89GQ/nMgqQr92zUXVqPvEhovW4+LYe+EGMq+XYfsZm+iZk9IDep0tEzDAX48Fv4u/wA3q1FI1dftCjWjr1745zl8rxdXCCrusKSnf7r+MX45chYXZ4n1CAvzQvXUoFo3ui5LKahy7UoiXVx3i22cXVSC7qAJbTufh8zH9cftNrbBsRwZ2nLuObTVu7pbBRr5o5NCbWiHjWinO5an/fT71//bwCRTLdlzAr6/cjrd/OSFqU1FlxdPLbCn70jIGY5fuQTOTH9YduQqdDpj7UE+EmPzQt11zXJaIhXf/dwr/O3pV1l0ph9SFKuShj3bCoNdh3iO98E2NFalLVAieGtgBN0c3Q2W1Lav2w01nAR3QJbIZ/r7mMFo1C8DsB24BY8Cvx7Mx6Y5O/GeWMYZL+eWwMIZzebVi6611J/gq7oBNjAYF2JJWTl4twrojWUi+JRq92oaDMYbfTuRAr9Nh65+5iAkLxImsIqSdzIG52gqTvx7Lnh6A/h2a49+/nRaJuiOXC3BX1yiUmavx390XUVllxfN3doZBr8OXuy/izbXHMDK+Ld4b2Rtl5mqUVFbLhil8uesC3vzxOABg2vdH8ezQjggL9EdOUSVyiirx0tcHsfTpW6HT6bD9TB6fMMKxJyMf/9e7NczVVhy6VIBebcOcqq7vLnTMxSiuhIQE3HrrrVi8eDEAwGq1IjY2Fi+++CKmTZtm137UqFEoLS3FunXr+G0DBw5Enz59sGTJEjDG0Lp1a/ztb3/D3//+dwBAYWEhoqKisHz5cjz++OM4efIkunfvjr1796J/f9uHZcOGDbjvvvtw+fJltG7dGh9//DH+8Y9/IDs7G0ajTTBMmzYNa9euxalTp+zGBQCVlZWorKxVw0VFRYiNjUVhYSFCQ9WtIXXhwcV/OP0H+rd7bsKLd9d+S/zrir18MO6Fd0cAADpM+wUAsPKvCYgJD0Sw0cBXqv3L5+n44+w1PNKvLeY/1tupc3L9fTcpEfHt7WvYOHs8ALRvGYT1L90mStt+c+0xfLn7Iibe3hFv3Gefen2j1IwPN5/Fo/3biuJshGQXVmD690fwVGJ73NVVOeYEsGV0PLpkFw5dKsBTA9tjjorF7I0fjmJleiZWTRzodBVqIW/9fAJLd9hMytzzAYCdZ6+h2spw+021QeNVFiu6/ON/AID+7Zvj20mDnD5P5vUy3P7eZnSPCcX6l29TbWu1MnR8w2ZV7dU2DM8N7YTJKw/AyoB3H+6Jxwc4L0jl4J73f0b1xkN9be7Qi9dLER1mws0zNoja/vD8IPStySoUwhhD0vtb+ck0+ZYo/Ho8Bz3bhOHnF4egpLIaPWb+CgB44c5OeDW5q10fHB/8fgb/+d1Wa8do0GPC7XH4cLMtnii+fXN8N2kQBr+7CVcKyjG4c0tMvedmvijo0VnDFN2ehy4VwE+vw74L+ZhVI6IT4lpg2r1dMerT3XbWuu2v3SlykQr/Lrj79bdvDsPKbPF1Z/NKcCm/HM/e3hHfHbiMayVm+Ol1+M+oPnhRpaCjkJujmomsGq5g0OvQJjxQtKQIALQOM+GfD/fEjrPX8GpyV4xcspP//xXZLAD5pWbFKtsNjUGv411nvduGYehNrbBk63k797AcI+Pb4qfDWXWqGG3006NbTCgv5JwZZ3z75gj0N+B0drHI1QrUJA9YGe64uRWyCyuQV1yJ66VmxISZ0LddOH4/mct/nm6/qRWC/A3YcDxb7lQOCfQ3YESvGGz9M0/kPua+HHAM7NgCRy8XotRsQYeWQXySRjOTH1oEG7H+6FW+yKcSbZsHIr59c/x+Iscu8D7YaEDv2HDkl5pxKrsYPdqE4tOn+jsVNuAKRUVFCAsLczh/uyR6zGYzgoKC8O233yIlJYXfPnbsWBQUFODHH3+0O6Zdu3aYOnUqpkyZwm+bOXMm1q5di8OHD+P8+fPo1KkTDh48iD59+vBthg4dij59+uCDDz7A0qVL8be//Q03btRmEVRXV8NkMmHNmjV46KGHMGbMGBQVFWHt2rV8m82bN+Ouu+5Cfn4+mje3/4c7a9YszJ492267u0TP7ydyMPnrAw4/QAAwf2RvUVzNpfwyjFm6B+OHxPFZNJnXy3Aur8Qu7gWw+VR/OZKFxwe0c1pV/3P9SWRcK8Unf4lXjedQ4ujlQvx46ApevLsLQk1+dq6hKosVx7OK0KN1qEsLaNaH/FIztpzOxf29WquuV8YYQ0FZlSg2xxWulVRizroTeGZwHHorBDsLefbLffj1eA6W/KUfhveQt5Qpcb2kEqGB/k7VOEo/fx3Tvz+KN+/vjju7RuLQpQJcvlGGET1jnHbdKTHrp+NIz8jH95MG2dU8+k/an/hg4xm8fHcX9GgThntUgqJPZBVh/Iq9KKmoxh/T7sKRywVo2zyIt3p+ufsiPtl6Dv8dn4AODuLECsrMOHSpAC2DAxAZGoCk97eiuKIaj98ai3cf6YX9F2/g58NZeCXpJgQHGPDU/9uDVs0CsNCJYGCucvPQm1rx1bwn/Xc//ncsm7cq3XlzKywbN0B03P6LN7D7/HXsu5CP/LIqfPtcIrIKynEquxgJcS3gb9Bj38UbGNI5AkXlVfj+4BW0CTdhWPdovPHDUazaewlPJrRDQseWeHnVQd4NbPLXQ6/TYWDHlvhsTH/8dcVebD6dh4S4FugcGYKv92SK3D4xYSakTR0Kg06HY1mF6B4Tiv9b9AfOK1hXX7q7C6becxP/PreoAq98cwgXrpXh2aEdUWVhmLPuBF4f3hUbjmfzwmBATdHPPRecc2u0DDaiY6tg7L1Q+//9yYR2WLX3EixWhg4tg3jrF1D7hfC349l49r/7oYPNOldeZcErqw/jvp7RqKyyYmNNmYQvxw9AdKgJ5/JKMPOn4xjSuRUOXy7A2dwS3NczmhcaOl1tnKK/QbwYb10x6HW2uk0MeP6OTmhm8ufd7WoIxyKkXYsgxISZZAt9ArY6W/EdmmPLaXF18ehQk50Ac4XEji2R1D0KizadQUFN3JrRT49nBsdhyVZxokLPNmGiOFY5HurbBv8Z1afO45HDLaInKysLbdq0wc6dO5GYmMhvf+2117B161akp9uve2I0GrFixQqMHj2a3/bRRx9h9uzZyMnJwc6dOzF48GBkZWUhJqb2n/9jjz0GnU6H1atX45///CdWrFiB06dPi/qOjIzE7NmzMWnSJAwbNgxxcXH45JNP+P0nTpzALbfcghMnTqBbN3vLgqctPYDNv330ciFujm6Gs7klOHalEHd2jURAzardl/LLsfPcNTzWP9arJkDCvVRbrLh8o9zhJN5YsVgZrpdWyprL5eAK8jkTQ+MKldUWXMovQ7sWwaqit65UW6woKK9CREgALFbmuKAnYy6LzesllXwJi4vXS3E2twSDOkXAyhj/P8Kgt7nu9l+8gYS4FtDrdSgoMyPtRA5aBBthZbb4qTaSb9clldXY9mcecooqMKhTBG6KCkG1lWH7mTwkdoyQLeApvJaiimqEBfojq6Ac+y7eQJ+24WjXMggWK8N3+y+j0mITgpfyy9G2eSCuFlagXYsgnL9WgltiwnDg0g10jwlFoNGAnWevYVDnCOSXmNEhIhiHLxXAoNehR5swnM0txh9nrsHfT4+UPm14C/LOs9dg0OuQ0LElGGM4lV2MLpEhuFpYgZ8OZ6FVSABG9m/L33Pu/lusDFkF5YhtEYRL+WXILzWjR5swrDuShXYtgtC3XXPcKDVjzf5LsFiB+3pGw9+gh05nE7FXbpTj7m6R6NQqBNdLzdh9/jqSukUh41opTmQVwcIYYsJMuLVDC1RZrPgzpxg924TD6KdH+vnr2HnuOiKaBaBZgB+iQk3ILipHblElusaEYkjnCBzPKsT2M9dgrraiT2w4Kqos6BwZgi41SSoFZWYczCzA0Jta4WJ+GfZeyEdUqAlDayzKf+YUY+fZayiprEZsiyAM7xGNnWevI7/UjObBNtdU33bh2HH2OpoH+aNTqxBE1QhDLq60uKIaReVVYAAe6deWd4efyyvB9j/z0L11GG7t0BwbT+Yiv8xWH6tdyyDc2yMGVwrKUVRehXYtgnA6pxjZhRUoLK9C1+hmWL7zAt59pFeD/607K3p8OmU9ICAAAQF1j2uoC1GhJkR1t00EsS2C7Kw0nSNDFNdgIpoOfgZ9kxU8gG0SdlbwALZvje4QJQF+BnSOlK/e3BD4GfR89pozi8LWxbomrAnVvmUw2reU/9wY/fRI7FTrmg0PMjqMTQsJ8MN9kpg8f4POoesYsF0LN3G1Dg/EAwJBZdDr8Nittedu29zm7uPcflwJjTsFcXacxZPLmBNaTDtHNpN9joM61wbH63Q6Pp4mtkUQXrizs+yYufFxY4ltEcS/FqayNw82YuLtnez6uL+XWDhGhATg/l62YqLdYkJFcWiArXaaMFwgoWNLJDhwofdqG45ebcMV94cHGfm5Iy4i2C5T9qaoZnZZvHIeAWkYQbTCGo1COrUKQSfBuoVJMlZc4Xik4QKOrt3duPRfJiIiAgaDATk54iC8nJwcREfbp6MCQHR0tGp77rejNrm54oqu1dXVyM/PF7WR60N4DoIgCIIgfBeXRI/RaER8fDw2btzIb7Nardi4caPI3SUkMTFR1B4A0tLS+PZxcXGIjo4WtSkqKkJ6ejrfJjExEQUFBdi/fz/fZtOmTbBarUhISODbbNu2DVVVVaLz3HzzzbLxPARBEARB+BjMRVatWsUCAgLY8uXL2YkTJ9jEiRNZeHg4y87OZowx9tRTT7Fp06bx7Xfs2MH8/PzYv//9b3by5Ek2c+ZM5u/vz44ePcq3effdd1l4eDj78ccf2ZEjR9iDDz7I4uLiWHl5Od9m+PDhrG/fviw9PZ398ccfrEuXLmz06NH8/oKCAhYVFcWeeuopduzYMbZq1SoWFBTEPvnkE6evrbCwkAFghYWFrt4WgiAIgiC8hLPzt8uihzHGFi1axNq1a8eMRiMbMGAA2717N79v6NChbOzYsaL233zzDbvpppuY0Whkt9xyC/vll19E+61WK3vzzTdZVFQUCwgIYHfffTc7ffq0qM3169fZ6NGjWUhICAsNDWXjxo1jxcXFojaHDx9mQ4YMYQEBAaxNmzbs3Xffdem6SPQQBEEQROPD2fnb5To9TRlno78JgiAIgtAOzs7ftPYWQRAEQRA+AYkegiAIgiB8AhI9BEEQBEH4BCR6CIIgCILwCUj0EARBEAThE5DoIQiCIAjCJyDRQxAEQRCET0CihyAIgiAIn8CnV1mXwtVpLCoq8vJICIIgCIJwFm7edlRvmUSPgOLiYgBAbGysl0dCEARBEISrFBcXIywsTHE/LUMhwGq1IisrC82aNYNOp2vQvouKihAbG4tLly7REhduhO6zZ6D77DnoXnsGus+ewV33mTGG4uJitG7dGnq9cuQOWXoE6PV6tG3b1q3nCA0NpT8oD0D32TPQffYcdK89A91nz+CO+6xm4eGgQGaCIAiCIHwCEj0EQRAEQfgEJHo8REBAAGbOnImAgABvD6VJQ/fZM9B99hx0rz0D3WfP4O37TIHMBEEQBEH4BGTpIQiCIAjCJyDRQxAEQRCET0CihyAIgiAIn4BED0EQBEEQPgGJHoIgCIIgfAISPR7gww8/RIcOHWAymZCQkIA9e/Z4e0iNim3btuH//u//0Lp1a+h0Oqxdu1a0nzGG1NRUxMTEIDAwEElJSThz5oyoTX5+Pp588kmEhoYiPDwc48ePR0lJiQevQvvMnTsXt956K5o1a4bIyEikpKTg9OnTojYVFRV44YUX0LJlS4SEhOCRRx5BTk6OqE1mZiZGjBiBoKAgREZG4tVXX0V1dbUnL0XzfPzxx+jVqxdflTYxMRH/+9//+P10n93Du+++C51OhylTpvDb6F7Xn1mzZkGn04l+unbtyu/X1D1mhFtZtWoVMxqNbOnSpez48eNswoQJLDw8nOXk5Hh7aI2G9evXs3/84x/s+++/ZwDYDz/8INr/7rvvsrCwMLZ27Vp2+PBh9sADD7C4uDhWXl7Otxk+fDjr3bs32717N9u+fTvr3LkzGz16tIevRNskJyezZcuWsWPHjrFDhw6x++67j7Vr146VlJTwbZ577jkWGxvLNm7cyPbt28cGDhzIBg0axO+vrq5mPXr0YElJSezgwYNs/fr1LCIigk2fPt0bl6RZfvrpJ/bLL7+wP//8k50+fZq98cYbzN/fnx07dowxRvfZHezZs4d16NCB9erVi7388sv8drrX9WfmzJnslltuYVevXuV/8vLy+P1auscketzMgAED2AsvvMC/t1gsrHXr1mzu3LleHFXjRSp6rFYri46OZu+99x6/raCggAUEBLCvv/6aMcbYiRMnGAC2d+9evs3//vc/ptPp2JUrVzw29sZGbm4uA8C2bt3KGLPdV39/f7ZmzRq+zcmTJxkAtmvXLsaYTaDq9XqWnZ3Nt/n4449ZaGgoq6ys9OwFNDKaN2/OPv/8c7rPbqC4uJh16dKFpaWlsaFDh/Kih+51wzBz5kzWu3dv2X1au8fk3nIjZrMZ+/fvR1JSEr9Nr9cjKSkJu3bt8uLImg4ZGRnIzs4W3eOwsDAkJCTw93jXrl0IDw9H//79+TZJSUnQ6/VIT0/3+JgbC4WFhQCAFi1aAAD279+Pqqoq0b3u2rUr2rVrJ7rXPXv2RFRUFN8mOTkZRUVFOH78uAdH33iwWCxYtWoVSktLkZiYSPfZDbzwwgsYMWKE6J4C9JluSM6cOYPWrVujY8eOePLJJ5GZmQlAe/eYVll3I9euXYPFYhE9SACIiorCqVOnvDSqpkV2djYAyN5jbl92djYiIyNF+/38/NCiRQu+DSHGarViypQpGDx4MHr06AHAdh+NRiPCw8NFbaX3Wu5ZcPuIWo4ePYrExERUVFQgJCQEP/zwA7p3745Dhw7RfW5AVq1ahQMHDmDv3r12++gz3TAkJCRg+fLluPnmm3H16lXMnj0bt912G44dO6a5e0yihyAIO1544QUcO3YMf/zxh7eH0mS5+eabcejQIRQWFuLbb7/F2LFjsXXrVm8Pq0lx6dIlvPzyy0hLS4PJZPL2cJos9957L/+6V69eSEhIQPv27fHNN98gMDDQiyOzh9xbbiQiIgIGg8EuSj0nJwfR0dFeGlXTgruPavc4Ojoaubm5ov3V1dXIz8+n5yDD5MmTsW7dOmzevBlt27blt0dHR8NsNqOgoEDUXnqv5Z4Ft4+oxWg0onPnzoiPj8fcuXPRu3dvfPDBB3SfG5D9+/cjNzcX/fr1g5+fH/z8/LB161YsXLgQfn5+iIqKonvtBsLDw3HTTTfh7Nmzmvs8k+hxI0ajEfHx8di4cSO/zWq1YuPGjUhMTPTiyJoOcXFxiI6OFt3joqIipKen8/c4MTERBQUF2L9/P99m06ZNsFqtSEhI8PiYtQpjDJMnT8YPP/yATZs2IS4uTrQ/Pj4e/v7+ont9+vRpZGZmiu710aNHRSIzLS0NoaGh6N69u2cupJFitVpRWVlJ97kBufvuu3H06FEcOnSI/+nfvz+efPJJ/jXd64anpKQE586dQ0xMjPY+zw0aFk3YsWrVKhYQEMCWL1/OTpw4wSZOnMjCw8NFUeqEOsXFxezgwYPs4MGDDAB7//332cGDB9nFixcZY7aU9fDwcPbjjz+yI0eOsAcffFA2Zb1v374sPT2d/fHHH6xLly6Usi5h0qRJLCwsjG3ZskWUelpWVsa3ee6551i7du3Ypk2b2L59+1hiYiJLTEzk93Opp8OGDWOHDh1iGzZsYK1ataL0XgnTpk1jW7duZRkZGezIkSNs2rRpTKfTsd9++40xRvfZnQiztxije90Q/O1vf2NbtmxhGRkZbMeOHSwpKYlFRESw3Nxcxpi27jGJHg+waNEi1q5dO2Y0GtmAAQPY7t27vT2kRsXmzZsZALufsWPHMsZsaetvvvkmi4qKYgEBAezuu+9mp0+fFvVx/fp1Nnr0aBYSEsJCQ0PZuHHjWHFxsReuRrvI3WMAbNmyZXyb8vJy9vzzz7PmzZuzoKAg9tBDD7GrV6+K+rlw4QK79957WWBgIIuIiGB/+9vfWFVVlYevRts888wzrH379sxoNLJWrVqxu+++mxc8jNF9didS0UP3uv6MGjWKxcTEMKPRyNq0acNGjRrFzp49y+/X0j3WMcZYw9qOCIIgCIIgtAfF9BAEQRAE4ROQ6CEIgiAIwicg0UMQBEEQhE9AoocgCIIgCJ+ARA9BEARBED4BiR6CIAiCIHwCEj0EQRAEQfgEJHoIgiAIgvAJSPQQBEEQBOETkOghCIIgCMInINFDEARBEIRP8P8BzAxV7PMGTtkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not model_loaded:\n",
    "    # plt.plot(test_total_losses)\n",
    "    plt.plot(test_feature_losses)\n",
    "    # plt.plot(edge_losses)\n",
    "    # plt.plot(kl_losses)\n",
    "    plt.title(\"Test Feature Loss\")\n",
    "    plt.legend(['Feature Loss', 'KL Loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not model_loaded:\n",
    "    plt.plot(test_position_losses)\n",
    "    plt.title(\"Test Position Loss\")\n",
    "\n",
    "    # atomic radius of oxygen is 0.74 Angstrom\n",
    "    # atomic radius of hydrogen is 0.53 Angstrom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh1tn4jHZzNy",
    "outputId": "baaf7ea4-07e8-41bd-aac6-9575569172ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error 6.978611099861647e-06\n"
     ]
    }
   ],
   "source": [
    "from torch.functional import F\n",
    "\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "\n",
    "embeddings = []\n",
    "input_feature = []\n",
    "decoded_feature = []\n",
    "\n",
    "for ind in range(len(test_loader)):\n",
    "    test_graph = test_loader.dataset[ind]\n",
    "\n",
    "    model.double()\n",
    "    z,encoded_edge_index = model.encode(test_graph.x,test_graph.edge_index)\n",
    "    decoded_x,decoded_edge_index = model.decode(z,encoded_edge_index)\n",
    "    heavy_indices = torch.where(test_graph.x[:,4] > torch.tensor([1]).to(device))\n",
    "\n",
    "    embeddings.append(z)\n",
    "    decoded_feature.append(decoded_x)\n",
    "    input_feature.append(test_graph.x)\n",
    "    \n",
    "    Error_wo_s = F.mse_loss(decoded_x[heavy_indices], test_graph.x[heavy_indices]).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    avg1 += Error_wo_s\n",
    "\n",
    "    # print(\"Error\" , Error_wo_s, Error_af_s)\n",
    "\n",
    "print(\"Average Error\", avg1/len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0790, 0.9918, 1.0785, 0.1515, 7.9993]], dtype=torch.float64,\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([[1.0796, 0.9928, 1.0734, 0.1520, 8.0000]], dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "heavy_indices = torch.where(input_feature[0][:,4] > torch.tensor([1]).to(device))\n",
    "heavy_indices\n",
    "decoded_feature[0][heavy_indices],input_feature[0][heavy_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "YdJKGevGm0sr",
    "outputId": "476d0e1c-deb3-41e1-a68a-e71d58f173df"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_self_loops=False\n",
    "adj_binary = convert_to_adj(decoded_edge_index, num_nodes=decoded_x.shape[0])\n",
    "indices = torch.where(adj_binary)\n",
    "G = nx.Graph()\n",
    "if not add_self_loops:\n",
    "    edges = [(i, j) for i, j in zip(indices[0].tolist(), indices[1].tolist()) if i != j]\n",
    "    G.add_edges_from(edges)\n",
    "else:\n",
    "    G.add_edges_from(zip(indices[0].tolist(), indices[1].tolist()))\n",
    "nx.draw_networkx(G)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQZK2tNWrgPu"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f9761786ac07e4eab4386916b2ac1a9951f01c213aa09aceac38efe2713e05d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "174bcfbaa57647a791816ea2f5f95aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "",
      "disabled": false,
      "icon": "compress",
      "layout": "IPY_MODEL_f7e90ca6eca44a02aa7dbd7c721963d2",
      "style": "IPY_MODEL_d0b06dda6324492e96af92e3aeea444b",
      "tooltip": ""
     }
    },
    "1ccf61fe60854532adca37efa0ce3d8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dbdb82571c54cdd93dc2852bfff8d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51f160dd2cbe413ca4340f08c1c556c6",
       "IPY_MODEL_f25cd88e94d7471fba0524c195300dbd"
      ],
      "layout": "IPY_MODEL_c842ad6e08ac425eade8ae91843af6cf"
     }
    },
    "51f160dd2cbe413ca4340f08c1c556c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PlayModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PlayModel",
      "_playing": false,
      "_repeat": false,
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PlayView",
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "interval": 100,
      "layout": "IPY_MODEL_8cb134fe0b18494bbefe6c95adc7d14e",
      "max": 0,
      "min": 0,
      "show_repeat": true,
      "step": 1,
      "style": "IPY_MODEL_65d323feef3b4d44a7846a7c208946f1",
      "value": 0
     }
    },
    "65d323feef3b4d44a7846a7c208946f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83451c0f082c4aa888b1dd14e9c775bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb134fe0b18494bbefe6c95adc7d14e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3e2e11d45734b7d9224fb987459470b": {
     "model_module": "nglview-js-widgets",
     "model_module_version": "3.0.1",
     "model_name": "NGLModel",
     "state": {
      "_camera_orientation": [
       -10.103352365027183,
       6.385389408422379,
       -0.592550746983955,
       0,
       3.959195270940704,
       5.341158002393939,
       -9.949816445385695,
       0,
       -5.0447088212804285,
       -8.596561905384883,
       -6.622090275149148,
       0,
       -1.7100000381469727,
       -0.8059999942779541,
       -0.2979999780654907,
       1
      ],
      "_camera_str": "orthographic",
      "_dom_classes": [],
      "_gui_theme": null,
      "_ibtn_fullscreen": "IPY_MODEL_174bcfbaa57647a791816ea2f5f95aba",
      "_igui": null,
      "_iplayer": "IPY_MODEL_1dbdb82571c54cdd93dc2852bfff8d40",
      "_model_module": "nglview-js-widgets",
      "_model_module_version": "3.0.1",
      "_model_name": "NGLModel",
      "_ngl_color_dict": {},
      "_ngl_coordinate_resource": {},
      "_ngl_full_stage_parameters": {
       "ambientColor": 14540253,
       "ambientIntensity": 0.2,
       "backgroundColor": "white",
       "cameraEyeSep": 0.3,
       "cameraFov": 40,
       "cameraType": "perspective",
       "clipDist": 10,
       "clipFar": 100,
       "clipNear": 0,
       "fogFar": 100,
       "fogNear": 50,
       "hoverTimeout": 0,
       "impostor": true,
       "lightColor": 14540253,
       "lightIntensity": 1,
       "mousePreset": "default",
       "panSpeed": 1,
       "quality": "medium",
       "rotateSpeed": 2,
       "sampleLevel": 0,
       "tooltip": true,
       "workerDefault": true,
       "zoomSpeed": 1.2
      },
      "_ngl_msg_archive": [
       {
        "args": [
         {
          "binary": false,
          "data": "MODEL     1\nATOM      1    O MOL     1       1.736   0.839   0.257  1.00  0.00           O  \nATOM      2    H MOL     1       1.777   0.781   0.322  1.00  0.00           H  \nATOM      3    H MOL     1       1.643   0.831   0.274  1.00  0.00           H  \nATOM      4    X MOL     1       1.730   0.831   0.267  1.00  0.00           X  \nENDMDL\n",
          "type": "blob"
         }
        ],
        "kwargs": {
         "defaultRepresentation": true,
         "ext": "pdb"
        },
        "methodName": "loadFile",
        "reconstruc_color_scheme": false,
        "target": "Stage",
        "type": "call_method"
       }
      ],
      "_ngl_original_stage_parameters": {
       "ambientColor": 14540253,
       "ambientIntensity": 0.2,
       "backgroundColor": "white",
       "cameraEyeSep": 0.3,
       "cameraFov": 40,
       "cameraType": "perspective",
       "clipDist": 10,
       "clipFar": 100,
       "clipNear": 0,
       "fogFar": 100,
       "fogNear": 50,
       "hoverTimeout": 0,
       "impostor": true,
       "lightColor": 14540253,
       "lightIntensity": 1,
       "mousePreset": "default",
       "panSpeed": 1,
       "quality": "medium",
       "rotateSpeed": 2,
       "sampleLevel": 0,
       "tooltip": true,
       "workerDefault": true,
       "zoomSpeed": 1.2
      },
      "_ngl_repr_dict": {
       "0": {
        "0": {
         "params": {
          "aspectRatio": 1.5,
          "assembly": "default",
          "bondScale": 0.3,
          "bondSpacing": 0.75,
          "clipCenter": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "clipNear": 0,
          "clipRadius": 0,
          "colorMode": "hcl",
          "colorReverse": false,
          "colorScale": "",
          "colorScheme": "element",
          "colorValue": 9474192,
          "cylinderOnly": false,
          "defaultAssembly": "",
          "depthWrite": true,
          "diffuse": 16777215,
          "diffuseInterior": false,
          "disableImpostor": false,
          "disablePicking": false,
          "flatShaded": false,
          "interiorColor": 2236962,
          "interiorDarkening": 0,
          "lazy": false,
          "lineOnly": false,
          "linewidth": 2,
          "matrix": {
           "elements": [
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1
           ]
          },
          "metalness": 0,
          "multipleBond": "off",
          "opacity": 1,
          "openEnded": true,
          "quality": "high",
          "radialSegments": 20,
          "radiusData": {},
          "radiusScale": 2,
          "radiusSize": 0.15,
          "radiusType": "size",
          "roughness": 0.4,
          "sele": "",
          "side": "double",
          "sphereDetail": 2,
          "useInteriorColor": true,
          "visible": true,
          "wireframe": false
         },
         "type": "ball+stick"
        }
       },
       "1": {
        "0": {
         "params": {
          "aspectRatio": 1.5,
          "assembly": "default",
          "bondScale": 0.3,
          "bondSpacing": 0.75,
          "clipCenter": {
           "x": 0,
           "y": 0,
           "z": 0
          },
          "clipNear": 0,
          "clipRadius": 0,
          "colorMode": "hcl",
          "colorReverse": false,
          "colorScale": "",
          "colorScheme": "element",
          "colorValue": 9474192,
          "cylinderOnly": false,
          "defaultAssembly": "",
          "depthWrite": true,
          "diffuse": 16777215,
          "diffuseInterior": false,
          "disableImpostor": false,
          "disablePicking": false,
          "flatShaded": false,
          "interiorColor": 2236962,
          "interiorDarkening": 0,
          "lazy": false,
          "lineOnly": false,
          "linewidth": 2,
          "matrix": {
           "elements": [
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            1
           ]
          },
          "metalness": 0,
          "multipleBond": "off",
          "opacity": 1,
          "openEnded": true,
          "quality": "high",
          "radialSegments": 20,
          "radiusData": {},
          "radiusScale": 2,
          "radiusSize": 0.15,
          "radiusType": "size",
          "roughness": 0.4,
          "sele": "",
          "side": "double",
          "sphereDetail": 2,
          "useInteriorColor": true,
          "visible": true,
          "wireframe": false
         },
         "type": "ball+stick"
        }
       }
      },
      "_ngl_serialize": false,
      "_ngl_version": "2.0.0-dev.36",
      "_ngl_view_id": [
       "5FF00EC2-ABC3-45F3-A902-138379E769E1"
      ],
      "_player_dict": {},
      "_scene_position": {},
      "_scene_rotation": {},
      "_synced_model_ids": [],
      "_synced_repr_model_ids": [],
      "_view_count": null,
      "_view_height": "",
      "_view_module": "nglview-js-widgets",
      "_view_module_version": "3.0.1",
      "_view_name": "NGLView",
      "_view_width": "",
      "background": "white",
      "frame": 0,
      "gui_style": null,
      "layout": "IPY_MODEL_83451c0f082c4aa888b1dd14e9c775bf",
      "max_frame": 0,
      "n_components": 2,
      "picked": {}
     }
    },
    "c842ad6e08ac425eade8ae91843af6cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0b06dda6324492e96af92e3aeea444b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "e8f4eabea82a4f928fa75a55769ed112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "f25cd88e94d7471fba0524c195300dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_1ccf61fe60854532adca37efa0ce3d8c",
      "max": 0,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_e8f4eabea82a4f928fa75a55769ed112",
      "value": 0
     }
    },
    "f7e90ca6eca44a02aa7dbd7c721963d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "34px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
